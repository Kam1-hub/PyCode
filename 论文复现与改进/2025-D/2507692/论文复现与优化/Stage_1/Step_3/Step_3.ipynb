{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c946856-463f-4e83-bffd-868f19c5906c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 正在计算路网中点并构建 KDTree 索引...\n",
      "----------------------------------------\n",
      "KDTree 索引构建成功！\n",
      "索引节点规模: 89655 个边中点\n",
      "坐标维度: 2D\n",
      "----------------------------------------\n",
      "包含中点信息的边表已保存: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_with_midpoints.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "# 1. 路径定义\n",
    "edges_path = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_physical_base.csv\"\n",
    "nodes_path = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\nodes_drive_physical_base.csv\"\n",
    "\n",
    "# 2. 加载物理底座数据 (锁定 ID 为字符串)\n",
    "df_edges = pd.read_csv(edges_path, dtype={'u': str, 'v': str})\n",
    "df_nodes = pd.read_csv(nodes_path, dtype={'node_id': str})\n",
    "\n",
    "# 3. 构建节点坐标快速查找表 (ID -> (x, y))\n",
    "node_coords = df_nodes.set_index('node_id')[['x', 'y']].to_dict('index')\n",
    "\n",
    "print(\">>> 正在计算路网中点并构建 KDTree 索引...\")\n",
    "\n",
    "# 4. 计算每条边的几何中点\n",
    "midpoints = []\n",
    "edge_map = [] # 用于记录索引与边的对应关系\n",
    "\n",
    "for idx, row in df_edges.iterrows():\n",
    "    u, v = row['u'], row['v']\n",
    "    \n",
    "    # 提取端点坐标\n",
    "    coord_u = node_coords[u]\n",
    "    coord_v = node_coords[v]\n",
    "    \n",
    "    # 计算几何中点 (Arithmetic Mean) \n",
    "    mid_x = (coord_u['x'] + coord_v['x']) / 2\n",
    "    mid_y = (coord_u['y'] + coord_v['y']) / 2\n",
    "    \n",
    "    midpoints.append([mid_x, mid_y])\n",
    "    edge_map.append({'u': u, 'v': v, 'index': idx})\n",
    "\n",
    "# 5. 构建 KDTree 空间索引 [cite: 23]\n",
    "midpoints_array = np.array(midpoints)\n",
    "spatial_index = KDTree(midpoints_array)\n",
    "\n",
    "# 6. 将中点坐标存回边表 (用于可视化验证)\n",
    "df_edges['mid_x'] = midpoints_array[:, 0]\n",
    "df_edges['mid_y'] = midpoints_array[:, 1]\n",
    "\n",
    "# 7. 体检报告 (Health Check)\n",
    "print(\"-\" * 40)\n",
    "print(f\"KDTree 索引构建成功！\")\n",
    "print(f\"索引节点规模: {len(midpoints)} 个边中点\")\n",
    "print(f\"坐标维度: {midpoints_array.shape[1]}D\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 8. 输出中间文件供后续步骤使用\n",
    "output_dir = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\"\n",
    "output_path = f\"{output_dir}\\\\edges_with_midpoints.csv\"\n",
    "df_edges.to_csv(output_path, index=False)\n",
    "print(f\"包含中点信息的边表已保存: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14ee0cf7-4c2b-4c8e-b846-abd7172ad681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 成功重构坐标的监测点数量: 855\n",
      "---------------------------------------------\n",
      "流量吸附完成！\n",
      "路网匹配覆盖率: 0.82%\n",
      "全局最高流量 (Peak): 134122\n",
      "---------------------------------------------\n",
      "已生成包含流量属性的边表: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_with_volume.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "# 1. 路径定义 (基于您的绝对路径)\n",
    "base_dir = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\"\n",
    "nodes_path = f\"{base_dir}\\\\nodes_drive_physical_base.csv\"\n",
    "edges_mid_path = f\"{base_dir}\\\\edges_with_midpoints.csv\"\n",
    "aadt_path = f\"{base_dir}\\\\MDOT_SHA_Annual_Average_Daily_Traffic_Baltimore.csv\"\n",
    "\n",
    "# 2. 加载数据集\n",
    "df_nodes = pd.read_csv(nodes_path, dtype={'node_id': str})\n",
    "df_edges = pd.read_csv(edges_mid_path, dtype={'u': str, 'v': str})\n",
    "df_aadt = pd.read_csv(aadt_path)\n",
    "\n",
    "# 3. 流量监测点坐标重构 (Coordinate Reconstruction)\n",
    "def extract_id(s):\n",
    "    if pd.isna(s): return None\n",
    "    match = re.search(r'(\\d+)', str(s)) # 提取 {} 中的数字\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "df_aadt['extracted_node_id'] = df_aadt['node start'].apply(extract_id)\n",
    "\n",
    "# 通过节点表补齐经纬度\n",
    "df_aadt_coords = df_aadt.merge(\n",
    "    df_nodes[['node_id', 'x', 'y']], \n",
    "    left_on='extracted_node_id', \n",
    "    right_on='node_id', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\">>> 成功重构坐标的监测点数量: {len(df_aadt_coords)}\")\n",
    "\n",
    "# 4. 构建 KDTree 并执行空间吸附\n",
    "# 提取路网边中点坐标\n",
    "edge_midpoints = df_edges[['mid_x', 'mid_y']].values\n",
    "spatial_tree = KDTree(edge_midpoints)\n",
    "\n",
    "# 检索监测点最近的边索引\n",
    "aadt_points = df_aadt_coords[['x', 'y']].values\n",
    "distances, indices = spatial_tree.query(aadt_points)\n",
    "\n",
    "# 5. 冲突处理：峰值捕捉 (MAX Strategy)\n",
    "# 使用 'AADT (Current)' 作为流量字段\n",
    "volume_col = 'AADT (Current)'\n",
    "df_aadt_coords['matched_edge_idx'] = indices\n",
    "\n",
    "# 按边索引聚合，取最大流量\n",
    "edge_volume_agg = df_aadt_coords.groupby('matched_edge_idx')[volume_col].max().to_dict()\n",
    "\n",
    "# 6. 将流量属性注入边表\n",
    "df_edges['volume'] = np.nan\n",
    "for edge_idx, vol in edge_volume_agg.items():\n",
    "    df_edges.at[edge_idx, 'volume'] = vol\n",
    "\n",
    "# 7. 体检报告 (Data Audit)\n",
    "matched_edges = df_edges['volume'].notna().sum()\n",
    "print(\"-\" * 45)\n",
    "print(f\"流量吸附完成！\")\n",
    "print(f\"路网匹配覆盖率: {matched_edges / len(df_edges):.2%}\")\n",
    "print(f\"全局最高流量 (Peak): {df_edges['volume'].max():.0f}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# 8. 保存输出\n",
    "output_path = f\"{base_dir}\\\\edges_with_volume.csv\"\n",
    "df_edges.to_csv(output_path, index=False)\n",
    "print(f\"已生成包含流量属性的边表: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61c0a5ba-0efe-4362-a555-e2689b718f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 正在加载数据集...\n",
      ">>> 正在执行监测点地理坐标重构...\n",
      ">>> 正在对 1102 个有效监测点执行 KDTree 空间吸附...\n",
      "--------------------------------------------------\n",
      "【阶段 3.2 流量吸附审计报告】\n",
      "1. AADT 原始记录总数: 2398\n",
      "2. 原始 CSV 缺失 node 标识的记录数: 1295 (约 54.0%)\n",
      "3. 成功恢复物理坐标并参与吸附的记录: 1102\n",
      "4. 流量吸附覆盖的边数: 853\n",
      "5. 全网最大监测流量: 165202\n",
      "--------------------------------------------------\n",
      ">>> 已生成包含流量属性的边表: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_with_volume.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "# 1. 设置绝对路径\n",
    "base_dir = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\"\n",
    "nodes_path = os.path.join(base_dir, \"nodes_drive_physical_base.csv\")\n",
    "edges_path = os.path.join(base_dir, \"edges_with_midpoints.csv\")\n",
    "aadt_path = os.path.join(base_dir, \"MDOT_SHA_Annual_Average_Daily_Traffic_Baltimore.csv\")\n",
    "\n",
    "# 2. 加载数据并锁定 ID 类型\n",
    "print(\">>> 正在加载数据集...\")\n",
    "nodes_df = pd.read_csv(nodes_path, dtype={'node_id': str})\n",
    "edges_df = pd.read_csv(edges_path, dtype={'u': str, 'v': str})\n",
    "aadt_df = pd.read_csv(aadt_path)\n",
    "\n",
    "# 3. 增强型坐标提取与审计逻辑\n",
    "def extract_all_ids(s):\n",
    "    if pd.isna(s): return []\n",
    "    return re.findall(r'(\\d+)', str(s))\n",
    "\n",
    "# 构建节点快速索引表 {id: (x, y)}\n",
    "nodes_lookup = nodes_df.set_index('node_id')[['x', 'y']].to_dict('index')\n",
    "nodes_lookup = {k: (v['x'], v['y']) for k, v in nodes_lookup.items()}\n",
    "\n",
    "def get_best_coord(row):\n",
    "    # 同时扫描 'node start' 和 'node(s) end' 列\n",
    "    ids = extract_all_ids(row['node start']) + extract_all_ids(row['node(s) end'])\n",
    "    for node_id in ids:\n",
    "        if node_id in nodes_lookup:\n",
    "            return nodes_lookup[node_id]\n",
    "    return None, None\n",
    "\n",
    "print(\">>> 正在执行监测点地理坐标重构...\")\n",
    "# 执行坐标恢复\n",
    "coords = aadt_df.apply(get_best_coord, axis=1)\n",
    "aadt_df['x'], aadt_df['y'] = zip(*[c if c else (None, None) for c in coords])\n",
    "\n",
    "# 数据审计：为何有些点无法匹配？\n",
    "total_rows = len(aadt_df)\n",
    "no_node_info = aadt_df[aadt_df['node start'].isna() & aadt_df['node(s) end'].isna()]\n",
    "aadt_mappable = aadt_df.dropna(subset=['x', 'y']).copy()\n",
    "\n",
    "# 4. 执行 KDTree 空间吸附 (Snapping)\n",
    "# 只有恢复了坐标的点才能参与吸附\n",
    "print(f\">>> 正在对 {len(aadt_mappable)} 个有效监测点执行 KDTree 空间吸附...\")\n",
    "tree = KDTree(edges_df[['mid_x', 'mid_y']].values)\n",
    "distances, indices = tree.query(aadt_mappable[['x', 'y']].values)\n",
    "\n",
    "# 5. 流量注入与冲突处理 (MAX 策略)\n",
    "aadt_mappable['edge_idx'] = indices\n",
    "# 使用 AADT (Current) 作为核心流量指标\n",
    "volume_map = aadt_mappable.groupby('edge_idx')['AADT (Current)'].max().to_dict()\n",
    "\n",
    "edges_df['volume'] = np.nan\n",
    "for idx, vol in volume_map.items():\n",
    "    edges_df.at[idx, 'volume'] = vol\n",
    "\n",
    "# 6. 最终质量审计报告 (Data Audit Report)\n",
    "print(\"-\" * 50)\n",
    "print(f\"【阶段 3.2 流量吸附审计报告】\")\n",
    "print(f\"1. AADT 原始记录总数: {total_rows}\")\n",
    "print(f\"2. 原始 CSV 缺失 node 标识的记录数: {len(no_node_info)} (约 {len(no_node_info)/total_rows:.1%})\")\n",
    "print(f\"3. 成功恢复物理坐标并参与吸附的记录: {len(aadt_mappable)}\")\n",
    "print(f\"4. 流量吸附覆盖的边数: {edges_df['volume'].notna().sum()}\")\n",
    "print(f\"5. 全网最大监测流量: {edges_df['volume'].max():.0f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 7. 保存结果\n",
    "output_path = os.path.join(base_dir, \"edges_with_volume.csv\")\n",
    "edges_df.to_csv(output_path, index=False)\n",
    "print(f\">>> 已生成包含流量属性的边表: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "332a8f7c-6bfa-4dda-832e-b0f0fb9d9e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 正在执行全局阻抗更新与属性补全...\n",
      "统计结果：已匹配路段流量中位数 = 5255 AADT\n",
      ">>> 正在基于 BPR 函数计算动态通行阻抗...\n",
      "--------------------------------------------------\n",
      "【阶段 3.3 阻抗建模审计报告】\n",
      "1. 全局背景流量填补值: 5255 AADT\n",
      "2. 全网平均自由流时间: 15.16 s\n",
      "3. 全网平均动态阻抗时间: 15.17 s\n",
      "4. 初始拥堵成本增加比: 0.03%\n",
      "--------------------------------------------------\n",
      ">>> 最终仿真模型已保存: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_final_model.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 1. 设置路径\n",
    "base_dir = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\"\n",
    "edges_volume_path = os.path.join(base_dir, \"edges_with_volume.csv\")\n",
    "\n",
    "# 2. 加载数据\n",
    "df_edges = pd.read_csv(edges_volume_path)\n",
    "\n",
    "print(\">>> 正在执行全局阻抗更新与属性补全...\")\n",
    "\n",
    "# 3. 统计学防御：填补“数据黑洞” (Median Imputation)\n",
    "# 计算已匹配路段流量的中位数作为全网“背景底噪”\n",
    "median_volume = df_edges['volume'].median()\n",
    "# 如果中位数获取失败（如全空），设定一个保守值（如 3000 AADT）\n",
    "if np.isnan(median_volume): median_volume = 3000.0\n",
    "\n",
    "print(f\"统计结果：已匹配路段流量中位数 = {median_volume:.0f} AADT\")\n",
    "\n",
    "# 执行填补：将 NaN 流量替换为中位数\n",
    "df_edges['volume_filled'] = df_edges['volume'].fillna(median_volume)\n",
    "\n",
    "# 4. 通行能力建模 (Capacity Modeling)\n",
    "# 假设车道数：优先使用原始数据车道（如果存在），否则默认为 2 车道\n",
    "# 注：如果之前的步骤没有提取 lanes，此处默认支路为 2 车道，主干道为 4 车道（根据流量判定）\n",
    "def estimate_lanes(row):\n",
    "    if row['volume_filled'] > 50000: return 4 # 判定为高速/主干\n",
    "    return 2 # 判定为普通支路\n",
    "\n",
    "df_edges['lanes'] = df_edges.apply(estimate_lanes, axis=1)\n",
    "\n",
    "# 计算每日通行能力 (Capacity)\n",
    "# 经验公式：单车道每日设计容量约为 15,000 辆\n",
    "df_edges['capacity'] = df_edges['lanes'] * 15000\n",
    "\n",
    "# 5. 激活 BPR 阻抗机理 (BPR Resistance Function)\n",
    "# 公式：T = T0 * (1 + alpha * (V/C)^beta)\n",
    "alpha = 0.15\n",
    "beta = 4\n",
    "\n",
    "print(\">>> 正在基于 BPR 函数计算动态通行阻抗...\")\n",
    "df_edges['free_flow_time'] = df_edges['travel_time'] # 步骤 2 计算的原始时间\n",
    "\n",
    "# 计算考虑拥堵后的最终通行时间 (Weight)\n",
    "df_edges['final_weight'] = df_edges['free_flow_time'] * (\n",
    "    1 + alpha * (df_edges['volume_filled'] / df_edges['capacity'])**beta\n",
    ")\n",
    "\n",
    "# 6. 体检报告 (Final Audit)\n",
    "congestion_increase = (df_edges['final_weight'].mean() - df_edges['free_flow_time'].mean()) / df_edges['free_flow_time'].mean()\n",
    "print(\"-\" * 50)\n",
    "print(f\"【阶段 3.3 阻抗建模审计报告】\")\n",
    "print(f\"1. 全局背景流量填补值: {median_volume:.0f} AADT\")\n",
    "print(f\"2. 全网平均自由流时间: {df_edges['free_flow_time'].mean():.2f} s\")\n",
    "print(f\"3. 全网平均动态阻抗时间: {df_edges['final_weight'].mean():.2f} s\")\n",
    "print(f\"4. 初始拥堵成本增加比: {congestion_increase:.2%}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 7. 持久化输出\n",
    "output_path = os.path.join(base_dir, \"edges_final_model.csv\")\n",
    "df_edges.to_csv(output_path, index=False)\n",
    "print(f\">>> 最终仿真模型已保存: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442d0fc2-b747-46ce-a9c4-c1d7d85622a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
