{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "736942aa-7288-466e-aeda-7985ca746bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== å¼€å§‹æ‰§è¡Œæ­¥éª¤ 1: æ•°æ®æºé”å®š ===\n",
      "æ•°æ®è·¯å¾„: D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\n",
      "\n",
      "[æˆåŠŸåŠ è½½] èŠ‚ç‚¹è¡¨: 37163 è¡Œ\n",
      "[æˆåŠŸåŠ è½½] è¾¹è¡¨:   91227 è¡Œ\n",
      "âŒ [è­¦å‘Š] å‘ç° 1 ä¸ªé‡å¤èŠ‚ç‚¹ IDï¼è¯·æ£€æŸ¥æ•°æ®æºã€‚\n",
      "âœ… [æ ¡éªŒé€šè¿‡] æ‰€æœ‰èŠ‚ç‚¹å‡åŒ…å«å®Œæ•´ç»çº¬åº¦åæ ‡ (x, y)ã€‚\n",
      "âœ… [æ ¡éªŒé€šè¿‡] æ‰€æœ‰è¾¹å‡åŒ…å«èµ·ç‚¹(u)ã€ç»ˆç‚¹(v)å’Œé•¿åº¦(length)ã€‚\n",
      "âš ï¸ [æ³¨æ„] å‘ç° 'maxspeed' åŒ…å«å­—ç¬¦ (ä¾‹å¦‚: '55 mph')ã€‚\n",
      "   -> è¿™å°†åœ¨ä¸‹ä¸€æ­¥ã€å­—æ®µæ¸…æ´—ã€‘ä¸­å¤„ç†ã€‚\n",
      "\n",
      "=== æ­¥éª¤ 1 å®Œæˆ: æ•°æ®æºå·²é”å®šä¸”åŸºç¡€è´¨é‡åˆæ ¼ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kam1\\AppData\\Local\\Temp\\ipykernel_29108\\4193017283.py:24: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  edges_df = pd.read_csv(edges_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# Step 1: æ–‡ä»¶æºé”å®šä¸åŸºç¡€è´¨æ£€ (Source Locking)\n",
    "# ==========================================\n",
    "\n",
    "# 1. é…ç½®ç»å¯¹è·¯å¾„\n",
    "base_path = r\"D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\"\n",
    "\n",
    "# 2. å®šä¹‰ç›®æ ‡æ–‡ä»¶ (åªé”å®š Drive æ•°æ®ï¼Œå‰”é™¤ Noise)\n",
    "node_file = 'nodes_drive.csv'\n",
    "edge_file = 'edges_drive.csv'\n",
    "\n",
    "print(f\"=== å¼€å§‹æ‰§è¡Œæ­¥éª¤ 1: æ•°æ®æºé”å®š ===\")\n",
    "print(f\"æ•°æ®è·¯å¾„: {base_path}\")\n",
    "\n",
    "try:\n",
    "    # 3. åŠ è½½æ•°æ®\n",
    "    nodes_path = os.path.join(base_path, node_file)\n",
    "    edges_path = os.path.join(base_path, edge_file)\n",
    "    \n",
    "    nodes_df = pd.read_csv(nodes_path)\n",
    "    edges_df = pd.read_csv(edges_path)\n",
    "    \n",
    "    print(f\"\\n[æˆåŠŸåŠ è½½] èŠ‚ç‚¹è¡¨: {len(nodes_df)} è¡Œ\")\n",
    "    print(f\"[æˆåŠŸåŠ è½½] è¾¹è¡¨:   {len(edges_df)} è¡Œ\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 4. å…³é”®ç‚¹æ ¡éªŒ (Critical Validations)\n",
    "    # ==========================================\n",
    "    \n",
    "    # Check A: èŠ‚ç‚¹ ID å”¯ä¸€æ€§ (é˜²æ­¢å›¾æ„å»ºæ—¶è¦†ç›–èŠ‚ç‚¹)\n",
    "    if nodes_df['osmid'].is_unique:\n",
    "        print(f\"âœ… [æ ¡éªŒé€šè¿‡] èŠ‚ç‚¹ ID (osmid) å”¯ä¸€ã€‚\")\n",
    "    else:\n",
    "        dup_count = nodes_df['osmid'].duplicated().sum()\n",
    "        print(f\"âŒ [è­¦å‘Š] å‘ç° {dup_count} ä¸ªé‡å¤èŠ‚ç‚¹ IDï¼è¯·æ£€æŸ¥æ•°æ®æºã€‚\")\n",
    "\n",
    "    # Check B: åæ ‡å®Œæ•´æ€§ (åç»­ KDTree åŒ¹é…å¿…é¡»)\n",
    "    missing_coords = nodes_df[['x', 'y']].isnull().sum().sum()\n",
    "    if missing_coords == 0:\n",
    "        print(f\"âœ… [æ ¡éªŒé€šè¿‡] æ‰€æœ‰èŠ‚ç‚¹å‡åŒ…å«å®Œæ•´ç»çº¬åº¦åæ ‡ (x, y)ã€‚\")\n",
    "    else:\n",
    "        print(f\"âŒ [è‡´å‘½é”™è¯¯] æœ‰ {missing_coords} ä¸ªèŠ‚ç‚¹ç¼ºå¤±åæ ‡ï¼Œæ¨¡å‹å°†æ— æ³•å»ºç«‹ç©ºé—´ç´¢å¼•ã€‚\")\n",
    "\n",
    "    # Check C: æ‹“æ‰‘å®Œæ•´æ€§ (u, v å¿…é¡»å­˜åœ¨)\n",
    "    missing_topo = edges_df[['u', 'v', 'length']].isnull().sum().sum()\n",
    "    if missing_topo == 0:\n",
    "        print(f\"âœ… [æ ¡éªŒé€šè¿‡] æ‰€æœ‰è¾¹å‡åŒ…å«èµ·ç‚¹(u)ã€ç»ˆç‚¹(v)å’Œé•¿åº¦(length)ã€‚\")\n",
    "    else:\n",
    "        print(f\"âŒ [è‡´å‘½é”™è¯¯] è¾¹è¡¨ç¼ºå¤±æ‹“æ‰‘ä¿¡æ¯ï¼Œè·¯ç½‘å·²æ–­è£‚ã€‚\")\n",
    "\n",
    "    # Check D: é¢„è­¦è„æ•°æ® (ä¸ºä¸‹ä¸€æ­¥æ¸…æ´—åšå‡†å¤‡)\n",
    "    # æ£€æŸ¥ maxspeed æ˜¯å¦åŒ…å«éæ•°å­—å­—ç¬¦ï¼ˆå¦‚ 'mph'ï¼‰\n",
    "    if edges_df['maxspeed'].dtype == 'object':\n",
    "        example_dirty = edges_df[edges_df['maxspeed'].astype(str).str.contains('mph', na=False)]['maxspeed'].iloc[0]\n",
    "        print(f\"âš ï¸ [æ³¨æ„] å‘ç° 'maxspeed' åŒ…å«å­—ç¬¦ (ä¾‹å¦‚: '{example_dirty}')ã€‚\")\n",
    "        print(f\"   -> è¿™å°†åœ¨ä¸‹ä¸€æ­¥ã€å­—æ®µæ¸…æ´—ã€‘ä¸­å¤„ç†ã€‚\")\n",
    "    \n",
    "    print(\"\\n=== æ­¥éª¤ 1 å®Œæˆ: æ•°æ®æºå·²é”å®šä¸”åŸºç¡€è´¨é‡åˆæ ¼ ===\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nâŒ [é”™è¯¯] æ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚\\nè¯¦ç»†ä¿¡æ¯: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ [é”™è¯¯] å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7941099-91f1-4c8b-9371-5847a1a1d6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æ­£åœ¨è¯»å–æ•°æ® ===\n",
      "âœ… æ•°æ®è¯»å–å®Œæˆï¼Œæ··åˆç±»å‹è­¦å‘Šå·²è§£å†³ã€‚\n",
      "\n",
      "=== é‡å¤ ID æ£€æŸ¥ç»“æœ ===\n",
      "å‘ç° 2 è¡Œæ¶‰åŠé‡å¤ IDã€‚å…·ä½“å†…å®¹å¦‚ä¸‹ï¼š\n",
      "          osmid          y          x          highway  ref  street_count  \\\n",
      "15489  37802386  39.371929 -76.711298  traffic_signals  NaN             4   \n",
      "24574  37802386  39.371929 -76.711298  traffic_signals  NaN             4   \n",
      "\n",
      "      junction railway                       geometry  \n",
      "15489      NaN     NaN  POINT (-76.7112977 39.371929)  \n",
      "24574      NaN     NaN  POINT (-76.7112977 39.371929)  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. é…ç½®è·¯å¾„\n",
    "base_path = r\"D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\"\n",
    "\n",
    "print(\"=== æ­£åœ¨è¯»å–æ•°æ® ===\")\n",
    "\n",
    "# 2. è¯»å–æ•°æ® (åŠ å…¥ low_memory=False è§£å†³ DtypeWarning æŠ¥é”™)\n",
    "nodes_df = pd.read_csv(os.path.join(base_path, 'nodes_drive.csv'))\n",
    "edges_df = pd.read_csv(os.path.join(base_path, 'edges_drive.csv'), low_memory=False)\n",
    "\n",
    "print(\"âœ… æ•°æ®è¯»å–å®Œæˆï¼Œæ··åˆç±»å‹è­¦å‘Šå·²è§£å†³ã€‚\")\n",
    "\n",
    "# 3. æ‰¾å‡ºæ‰€æœ‰é‡å¤çš„ ID\n",
    "# keep=False è¡¨ç¤ºæŠŠæ‰€æœ‰é‡å¤çš„æ¡ç›®éƒ½åˆ—å‡ºæ¥ï¼Œæ–¹ä¾¿å¯¹æ¯”\n",
    "dup_mask = nodes_df.duplicated(subset=['osmid'], keep=False)\n",
    "duplicate_rows = nodes_df[dup_mask]\n",
    "\n",
    "print(f\"\\n=== é‡å¤ ID æ£€æŸ¥ç»“æœ ===\")\n",
    "if not duplicate_rows.empty:\n",
    "    print(f\"å‘ç° {len(duplicate_rows)} è¡Œæ¶‰åŠé‡å¤ IDã€‚å…·ä½“å†…å®¹å¦‚ä¸‹ï¼š\")\n",
    "    # æ‰“å°å‡ºæ¥ä¾›ä½ å†³ç­–\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    print(\"æœªå‘ç°é‡å¤çš„ osmidã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df93e34c-9682-41df-874f-51ecee056e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ ç´¢å¼• 24574 ä¸å­˜åœ¨ï¼ˆå¯èƒ½å·²è¢«å‰”é™¤ï¼‰ã€‚\n",
      "ğŸ’¾ æ•°æ®å·²æˆåŠŸè¦†ç›–ä¿å­˜è‡³: D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\\nodes_drive.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. è¿™é‡Œè¡¥ä¸Šè·¯å¾„ï¼ˆå¿…é¡»æœ‰è¿™ä¸€æ­¥ï¼‰\n",
    "base_path = r\"D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\"\n",
    "file_path = os.path.join(base_path, 'nodes_drive.csv') \n",
    "\n",
    "# 2. è¿™é‡Œçš„å˜é‡åè¦æ˜¯ nodes_df (å¯¹åº”æ‚¨ Cell 2 è¯»å‡ºæ¥çš„åå­—)\n",
    "if 24574 in nodes_df.index:\n",
    "    nodes_df.drop(index=24574, inplace=True) # è¿™é‡Œæ”¹ nodes_df\n",
    "    print(\"âœ… å·²æˆåŠŸä»å†…å­˜ä¸­å‰”é™¤ç´¢å¼• 24574ã€‚\")\n",
    "else:\n",
    "    print(\"âš ï¸ ç´¢å¼• 24574 ä¸å­˜åœ¨ï¼ˆå¯èƒ½å·²è¢«å‰”é™¤ï¼‰ã€‚\")\n",
    "\n",
    "try:\n",
    "    # 3. è¿™é‡Œä¿å­˜ä¹Ÿè¦ç”¨ nodes_df\n",
    "    nodes_df.to_csv(file_path, index=False) \n",
    "    print(f\"ğŸ’¾ æ•°æ®å·²æˆåŠŸè¦†ç›–ä¿å­˜è‡³: {file_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ä¿å­˜å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e63e826a-09d2-470d-a937-3a800f74d423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== å¼€å§‹æ‰§è¡Œæ­¥éª¤ 1: æ•°æ®æºé”å®š ===\n",
      "æ•°æ®è·¯å¾„: D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\n",
      "\n",
      "[æˆåŠŸåŠ è½½] èŠ‚ç‚¹è¡¨: 37162 è¡Œ\n",
      "[æˆåŠŸåŠ è½½] è¾¹è¡¨:   91227 è¡Œ\n",
      "âœ… [æ ¡éªŒé€šè¿‡] èŠ‚ç‚¹ ID (osmid) å”¯ä¸€ã€‚\n",
      "âœ… [æ ¡éªŒé€šè¿‡] æ‰€æœ‰èŠ‚ç‚¹å‡åŒ…å«å®Œæ•´ç»çº¬åº¦åæ ‡ (x, y)ã€‚\n",
      "âœ… [æ ¡éªŒé€šè¿‡] æ‰€æœ‰è¾¹å‡åŒ…å«èµ·ç‚¹(u)ã€ç»ˆç‚¹(v)å’Œé•¿åº¦(length)ã€‚\n",
      "âš ï¸ [æ³¨æ„] å‘ç° 'maxspeed' åŒ…å«å­—ç¬¦ (ä¾‹å¦‚: '55 mph')ã€‚\n",
      "   -> è¿™å°†åœ¨ä¸‹ä¸€æ­¥ã€å­—æ®µæ¸…æ´—ã€‘ä¸­å¤„ç†ã€‚\n",
      "\n",
      "=== æ­¥éª¤ 1 å®Œæˆ: æ•°æ®æºå·²é”å®šä¸”åŸºç¡€è´¨é‡åˆæ ¼ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kam1\\AppData\\Local\\Temp\\ipykernel_29108\\4193017283.py:24: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  edges_df = pd.read_csv(edges_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# Step 1: æ–‡ä»¶æºé”å®šä¸åŸºç¡€è´¨æ£€ (Source Locking)\n",
    "# ==========================================\n",
    "\n",
    "# 1. é…ç½®ç»å¯¹è·¯å¾„\n",
    "base_path = r\"D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\"\n",
    "\n",
    "# 2. å®šä¹‰ç›®æ ‡æ–‡ä»¶ (åªé”å®š Drive æ•°æ®ï¼Œå‰”é™¤ Noise)\n",
    "node_file = 'nodes_drive.csv'\n",
    "edge_file = 'edges_drive.csv'\n",
    "\n",
    "print(f\"=== å¼€å§‹æ‰§è¡Œæ­¥éª¤ 1: æ•°æ®æºé”å®š ===\")\n",
    "print(f\"æ•°æ®è·¯å¾„: {base_path}\")\n",
    "\n",
    "try:\n",
    "    # 3. åŠ è½½æ•°æ®\n",
    "    nodes_path = os.path.join(base_path, node_file)\n",
    "    edges_path = os.path.join(base_path, edge_file)\n",
    "    \n",
    "    nodes_df = pd.read_csv(nodes_path)\n",
    "    edges_df = pd.read_csv(edges_path)\n",
    "    \n",
    "    print(f\"\\n[æˆåŠŸåŠ è½½] èŠ‚ç‚¹è¡¨: {len(nodes_df)} è¡Œ\")\n",
    "    print(f\"[æˆåŠŸåŠ è½½] è¾¹è¡¨:   {len(edges_df)} è¡Œ\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 4. å…³é”®ç‚¹æ ¡éªŒ (Critical Validations)\n",
    "    # ==========================================\n",
    "    \n",
    "    # Check A: èŠ‚ç‚¹ ID å”¯ä¸€æ€§ (é˜²æ­¢å›¾æ„å»ºæ—¶è¦†ç›–èŠ‚ç‚¹)\n",
    "    if nodes_df['osmid'].is_unique:\n",
    "        print(f\"âœ… [æ ¡éªŒé€šè¿‡] èŠ‚ç‚¹ ID (osmid) å”¯ä¸€ã€‚\")\n",
    "    else:\n",
    "        dup_count = nodes_df['osmid'].duplicated().sum()\n",
    "        print(f\"âŒ [è­¦å‘Š] å‘ç° {dup_count} ä¸ªé‡å¤èŠ‚ç‚¹ IDï¼è¯·æ£€æŸ¥æ•°æ®æºã€‚\")\n",
    "\n",
    "    # Check B: åæ ‡å®Œæ•´æ€§ (åç»­ KDTree åŒ¹é…å¿…é¡»)\n",
    "    missing_coords = nodes_df[['x', 'y']].isnull().sum().sum()\n",
    "    if missing_coords == 0:\n",
    "        print(f\"âœ… [æ ¡éªŒé€šè¿‡] æ‰€æœ‰èŠ‚ç‚¹å‡åŒ…å«å®Œæ•´ç»çº¬åº¦åæ ‡ (x, y)ã€‚\")\n",
    "    else:\n",
    "        print(f\"âŒ [è‡´å‘½é”™è¯¯] æœ‰ {missing_coords} ä¸ªèŠ‚ç‚¹ç¼ºå¤±åæ ‡ï¼Œæ¨¡å‹å°†æ— æ³•å»ºç«‹ç©ºé—´ç´¢å¼•ã€‚\")\n",
    "\n",
    "    # Check C: æ‹“æ‰‘å®Œæ•´æ€§ (u, v å¿…é¡»å­˜åœ¨)\n",
    "    missing_topo = edges_df[['u', 'v', 'length']].isnull().sum().sum()\n",
    "    if missing_topo == 0:\n",
    "        print(f\"âœ… [æ ¡éªŒé€šè¿‡] æ‰€æœ‰è¾¹å‡åŒ…å«èµ·ç‚¹(u)ã€ç»ˆç‚¹(v)å’Œé•¿åº¦(length)ã€‚\")\n",
    "    else:\n",
    "        print(f\"âŒ [è‡´å‘½é”™è¯¯] è¾¹è¡¨ç¼ºå¤±æ‹“æ‰‘ä¿¡æ¯ï¼Œè·¯ç½‘å·²æ–­è£‚ã€‚\")\n",
    "\n",
    "    # Check D: é¢„è­¦è„æ•°æ® (ä¸ºä¸‹ä¸€æ­¥æ¸…æ´—åšå‡†å¤‡)\n",
    "    # æ£€æŸ¥ maxspeed æ˜¯å¦åŒ…å«éæ•°å­—å­—ç¬¦ï¼ˆå¦‚ 'mph'ï¼‰\n",
    "    if edges_df['maxspeed'].dtype == 'object':\n",
    "        example_dirty = edges_df[edges_df['maxspeed'].astype(str).str.contains('mph', na=False)]['maxspeed'].iloc[0]\n",
    "        print(f\"âš ï¸ [æ³¨æ„] å‘ç° 'maxspeed' åŒ…å«å­—ç¬¦ (ä¾‹å¦‚: '{example_dirty}')ã€‚\")\n",
    "        print(f\"   -> è¿™å°†åœ¨ä¸‹ä¸€æ­¥ã€å­—æ®µæ¸…æ´—ã€‘ä¸­å¤„ç†ã€‚\")\n",
    "    \n",
    "    print(\"\\n=== æ­¥éª¤ 1 å®Œæˆ: æ•°æ®æºå·²é”å®šä¸”åŸºç¡€è´¨é‡åˆæ ¼ ===\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nâŒ [é”™è¯¯] æ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚\\nè¯¦ç»†ä¿¡æ¯: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ [é”™è¯¯] å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9798ed1e-b63d-4a61-9c27-20249a1a16d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è¯»å–æ–‡ä»¶: D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\\edges_drive.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kam1\\AppData\\Local\\Temp\\ipykernel_29108\\1465836527.py:76: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  edges_df = pd.read_csv(INPUT_FILE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨æ¸…æ´— 'maxspeed' (è½¬æ¢ä¸º m/s)...\n",
      "æ­£åœ¨æ¸…æ´— 'lanes' (å¤„ç†åˆ—è¡¨å¹¶ä¿ç•™æµ®ç‚¹æ•°)...\n",
      "\n",
      "æ¸…æ´—åæ•°æ®é¢„è§ˆ (Head 5):\n",
      "   maxspeed  lanes\n",
      "0       NaN    NaN\n",
      "1       NaN    NaN\n",
      "2       NaN    NaN\n",
      "3       NaN    NaN\n",
      "4       NaN    NaN\n",
      "\n",
      "æ¸…æ´—ç»Ÿè®¡:\n",
      "Maxspeed éç©ºæ•°é‡: 48971\n",
      "Lanes éç©ºæ•°é‡:    44467\n",
      "\n",
      "æ­£åœ¨ä¿å­˜æ–‡ä»¶è‡³: D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\\edges_drive_step2.csv ...\n",
      "âœ… æ­¥éª¤ 2 å®Œæˆ: å­—æ®µç±»å‹æ¸…æ´—å·²ä¿å­˜ã€‚\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ================= é…ç½®è·¯å¾„ =================\n",
    "# è®¾ç½®å·¥ä½œç›®å½•ä¸ºæŒ‡å®šçš„ç»å¯¹è·¯å¾„\n",
    "WORK_DIR = r\"D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\"\n",
    "\n",
    "# è¾“å…¥æ–‡ä»¶ (å‡è®¾æºæ–‡ä»¶ä¹Ÿåœ¨è¯¥ç›®å½•ä¸‹ï¼Œå¦‚æœä¸æ˜¯è¯·ä¿®æ”¹æ­¤å¤„)\n",
    "INPUT_FILE = os.path.join(WORK_DIR, \"edges_drive.csv\")\n",
    "# è¾“å‡ºæ–‡ä»¶\n",
    "OUTPUT_FILE = os.path.join(WORK_DIR, \"edges_drive_step2.csv\")\n",
    "\n",
    "# ================= æ¸…æ´—å‡½æ•°å®šä¹‰ =================\n",
    "\n",
    "def clean_maxspeed_v2(val):\n",
    "    \"\"\"\n",
    "    æ¸…æ´— maxspeed å­—æ®µ:\n",
    "    1. å»é™¤ mph å•ä½\n",
    "    2. å¤„ç†åˆ—è¡¨å­—ç¬¦ä¸² ['45', '60'] -> å–å¹³å‡å€¼\n",
    "    3. ç»Ÿä¸€è½¬æ¢ä¸º m/s (ä¹˜ä»¥ 0.44704)\n",
    "    \"\"\"\n",
    "    if pd.isna(val): return np.nan\n",
    "    \n",
    "    # è¾…åŠ©å†…éƒ¨å‡½æ•°ï¼šæå–æ•°å­—\n",
    "    def get_num(s):\n",
    "        match = re.search(r\"([0-9\\.]+)\", str(s))\n",
    "        return float(match.group(1)) if match else None\n",
    "\n",
    "    # é€»è¾‘ï¼šå¦‚æœæ˜¯åˆ—è¡¨å­—ç¬¦ä¸²ï¼Œè§£æå¹¶å–å¹³å‡ï¼›å¦åˆ™ç›´æ¥æå–\n",
    "    val_num = np.nan\n",
    "    if isinstance(val, str) and val.strip().startswith('['):\n",
    "        try:\n",
    "            val_list = ast.literal_eval(val)\n",
    "            nums = [get_num(v) for v in val_list if get_num(v) is not None]\n",
    "            val_num = np.mean(nums) if nums else np.nan\n",
    "        except: \n",
    "            val_num = np.nan\n",
    "    else:\n",
    "        val_num = get_num(val)\n",
    "        \n",
    "    # æ¢ç®— mph -> m/s (1 mph = 0.44704 m/s)\n",
    "    return val_num * 0.44704 if pd.notna(val_num) else np.nan\n",
    "\n",
    "def clean_lanes_v2(val):\n",
    "    \"\"\"\n",
    "    æ¸…æ´— lanes å­—æ®µ:\n",
    "    1. å¤„ç†åˆ—è¡¨å­—ç¬¦ä¸² ['2', '3'] -> å–å¹³å‡å€¼ (å¦‚ 2.5)\n",
    "    2. ä¿ç•™ä¸ºæµ®ç‚¹æ•°ï¼Œç”¨äºåç»­å®¹é‡è®¡ç®—\n",
    "    \"\"\"\n",
    "    if pd.isna(val): return np.nan\n",
    "    \n",
    "    def get_num(s):\n",
    "        match = re.search(r\"([0-9\\.]+)\", str(s))\n",
    "        return float(match.group(1)) if match else None\n",
    "\n",
    "    if isinstance(val, str) and val.strip().startswith('['):\n",
    "        try:\n",
    "            val_list = ast.literal_eval(val)\n",
    "            nums = [get_num(v) for v in val_list if get_num(v) is not None]\n",
    "            return np.mean(nums) if nums else np.nan\n",
    "        except: \n",
    "            return np.nan\n",
    "    else:\n",
    "        return get_num(val)\n",
    "\n",
    "# ================= ä¸»æ‰§è¡Œé€»è¾‘ =================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"æ­£åœ¨è¯»å–æ–‡ä»¶: {INPUT_FILE} ...\")\n",
    "    \n",
    "    # 1. è¯»å–æ•°æ®\n",
    "    try:\n",
    "        edges_df = pd.read_csv(INPUT_FILE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {INPUT_FILE}ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚\")\n",
    "        exit()\n",
    "\n",
    "    # 2. åº”ç”¨æ¸…æ´— (Type Cleaning)\n",
    "    print(\"æ­£åœ¨æ¸…æ´— 'maxspeed' (è½¬æ¢ä¸º m/s)...\")\n",
    "    edges_df['maxspeed'] = edges_df['maxspeed'].apply(clean_maxspeed_v2)\n",
    "\n",
    "    print(\"æ­£åœ¨æ¸…æ´— 'lanes' (å¤„ç†åˆ—è¡¨å¹¶ä¿ç•™æµ®ç‚¹æ•°)...\")\n",
    "    edges_df['lanes'] = edges_df['lanes'].apply(clean_lanes_v2)\n",
    "\n",
    "    # 3. æ£€æŸ¥ç»“æœé¢„è§ˆ\n",
    "    print(\"\\næ¸…æ´—åæ•°æ®é¢„è§ˆ (Head 5):\")\n",
    "    print(edges_df[['maxspeed', 'lanes']].head())\n",
    "    \n",
    "    print(\"\\næ¸…æ´—ç»Ÿè®¡:\")\n",
    "    print(f\"Maxspeed éç©ºæ•°é‡: {edges_df['maxspeed'].notna().sum()}\")\n",
    "    print(f\"Lanes éç©ºæ•°é‡:    {edges_df['lanes'].notna().sum()}\")\n",
    "\n",
    "    # 4. ä¿å­˜æ–‡ä»¶\n",
    "    print(f\"\\næ­£åœ¨ä¿å­˜æ–‡ä»¶è‡³: {OUTPUT_FILE} ...\")\n",
    "    edges_df.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(\"âœ… æ­¥éª¤ 2 å®Œæˆ: å­—æ®µç±»å‹æ¸…æ´—å·²ä¿å­˜ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f24a22e-679c-40aa-92ab-7691702ac2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è¯»å–æ–‡ä»¶: D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\\edges_drive_step2.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kam1\\AppData\\Local\\Temp\\ipykernel_29108\\3980590184.py:92: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  edges_df = pd.read_csv(INPUT_FILE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¡«è¡¥å‰ç¼ºå¤±å€¼ -> Maxspeed: 42256, Lanes: 46760\n",
      "æ­£åœ¨åº”ç”¨åˆ†çº§å¡«è¡¥ç­–ç•¥ (Hierarchical Imputation)...\n",
      "å¡«è¡¥åç¼ºå¤±å€¼ -> Maxspeed: 0, Lanes: 0\n",
      "æ­£åœ¨ä¿å­˜æ–‡ä»¶è‡³: D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\\edges_drive_step3.csv ...\n",
      "âœ… æ­¥éª¤ 3 å®Œæˆ: ç¼ºå¤±å€¼åˆ†çº§å¡«è¡¥å·²ä¿å­˜ã€‚\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "\n",
    "# ================= é…ç½®è·¯å¾„ =================\n",
    "# è¾“å…¥æ–‡ä»¶ (Step 2 çš„è¾“å‡º)\n",
    "INPUT_FILE = r\"D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\\edges_drive_step2.csv\"\n",
    "# è¾“å‡ºæ–‡ä»¶ (Step 3 çš„ç»“æœ)\n",
    "OUTPUT_FILE = r\"D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\\edges_drive_step3.csv\"\n",
    "\n",
    "# ================= 1. å®šä¹‰åˆ†çº§å¡«è¡¥å­—å…¸ (Hierarchical Dictionary) =================\n",
    "# å•ä½è¯´æ˜: \n",
    "# Speed: m/s (1 mph = 0.44704 m/s)\n",
    "# Lanes: float\n",
    "\n",
    "imputation_dict = {\n",
    "    # --- é«˜é€Ÿå…¬è·¯ç³»ç»Ÿ (Motorways) ---\n",
    "    'motorway':      {'speed': 29.06, 'lanes': 3.0}, # ~65 mph\n",
    "    'motorway_link': {'speed': 13.41, 'lanes': 1.0}, # ~30 mph (åŒé“å•è½¦é“)\n",
    "    \n",
    "    # --- å¿«é€Ÿè·¯ç³»ç»Ÿ (Trunk) ---\n",
    "    'trunk':         {'speed': 20.12, 'lanes': 3.0}, # ~45 mph\n",
    "    'trunk_link':    {'speed': 13.41, 'lanes': 1.0}, # ~30 mph\n",
    "    \n",
    "    # --- ä¸»å¹²é“ç³»ç»Ÿ (Primary) ---\n",
    "    'primary':       {'speed': 13.41, 'lanes': 2.0}, # ~30 mph\n",
    "    'primary_link':  {'speed': 11.18, 'lanes': 1.0}, # ~25 mph\n",
    "    \n",
    "    # --- æ¬¡å¹²é“ç³»ç»Ÿ (Secondary) ---\n",
    "    'secondary':     {'speed': 13.41, 'lanes': 2.0}, # ~30 mph\n",
    "    'secondary_link':{'speed': 11.18, 'lanes': 1.0}, # ~25 mph\n",
    "    \n",
    "    # --- æ”¯è·¯ç³»ç»Ÿ (Tertiary) ---\n",
    "    'tertiary':      {'speed': 11.18, 'lanes': 2.0}, # ~25 mph\n",
    "    'tertiary_link': {'speed': 11.18, 'lanes': 1.0}, # ~25 mph\n",
    "    \n",
    "    # --- å±…ä½åŒºä¸ä½é€Ÿé“è·¯ ---\n",
    "    'residential':   {'speed': 8.94,  'lanes': 1.0}, # ~20 mph (ä¿å®ˆç­–ç•¥:é˜²æ­¢è¿‡å¢ƒç©¿æ’)\n",
    "    'living_street': {'speed': 6.71,  'lanes': 1.0}, # ~15 mph\n",
    "    'unclassified':  {'speed': 8.94,  'lanes': 1.0}, # ~20 mph\n",
    "    'service':       {'speed': 6.71,  'lanes': 1.0}  # ~15 mph (æœåŠ¡é“è·¯)\n",
    "}\n",
    "\n",
    "# --- å…¨å±€å…œåº•ç­–ç•¥ (Fallback) ---\n",
    "# å½“ highway ç±»å‹ä¸åœ¨å­—å…¸ä¸­æ—¶ä½¿ç”¨ (å¦‚ 'busway', 'path' ç­‰)\n",
    "GLOBAL_DEFAULT = {'speed': 8.94, 'lanes': 1.0} # ~20 mph, 1 lane\n",
    "\n",
    "# ================= 2. æ ¸å¿ƒå¡«è¡¥å‡½æ•° =================\n",
    "\n",
    "def fill_missing_values(row):\n",
    "    \"\"\"\n",
    "    å¯¹æ¯ä¸€è¡Œåº”ç”¨åˆ†çº§å¡«è¡¥é€»è¾‘\n",
    "    \"\"\"\n",
    "    # --- A. è·å–å¹¶æ¸…æ´— highway ç±»å‹ ---\n",
    "    hw_raw = row['highway']\n",
    "    \n",
    "    # å¦‚æœæ˜¯åˆ—è¡¨å­—ç¬¦ä¸² \"['primary', 'residential']\"ï¼Œå–ç¬¬ä¸€ä¸ª\n",
    "    if isinstance(hw_raw, str) and hw_raw.strip().startswith('['):\n",
    "        try:\n",
    "            hw_list = ast.literal_eval(hw_raw)\n",
    "            hw_type = hw_list[0] if hw_list else 'unclassified'\n",
    "        except:\n",
    "            hw_type = 'unclassified'\n",
    "    else:\n",
    "        hw_type = str(hw_raw)\n",
    "        \n",
    "    # --- B. æŸ¥å­—å…¸è·å–é»˜è®¤å€¼ ---\n",
    "    defaults = imputation_dict.get(hw_type, GLOBAL_DEFAULT)\n",
    "    \n",
    "    # --- C. å¡«è¡¥ maxspeed ---\n",
    "    speed = row['maxspeed']\n",
    "    if pd.isna(speed):\n",
    "        speed = defaults['speed']\n",
    "        \n",
    "    # --- D. å¡«è¡¥ lanes ---\n",
    "    lanes = row['lanes']\n",
    "    if pd.isna(lanes):\n",
    "        lanes = defaults['lanes']\n",
    "        \n",
    "    return speed, lanes\n",
    "\n",
    "# ================= 3. ä¸»æ‰§è¡Œé€»è¾‘ =================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"æ­£åœ¨è¯»å–æ–‡ä»¶: {INPUT_FILE} ...\")\n",
    "    \n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {INPUT_FILE}ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚\")\n",
    "    else:\n",
    "        # è¯»å–æ•°æ®\n",
    "        edges_df = pd.read_csv(INPUT_FILE)\n",
    "        \n",
    "        # ç»Ÿè®¡å¡«è¡¥å‰çš„ç¼ºå¤±æƒ…å†µ\n",
    "        missing_speed_before = edges_df['maxspeed'].isna().sum()\n",
    "        missing_lanes_before = edges_df['lanes'].isna().sum()\n",
    "        print(f\"å¡«è¡¥å‰ç¼ºå¤±å€¼ -> Maxspeed: {missing_speed_before}, Lanes: {missing_lanes_before}\")\n",
    "        \n",
    "        # æ‰§è¡Œå¡«è¡¥\n",
    "        print(\"æ­£åœ¨åº”ç”¨åˆ†çº§å¡«è¡¥ç­–ç•¥ (Hierarchical Imputation)...\")\n",
    "        # ä½¿ç”¨ apply è·å–å¡«è¡¥åçš„ä¸¤åˆ—æ•°æ®\n",
    "        filled_data = edges_df.apply(fill_missing_values, axis=1, result_type='expand')\n",
    "        \n",
    "        # å°†ç»“æœèµ‹å€¼å›åŸ DataFrame\n",
    "        edges_df['maxspeed'] = filled_data[0]\n",
    "        edges_df['lanes'] = filled_data[1]\n",
    "        \n",
    "        # ç»Ÿè®¡å¡«è¡¥åçš„ç¼ºå¤±æƒ…å†µ (ç†è®ºä¸Šåº”ä¸º 0)\n",
    "        missing_speed_after = edges_df['maxspeed'].isna().sum()\n",
    "        missing_lanes_after = edges_df['lanes'].isna().sum()\n",
    "        print(f\"å¡«è¡¥åç¼ºå¤±å€¼ -> Maxspeed: {missing_speed_after}, Lanes: {missing_lanes_after}\")\n",
    "        \n",
    "        # å¦‚æœä»æœ‰ NaN (æå°‘è§æƒ…å†µ), å¼ºåˆ¶ä½¿ç”¨å…¨å±€å…œåº•\n",
    "        if missing_speed_after > 0:\n",
    "            print(\"âš ï¸ è­¦å‘Š: ä»æœ‰ maxspeed ç¼ºå¤±ï¼Œå¼ºåˆ¶åº”ç”¨å…¨å±€å…œåº•...\")\n",
    "            edges_df['maxspeed'] = edges_df['maxspeed'].fillna(GLOBAL_DEFAULT['speed'])\n",
    "            \n",
    "        if missing_lanes_after > 0:\n",
    "            print(\"âš ï¸ è­¦å‘Š: ä»æœ‰ lanes ç¼ºå¤±ï¼Œå¼ºåˆ¶åº”ç”¨å…¨å±€å…œåº•...\")\n",
    "            edges_df['lanes'] = edges_df['lanes'].fillna(GLOBAL_DEFAULT['lanes'])\n",
    "\n",
    "        # ä¿å­˜æ–‡ä»¶\n",
    "        print(f\"æ­£åœ¨ä¿å­˜æ–‡ä»¶è‡³: {OUTPUT_FILE} ...\")\n",
    "        edges_df.to_csv(OUTPUT_FILE, index=False)\n",
    "        print(\"âœ… æ­¥éª¤ 3 å®Œæˆ: ç¼ºå¤±å€¼åˆ†çº§å¡«è¡¥å·²ä¿å­˜ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df7ccf81-adaa-456e-b091-d1b7fb2a03cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ–‡ä»¶è¯»å–æˆåŠŸã€‚\n",
      "æ•°æ®æ€»è¡Œæ•°: 91227\n",
      "------------------------------\n",
      "onewayåˆ—ä¸­å‡ºç°çš„æ‰€æœ‰å”¯ä¸€å†…å®¹å¦‚ä¸‹ï¼š\n",
      "------------------------------\n",
      "False\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kam1\\AppData\\Local\\Temp\\ipykernel_29108\\3381970734.py:9: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# è®¾ç½®æ–‡ä»¶çš„ç»å¯¹è·¯å¾„\n",
    "file_path = r\"D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\\edges_drive_step3.csv\"\n",
    "\n",
    "try:\n",
    "    # è¯»å–CSVæ–‡ä»¶\n",
    "    # ç”±äºä¸ç¡®å®šæ–‡ä»¶ç¼–ç ï¼Œé»˜è®¤å°è¯•utf-8ï¼Œå¦‚æœæŠ¥é”™å¯ä»¥å°è¯• encoding='gbk'\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ 'oneway' åˆ—\n",
    "    if 'oneway' in df.columns:\n",
    "        # è·å– 'oneway' åˆ—çš„æ‰€æœ‰å”¯ä¸€å€¼\n",
    "        unique_values = df['oneway'].unique()\n",
    "        \n",
    "        print(f\"æ–‡ä»¶è¯»å–æˆåŠŸã€‚\")\n",
    "        print(f\"æ•°æ®æ€»è¡Œæ•°: {len(df)}\")\n",
    "        print(\"-\" * 30)\n",
    "        print(\"onewayåˆ—ä¸­å‡ºç°çš„æ‰€æœ‰å”¯ä¸€å†…å®¹å¦‚ä¸‹ï¼š\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # é€ä¸ªæ‰“å°å”¯ä¸€å€¼ï¼Œæ–¹ä¾¿æŸ¥çœ‹\n",
    "        for val in unique_values:\n",
    "            print(val)\n",
    "            # å¦‚æœæƒ³çœ‹è¯¥å€¼çš„å…·ä½“ç±»å‹ï¼ˆæ˜¯å­—ç¬¦ä¸²è¿˜æ˜¯å¸ƒå°”å€¼ï¼‰ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢æ³¨é‡Š\n",
    "            # print(f\"å€¼: {val}, ç±»å‹: {type(val)}\")\n",
    "            \n",
    "    else:\n",
    "        print(\"é”™è¯¯ï¼šæ•°æ®é›†ä¸­æœªæ‰¾åˆ°åä¸º 'oneway' çš„åˆ—ï¼Œè¯·æ£€æŸ¥åˆ—åã€‚\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œè¯·ç¡®è®¤è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼š\\n{file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df0e9ab-35a4-4be1-82b7-d7b1de73de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# 1. è®¾ç½®æ–‡ä»¶è·¯å¾„\n",
    "input_path = r\"D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\\edges_drive_step3.csv\"\n",
    "# æ‚¨å¯ä»¥æŒ‡å®šä¸€ä¸ªè¾“å‡ºè·¯å¾„ï¼Œæˆ–è€…æš‚æ—¶ä¸ä¿å­˜ï¼Œåªçœ‹ç»“æœ\n",
    "output_path = r\"D:\\PyCode\\è®ºæ–‡å¤ç°ä¸æ”¹è¿›\\2025-D\\2507692\\è®ºæ–‡å¤ç°ä¸ä¼˜åŒ–\\2025_Problem_D_Data\\edges_drive_step4.csv\"\n",
    "\n",
    "def reverse_linestring(wkt_string):\n",
    "    \"\"\"\n",
    "    ç¿»è½¬ LINESTRING çš„åæ ‡åºåˆ—ã€‚\n",
    "    è¾“å…¥ç¤ºä¾‹: \"LINESTRING (116.3 39.9, 116.4 40.0)\"\n",
    "    è¾“å‡ºç¤ºä¾‹: \"LINESTRING (116.4 40.0, 116.3 39.9)\"\n",
    "    \"\"\"\n",
    "    if pd.isna(wkt_string) or not isinstance(wkt_string, str):\n",
    "        return wkt_string\n",
    "    \n",
    "    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ‹¬å·å†…çš„å†…å®¹\n",
    "    match = re.search(r'LINESTRING\\s*\\((.*)\\)', wkt_string)\n",
    "    if match:\n",
    "        coords_str = match.group(1)\n",
    "        # æŒ‰é€—å·åˆ†å‰²åæ ‡ç‚¹\n",
    "        points = coords_str.split(',')\n",
    "        # ç¿»è½¬åˆ—è¡¨\n",
    "        reversed_points = points[::-1]\n",
    "        # é‡æ–°ç»„åˆ\n",
    "        return f\"LINESTRING ({','.join(reversed_points)})\"\n",
    "    return wkt_string\n",
    "\n",
    "try:\n",
    "    print(f\"æ­£åœ¨è¯»å–æ–‡ä»¶: {input_path}\")\n",
    "    df = pd.read_csv(input_path)\n",
    "    \n",
    "    print(f\"åŸå§‹è¡Œæ•°: {len(df)}\")\n",
    "    \n",
    "    # 2. ç¡®ä¿ oneway åˆ—æ˜¯å¸ƒå°”ç±»å‹ (é˜²æ­¢è¯»å–ä¸ºå­—ç¬¦ä¸² 'True'/'False')\n",
    "    # å¦‚æœè¯»å–å·²ç»æ˜¯boolåˆ™æ— å½±å“ï¼Œå¦‚æœæ˜¯å­—ç¬¦ä¸²åˆ™è½¬æ¢\n",
    "    if df['oneway'].dtype == 'object':\n",
    "        df['oneway'] = df['oneway'].map({'True': True, 'False': False, True: True, False: False})\n",
    "        \n",
    "    # 3. ç­›é€‰å‡ºéœ€è¦ç”Ÿæˆåå‘è¾¹çš„è¡Œ (oneway == False)\n",
    "    # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ oneway=True çš„æ˜¯å•è¡Œé“ï¼Œä¸éœ€è¦åå‘ï¼›oneway=False æ˜¯åŒå‘é“ï¼Œéœ€è¦ç”Ÿæˆåå‘è¾¹\n",
    "    bidirectional_edges = df[df['oneway'] == False].copy()\n",
    "    \n",
    "    print(f\"æ£€æµ‹åˆ°åŒå‘é“è·¯ (oneway=False) è¡Œæ•°: {len(bidirectional_edges)}\")\n",
    "    \n",
    "    if len(bidirectional_edges) > 0:\n",
    "        # 4. æ„å»ºåå‘è¾¹\n",
    "        # 4.1 äº¤æ¢èµ·ç‚¹å’Œç»ˆç‚¹ (u, v) -> (v, u)\n",
    "        bidirectional_edges = bidirectional_edges.rename(columns={'u': 'v_new', 'v': 'u_new'})\n",
    "        bidirectional_edges = bidirectional_edges.rename(columns={'v_new': 'v', 'u_new': 'u'})\n",
    "        \n",
    "        # 4.2 å‡ ä½•ç¿»è½¬ (è°ƒç”¨å‡½æ•°)\n",
    "        print(\"æ­£åœ¨è¿›è¡Œå‡ ä½•ç¿»è½¬ (Geometry Flip)...\")\n",
    "        if 'geometry' in bidirectional_edges.columns:\n",
    "            bidirectional_edges['geometry'] = bidirectional_edges['geometry'].apply(reverse_linestring)\n",
    "        \n",
    "        # 4.3 åˆå¹¶æ•°æ®\n",
    "        # åŸå§‹æ•°æ® + æ–°ç”Ÿæˆçš„åå‘æ•°æ®\n",
    "        df_expanded = pd.concat([df, bidirectional_edges], ignore_index=True)\n",
    "        \n",
    "        print(\"-\" * 30)\n",
    "        print(\"å¤„ç†å®Œæˆ\")\n",
    "        print(f\"æ‰©å……åæ€»è¡Œæ•°: {len(df_expanded)}\")\n",
    "        print(f\"ç†è®ºå¢åŠ è¡Œæ•°: {len(bidirectional_edges)}\")\n",
    "        print(f\"å®é™…å¢åŠ è¡Œæ•°: {len(df_expanded) - len(df)}\")\n",
    "        \n",
    "        # 5. æ£€æŸ¥é‡å¤ (Check B)\n",
    "        # æœ‰æ—¶å€™åŸå§‹æ•°æ®å¯èƒ½å·²ç»åŒ…å«äº†åŒå‘çš„ä¸¤æ¡è®°å½•(keyä¸åŒ)ï¼Œè¿™é‡Œç®€å•æ£€æŸ¥ä¸€ä¸‹ u, v, key æ˜¯å¦æœ‰å®Œå…¨é‡å¤çš„\n",
    "        # è¿™é‡Œå‡è®¾ 'key' åˆ—å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å¯ä»¥ä½¿ç”¨ u, v åˆ¤æ–­\n",
    "        if 'key' in df_expanded.columns:\n",
    "            # å¦‚æœæ˜¯osmnxæ•°æ®ï¼Œé€šå¸¸key=0ã€‚ç”Ÿæˆçš„åå‘è¾¹keyä¹Ÿä¸º0å¯èƒ½ä¼šå¯¼è‡´å¤šé‡è¾¹ç´¢å¼•å†²çª\n",
    "            # è¿™é‡Œçš„å¤„ç†å–å†³äºåç»­æ˜¯å¦ä½¿ç”¨ MultiGraphã€‚\n",
    "            # ç®€å•çš„å»é‡æ£€æŸ¥ï¼š\n",
    "            duplicates = df_expanded.duplicated(subset=['u', 'v'], keep='first').sum()\n",
    "            print(f\"u, v å®Œå…¨é‡å¤çš„è¾¹æ•°é‡ (å¯èƒ½åŒ…å«åŸæœ¬å°±å­˜åœ¨çš„å¤šé‡è¾¹): {duplicates}\")\n",
    "        \n",
    "        # 6. (å¯é€‰) ä¿å­˜ç»“æœ\n",
    "        # df_expanded.to_csv(output_path, index=False)\n",
    "        # print(f\"ç»“æœå·²ä¿å­˜è‡³: {output_path}\")\n",
    "        \n",
    "        # æ‰“å°å‰å‡ è¡ŒæŸ¥çœ‹åå‘è¾¹æ•ˆæœ\n",
    "        print(\"\\nåå‘è¾¹ç¤ºä¾‹ (å‰3æ¡):\")\n",
    "        print(bidirectional_edges[['u', 'v', 'oneway', 'geometry']].head(3))\n",
    "        \n",
    "    else:\n",
    "        print(\"æœªæ£€æµ‹åˆ° oneway=False çš„æ•°æ®ï¼Œæœªè¿›è¡Œæ‰©å……ã€‚\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"å‘ç”Ÿé”™è¯¯: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
