{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "736942aa-7288-466e-aeda-7985ca746bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 开始执行步骤 1: 数据源锁定 ===\n",
      "数据路径: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\n",
      "\n",
      "[成功加载] 节点表: 37163 行\n",
      "[成功加载] 边表:   91227 行\n",
      "❌ [警告] 发现 1 个重复节点 ID！请检查数据源。\n",
      "✅ [校验通过] 所有节点均包含完整经纬度坐标 (x, y)。\n",
      "✅ [校验通过] 所有边均包含起点(u)、终点(v)和长度(length)。\n",
      "⚠️ [注意] 发现 'maxspeed' 包含字符 (例如: '55 mph')。\n",
      "   -> 这将在下一步【字段清洗】中处理。\n",
      "\n",
      "=== 步骤 1 完成: 数据源已锁定且基础质量合格 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kam1\\AppData\\Local\\Temp\\ipykernel_29108\\4193017283.py:24: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  edges_df = pd.read_csv(edges_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# Step 1: 文件源锁定与基础质检 (Source Locking)\n",
    "# ==========================================\n",
    "\n",
    "# 1. 配置绝对路径\n",
    "base_path = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\"\n",
    "\n",
    "# 2. 定义目标文件 (只锁定 Drive 数据，剔除 Noise)\n",
    "node_file = 'nodes_drive.csv'\n",
    "edge_file = 'edges_drive.csv'\n",
    "\n",
    "print(f\"=== 开始执行步骤 1: 数据源锁定 ===\")\n",
    "print(f\"数据路径: {base_path}\")\n",
    "\n",
    "try:\n",
    "    # 3. 加载数据\n",
    "    nodes_path = os.path.join(base_path, node_file)\n",
    "    edges_path = os.path.join(base_path, edge_file)\n",
    "    \n",
    "    nodes_df = pd.read_csv(nodes_path)\n",
    "    edges_df = pd.read_csv(edges_path)\n",
    "    \n",
    "    print(f\"\\n[成功加载] 节点表: {len(nodes_df)} 行\")\n",
    "    print(f\"[成功加载] 边表:   {len(edges_df)} 行\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 4. 关键点校验 (Critical Validations)\n",
    "    # ==========================================\n",
    "    \n",
    "    # Check A: 节点 ID 唯一性 (防止图构建时覆盖节点)\n",
    "    if nodes_df['osmid'].is_unique:\n",
    "        print(f\"✅ [校验通过] 节点 ID (osmid) 唯一。\")\n",
    "    else:\n",
    "        dup_count = nodes_df['osmid'].duplicated().sum()\n",
    "        print(f\"❌ [警告] 发现 {dup_count} 个重复节点 ID！请检查数据源。\")\n",
    "\n",
    "    # Check B: 坐标完整性 (后续 KDTree 匹配必须)\n",
    "    missing_coords = nodes_df[['x', 'y']].isnull().sum().sum()\n",
    "    if missing_coords == 0:\n",
    "        print(f\"✅ [校验通过] 所有节点均包含完整经纬度坐标 (x, y)。\")\n",
    "    else:\n",
    "        print(f\"❌ [致命错误] 有 {missing_coords} 个节点缺失坐标，模型将无法建立空间索引。\")\n",
    "\n",
    "    # Check C: 拓扑完整性 (u, v 必须存在)\n",
    "    missing_topo = edges_df[['u', 'v', 'length']].isnull().sum().sum()\n",
    "    if missing_topo == 0:\n",
    "        print(f\"✅ [校验通过] 所有边均包含起点(u)、终点(v)和长度(length)。\")\n",
    "    else:\n",
    "        print(f\"❌ [致命错误] 边表缺失拓扑信息，路网已断裂。\")\n",
    "\n",
    "    # Check D: 预警脏数据 (为下一步清洗做准备)\n",
    "    # 检查 maxspeed 是否包含非数字字符（如 'mph'）\n",
    "    if edges_df['maxspeed'].dtype == 'object':\n",
    "        example_dirty = edges_df[edges_df['maxspeed'].astype(str).str.contains('mph', na=False)]['maxspeed'].iloc[0]\n",
    "        print(f\"⚠️ [注意] 发现 'maxspeed' 包含字符 (例如: '{example_dirty}')。\")\n",
    "        print(f\"   -> 这将在下一步【字段清洗】中处理。\")\n",
    "    \n",
    "    print(\"\\n=== 步骤 1 完成: 数据源已锁定且基础质量合格 ===\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n❌ [错误] 找不到文件，请检查路径是否正确。\\n详细信息: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ [错误] 发生未预期的错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7941099-91f1-4c8b-9371-5847a1a1d6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 正在读取数据 ===\n",
      "✅ 数据读取完成，混合类型警告已解决。\n",
      "\n",
      "=== 重复 ID 检查结果 ===\n",
      "发现 2 行涉及重复 ID。具体内容如下：\n",
      "          osmid          y          x          highway  ref  street_count  \\\n",
      "15489  37802386  39.371929 -76.711298  traffic_signals  NaN             4   \n",
      "24574  37802386  39.371929 -76.711298  traffic_signals  NaN             4   \n",
      "\n",
      "      junction railway                       geometry  \n",
      "15489      NaN     NaN  POINT (-76.7112977 39.371929)  \n",
      "24574      NaN     NaN  POINT (-76.7112977 39.371929)  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. 配置路径\n",
    "base_path = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\"\n",
    "\n",
    "print(\"=== 正在读取数据 ===\")\n",
    "\n",
    "# 2. 读取数据 (加入 low_memory=False 解决 DtypeWarning 报错)\n",
    "nodes_df = pd.read_csv(os.path.join(base_path, 'nodes_drive.csv'))\n",
    "edges_df = pd.read_csv(os.path.join(base_path, 'edges_drive.csv'), low_memory=False)\n",
    "\n",
    "print(\"✅ 数据读取完成，混合类型警告已解决。\")\n",
    "\n",
    "# 3. 找出所有重复的 ID\n",
    "# keep=False 表示把所有重复的条目都列出来，方便对比\n",
    "dup_mask = nodes_df.duplicated(subset=['osmid'], keep=False)\n",
    "duplicate_rows = nodes_df[dup_mask]\n",
    "\n",
    "print(f\"\\n=== 重复 ID 检查结果 ===\")\n",
    "if not duplicate_rows.empty:\n",
    "    print(f\"发现 {len(duplicate_rows)} 行涉及重复 ID。具体内容如下：\")\n",
    "    # 打印出来供你决策\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    print(\"未发现重复的 osmid。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df93e34c-9682-41df-874f-51ecee056e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 索引 24574 不存在（可能已被剔除）。\n",
      "💾 数据已成功覆盖保存至: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\nodes_drive.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. 这里补上路径（必须有这一步）\n",
    "base_path = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\"\n",
    "file_path = os.path.join(base_path, 'nodes_drive.csv') \n",
    "\n",
    "# 2. 这里的变量名要是 nodes_df (对应您 Cell 2 读出来的名字)\n",
    "if 24574 in nodes_df.index:\n",
    "    nodes_df.drop(index=24574, inplace=True) # 这里改 nodes_df\n",
    "    print(\"✅ 已成功从内存中剔除索引 24574。\")\n",
    "else:\n",
    "    print(\"⚠️ 索引 24574 不存在（可能已被剔除）。\")\n",
    "\n",
    "try:\n",
    "    # 3. 这里保存也要用 nodes_df\n",
    "    nodes_df.to_csv(file_path, index=False) \n",
    "    print(f\"💾 数据已成功覆盖保存至: {file_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 保存失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e63e826a-09d2-470d-a937-3a800f74d423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 开始执行步骤 1: 数据源锁定 ===\n",
      "数据路径: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\n",
      "\n",
      "[成功加载] 节点表: 37162 行\n",
      "[成功加载] 边表:   91227 行\n",
      "✅ [校验通过] 节点 ID (osmid) 唯一。\n",
      "✅ [校验通过] 所有节点均包含完整经纬度坐标 (x, y)。\n",
      "✅ [校验通过] 所有边均包含起点(u)、终点(v)和长度(length)。\n",
      "⚠️ [注意] 发现 'maxspeed' 包含字符 (例如: '55 mph')。\n",
      "   -> 这将在下一步【字段清洗】中处理。\n",
      "\n",
      "=== 步骤 1 完成: 数据源已锁定且基础质量合格 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kam1\\AppData\\Local\\Temp\\ipykernel_29108\\4193017283.py:24: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  edges_df = pd.read_csv(edges_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# Step 1: 文件源锁定与基础质检 (Source Locking)\n",
    "# ==========================================\n",
    "\n",
    "# 1. 配置绝对路径\n",
    "base_path = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\"\n",
    "\n",
    "# 2. 定义目标文件 (只锁定 Drive 数据，剔除 Noise)\n",
    "node_file = 'nodes_drive.csv'\n",
    "edge_file = 'edges_drive.csv'\n",
    "\n",
    "print(f\"=== 开始执行步骤 1: 数据源锁定 ===\")\n",
    "print(f\"数据路径: {base_path}\")\n",
    "\n",
    "try:\n",
    "    # 3. 加载数据\n",
    "    nodes_path = os.path.join(base_path, node_file)\n",
    "    edges_path = os.path.join(base_path, edge_file)\n",
    "    \n",
    "    nodes_df = pd.read_csv(nodes_path)\n",
    "    edges_df = pd.read_csv(edges_path)\n",
    "    \n",
    "    print(f\"\\n[成功加载] 节点表: {len(nodes_df)} 行\")\n",
    "    print(f\"[成功加载] 边表:   {len(edges_df)} 行\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 4. 关键点校验 (Critical Validations)\n",
    "    # ==========================================\n",
    "    \n",
    "    # Check A: 节点 ID 唯一性 (防止图构建时覆盖节点)\n",
    "    if nodes_df['osmid'].is_unique:\n",
    "        print(f\"✅ [校验通过] 节点 ID (osmid) 唯一。\")\n",
    "    else:\n",
    "        dup_count = nodes_df['osmid'].duplicated().sum()\n",
    "        print(f\"❌ [警告] 发现 {dup_count} 个重复节点 ID！请检查数据源。\")\n",
    "\n",
    "    # Check B: 坐标完整性 (后续 KDTree 匹配必须)\n",
    "    missing_coords = nodes_df[['x', 'y']].isnull().sum().sum()\n",
    "    if missing_coords == 0:\n",
    "        print(f\"✅ [校验通过] 所有节点均包含完整经纬度坐标 (x, y)。\")\n",
    "    else:\n",
    "        print(f\"❌ [致命错误] 有 {missing_coords} 个节点缺失坐标，模型将无法建立空间索引。\")\n",
    "\n",
    "    # Check C: 拓扑完整性 (u, v 必须存在)\n",
    "    missing_topo = edges_df[['u', 'v', 'length']].isnull().sum().sum()\n",
    "    if missing_topo == 0:\n",
    "        print(f\"✅ [校验通过] 所有边均包含起点(u)、终点(v)和长度(length)。\")\n",
    "    else:\n",
    "        print(f\"❌ [致命错误] 边表缺失拓扑信息，路网已断裂。\")\n",
    "\n",
    "    # Check D: 预警脏数据 (为下一步清洗做准备)\n",
    "    # 检查 maxspeed 是否包含非数字字符（如 'mph'）\n",
    "    if edges_df['maxspeed'].dtype == 'object':\n",
    "        example_dirty = edges_df[edges_df['maxspeed'].astype(str).str.contains('mph', na=False)]['maxspeed'].iloc[0]\n",
    "        print(f\"⚠️ [注意] 发现 'maxspeed' 包含字符 (例如: '{example_dirty}')。\")\n",
    "        print(f\"   -> 这将在下一步【字段清洗】中处理。\")\n",
    "    \n",
    "    print(\"\\n=== 步骤 1 完成: 数据源已锁定且基础质量合格 ===\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n❌ [错误] 找不到文件，请检查路径是否正确。\\n详细信息: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ [错误] 发生未预期的错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9798ed1e-b63d-4a61-9c27-20249a1a16d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取文件: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kam1\\AppData\\Local\\Temp\\ipykernel_29108\\1465836527.py:76: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  edges_df = pd.read_csv(INPUT_FILE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在清洗 'maxspeed' (转换为 m/s)...\n",
      "正在清洗 'lanes' (处理列表并保留浮点数)...\n",
      "\n",
      "清洗后数据预览 (Head 5):\n",
      "   maxspeed  lanes\n",
      "0       NaN    NaN\n",
      "1       NaN    NaN\n",
      "2       NaN    NaN\n",
      "3       NaN    NaN\n",
      "4       NaN    NaN\n",
      "\n",
      "清洗统计:\n",
      "Maxspeed 非空数量: 48971\n",
      "Lanes 非空数量:    44467\n",
      "\n",
      "正在保存文件至: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step2.csv ...\n",
      "✅ 步骤 2 完成: 字段类型清洗已保存。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ================= 配置路径 =================\n",
    "# 设置工作目录为指定的绝对路径\n",
    "WORK_DIR = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\"\n",
    "\n",
    "# 输入文件 (假设源文件也在该目录下，如果不是请修改此处)\n",
    "INPUT_FILE = os.path.join(WORK_DIR, \"edges_drive.csv\")\n",
    "# 输出文件\n",
    "OUTPUT_FILE = os.path.join(WORK_DIR, \"edges_drive_step2.csv\")\n",
    "\n",
    "# ================= 清洗函数定义 =================\n",
    "\n",
    "def clean_maxspeed_v2(val):\n",
    "    \"\"\"\n",
    "    清洗 maxspeed 字段:\n",
    "    1. 去除 mph 单位\n",
    "    2. 处理列表字符串 ['45', '60'] -> 取平均值\n",
    "    3. 统一转换为 m/s (乘以 0.44704)\n",
    "    \"\"\"\n",
    "    if pd.isna(val): return np.nan\n",
    "    \n",
    "    # 辅助内部函数：提取数字\n",
    "    def get_num(s):\n",
    "        match = re.search(r\"([0-9\\.]+)\", str(s))\n",
    "        return float(match.group(1)) if match else None\n",
    "\n",
    "    # 逻辑：如果是列表字符串，解析并取平均；否则直接提取\n",
    "    val_num = np.nan\n",
    "    if isinstance(val, str) and val.strip().startswith('['):\n",
    "        try:\n",
    "            val_list = ast.literal_eval(val)\n",
    "            nums = [get_num(v) for v in val_list if get_num(v) is not None]\n",
    "            val_num = np.mean(nums) if nums else np.nan\n",
    "        except: \n",
    "            val_num = np.nan\n",
    "    else:\n",
    "        val_num = get_num(val)\n",
    "        \n",
    "    # 换算 mph -> m/s (1 mph = 0.44704 m/s)\n",
    "    return val_num * 0.44704 if pd.notna(val_num) else np.nan\n",
    "\n",
    "def clean_lanes_v2(val):\n",
    "    \"\"\"\n",
    "    清洗 lanes 字段:\n",
    "    1. 处理列表字符串 ['2', '3'] -> 取平均值 (如 2.5)\n",
    "    2. 保留为浮点数，用于后续容量计算\n",
    "    \"\"\"\n",
    "    if pd.isna(val): return np.nan\n",
    "    \n",
    "    def get_num(s):\n",
    "        match = re.search(r\"([0-9\\.]+)\", str(s))\n",
    "        return float(match.group(1)) if match else None\n",
    "\n",
    "    if isinstance(val, str) and val.strip().startswith('['):\n",
    "        try:\n",
    "            val_list = ast.literal_eval(val)\n",
    "            nums = [get_num(v) for v in val_list if get_num(v) is not None]\n",
    "            return np.mean(nums) if nums else np.nan\n",
    "        except: \n",
    "            return np.nan\n",
    "    else:\n",
    "        return get_num(val)\n",
    "\n",
    "# ================= 主执行逻辑 =================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"正在读取文件: {INPUT_FILE} ...\")\n",
    "    \n",
    "    # 1. 读取数据\n",
    "    try:\n",
    "        edges_df = pd.read_csv(INPUT_FILE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 找不到文件 {INPUT_FILE}，请检查路径。\")\n",
    "        exit()\n",
    "\n",
    "    # 2. 应用清洗 (Type Cleaning)\n",
    "    print(\"正在清洗 'maxspeed' (转换为 m/s)...\")\n",
    "    edges_df['maxspeed'] = edges_df['maxspeed'].apply(clean_maxspeed_v2)\n",
    "\n",
    "    print(\"正在清洗 'lanes' (处理列表并保留浮点数)...\")\n",
    "    edges_df['lanes'] = edges_df['lanes'].apply(clean_lanes_v2)\n",
    "\n",
    "    # 3. 检查结果预览\n",
    "    print(\"\\n清洗后数据预览 (Head 5):\")\n",
    "    print(edges_df[['maxspeed', 'lanes']].head())\n",
    "    \n",
    "    print(\"\\n清洗统计:\")\n",
    "    print(f\"Maxspeed 非空数量: {edges_df['maxspeed'].notna().sum()}\")\n",
    "    print(f\"Lanes 非空数量:    {edges_df['lanes'].notna().sum()}\")\n",
    "\n",
    "    # 4. 保存文件\n",
    "    print(f\"\\n正在保存文件至: {OUTPUT_FILE} ...\")\n",
    "    edges_df.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(\"✅ 步骤 2 完成: 字段类型清洗已保存。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f24a22e-679c-40aa-92ab-7691702ac2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取文件: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step2.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kam1\\AppData\\Local\\Temp\\ipykernel_29108\\3980590184.py:92: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  edges_df = pd.read_csv(INPUT_FILE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "填补前缺失值 -> Maxspeed: 42256, Lanes: 46760\n",
      "正在应用分级填补策略 (Hierarchical Imputation)...\n",
      "填补后缺失值 -> Maxspeed: 0, Lanes: 0\n",
      "正在保存文件至: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step3.csv ...\n",
      "✅ 步骤 3 完成: 缺失值分级填补已保存。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "\n",
    "# ================= 配置路径 =================\n",
    "# 输入文件 (Step 2 的输出)\n",
    "INPUT_FILE = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step2.csv\"\n",
    "# 输出文件 (Step 3 的结果)\n",
    "OUTPUT_FILE = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step3.csv\"\n",
    "\n",
    "# ================= 1. 定义分级填补字典 (Hierarchical Dictionary) =================\n",
    "# 单位说明: \n",
    "# Speed: m/s (1 mph = 0.44704 m/s)\n",
    "# Lanes: float\n",
    "\n",
    "imputation_dict = {\n",
    "    # --- 高速公路系统 (Motorways) ---\n",
    "    'motorway':      {'speed': 29.06, 'lanes': 3.0}, # ~65 mph\n",
    "    'motorway_link': {'speed': 13.41, 'lanes': 1.0}, # ~30 mph (匝道单车道)\n",
    "    \n",
    "    # --- 快速路系统 (Trunk) ---\n",
    "    'trunk':         {'speed': 20.12, 'lanes': 3.0}, # ~45 mph\n",
    "    'trunk_link':    {'speed': 13.41, 'lanes': 1.0}, # ~30 mph\n",
    "    \n",
    "    # --- 主干道系统 (Primary) ---\n",
    "    'primary':       {'speed': 13.41, 'lanes': 2.0}, # ~30 mph\n",
    "    'primary_link':  {'speed': 11.18, 'lanes': 1.0}, # ~25 mph\n",
    "    \n",
    "    # --- 次干道系统 (Secondary) ---\n",
    "    'secondary':     {'speed': 13.41, 'lanes': 2.0}, # ~30 mph\n",
    "    'secondary_link':{'speed': 11.18, 'lanes': 1.0}, # ~25 mph\n",
    "    \n",
    "    # --- 支路系统 (Tertiary) ---\n",
    "    'tertiary':      {'speed': 11.18, 'lanes': 2.0}, # ~25 mph\n",
    "    'tertiary_link': {'speed': 11.18, 'lanes': 1.0}, # ~25 mph\n",
    "    \n",
    "    # --- 居住区与低速道路 ---\n",
    "    'residential':   {'speed': 8.94,  'lanes': 1.0}, # ~20 mph (保守策略:防止过境穿插)\n",
    "    'living_street': {'speed': 6.71,  'lanes': 1.0}, # ~15 mph\n",
    "    'unclassified':  {'speed': 8.94,  'lanes': 1.0}, # ~20 mph\n",
    "    'service':       {'speed': 6.71,  'lanes': 1.0}  # ~15 mph (服务道路)\n",
    "}\n",
    "\n",
    "# --- 全局兜底策略 (Fallback) ---\n",
    "# 当 highway 类型不在字典中时使用 (如 'busway', 'path' 等)\n",
    "GLOBAL_DEFAULT = {'speed': 8.94, 'lanes': 1.0} # ~20 mph, 1 lane\n",
    "\n",
    "# ================= 2. 核心填补函数 =================\n",
    "\n",
    "def fill_missing_values(row):\n",
    "    \"\"\"\n",
    "    对每一行应用分级填补逻辑\n",
    "    \"\"\"\n",
    "    # --- A. 获取并清洗 highway 类型 ---\n",
    "    hw_raw = row['highway']\n",
    "    \n",
    "    # 如果是列表字符串 \"['primary', 'residential']\"，取第一个\n",
    "    if isinstance(hw_raw, str) and hw_raw.strip().startswith('['):\n",
    "        try:\n",
    "            hw_list = ast.literal_eval(hw_raw)\n",
    "            hw_type = hw_list[0] if hw_list else 'unclassified'\n",
    "        except:\n",
    "            hw_type = 'unclassified'\n",
    "    else:\n",
    "        hw_type = str(hw_raw)\n",
    "        \n",
    "    # --- B. 查字典获取默认值 ---\n",
    "    defaults = imputation_dict.get(hw_type, GLOBAL_DEFAULT)\n",
    "    \n",
    "    # --- C. 填补 maxspeed ---\n",
    "    speed = row['maxspeed']\n",
    "    if pd.isna(speed):\n",
    "        speed = defaults['speed']\n",
    "        \n",
    "    # --- D. 填补 lanes ---\n",
    "    lanes = row['lanes']\n",
    "    if pd.isna(lanes):\n",
    "        lanes = defaults['lanes']\n",
    "        \n",
    "    return speed, lanes\n",
    "\n",
    "# ================= 3. 主执行逻辑 =================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"正在读取文件: {INPUT_FILE} ...\")\n",
    "    \n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"❌ 错误: 找不到文件 {INPUT_FILE}，请检查路径。\")\n",
    "    else:\n",
    "        # 读取数据\n",
    "        edges_df = pd.read_csv(INPUT_FILE)\n",
    "        \n",
    "        # 统计填补前的缺失情况\n",
    "        missing_speed_before = edges_df['maxspeed'].isna().sum()\n",
    "        missing_lanes_before = edges_df['lanes'].isna().sum()\n",
    "        print(f\"填补前缺失值 -> Maxspeed: {missing_speed_before}, Lanes: {missing_lanes_before}\")\n",
    "        \n",
    "        # 执行填补\n",
    "        print(\"正在应用分级填补策略 (Hierarchical Imputation)...\")\n",
    "        # 使用 apply 获取填补后的两列数据\n",
    "        filled_data = edges_df.apply(fill_missing_values, axis=1, result_type='expand')\n",
    "        \n",
    "        # 将结果赋值回原 DataFrame\n",
    "        edges_df['maxspeed'] = filled_data[0]\n",
    "        edges_df['lanes'] = filled_data[1]\n",
    "        \n",
    "        # 统计填补后的缺失情况 (理论上应为 0)\n",
    "        missing_speed_after = edges_df['maxspeed'].isna().sum()\n",
    "        missing_lanes_after = edges_df['lanes'].isna().sum()\n",
    "        print(f\"填补后缺失值 -> Maxspeed: {missing_speed_after}, Lanes: {missing_lanes_after}\")\n",
    "        \n",
    "        # 如果仍有 NaN (极少见情况), 强制使用全局兜底\n",
    "        if missing_speed_after > 0:\n",
    "            print(\"⚠️ 警告: 仍有 maxspeed 缺失，强制应用全局兜底...\")\n",
    "            edges_df['maxspeed'] = edges_df['maxspeed'].fillna(GLOBAL_DEFAULT['speed'])\n",
    "            \n",
    "        if missing_lanes_after > 0:\n",
    "            print(\"⚠️ 警告: 仍有 lanes 缺失，强制应用全局兜底...\")\n",
    "            edges_df['lanes'] = edges_df['lanes'].fillna(GLOBAL_DEFAULT['lanes'])\n",
    "\n",
    "        # 保存文件\n",
    "        print(f\"正在保存文件至: {OUTPUT_FILE} ...\")\n",
    "        edges_df.to_csv(OUTPUT_FILE, index=False)\n",
    "        print(\"✅ 步骤 3 完成: 缺失值分级填补已保存。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df7ccf81-adaa-456e-b091-d1b7fb2a03cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件读取成功。\n",
      "数据总行数: 91227\n",
      "------------------------------\n",
      "oneway列中出现的所有唯一内容如下：\n",
      "------------------------------\n",
      "False\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kam1\\AppData\\Local\\Temp\\ipykernel_29108\\3381970734.py:9: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 设置文件的绝对路径\n",
    "file_path = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step3.csv\"\n",
    "\n",
    "try:\n",
    "    # 读取CSV文件\n",
    "    # 由于不确定文件编码，默认尝试utf-8，如果报错可以尝试 encoding='gbk'\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 检查是否存在 'oneway' 列\n",
    "    if 'oneway' in df.columns:\n",
    "        # 获取 'oneway' 列的所有唯一值\n",
    "        unique_values = df['oneway'].unique()\n",
    "        \n",
    "        print(f\"文件读取成功。\")\n",
    "        print(f\"数据总行数: {len(df)}\")\n",
    "        print(\"-\" * 30)\n",
    "        print(\"oneway列中出现的所有唯一内容如下：\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # 逐个打印唯一值，方便查看\n",
    "        for val in unique_values:\n",
    "            print(val)\n",
    "            # 如果想看该值的具体类型（是字符串还是布尔值），可以取消下面注释\n",
    "            # print(f\"值: {val}, 类型: {type(val)}\")\n",
    "            \n",
    "    else:\n",
    "        print(\"错误：数据集中未找到名为 'oneway' 的列，请检查列名。\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误：找不到文件，请确认路径是否正确：\\n{file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"读取文件时发生错误：{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fff6d2ab-b108-4d4b-9e1f-3dd564c89227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取文件: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step3.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kam1\\AppData\\Local\\Temp\\ipykernel_29108\\1097837975.py:21: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ oneway 字段标准化完成。\n",
      "正在检查 77198 条双向道路的连通性...\n",
      "----------------------------------------\n",
      "📊 检查报告 (Step 4: Bidirectional Expansion)\n",
      "  - 双向道总记录数 (oneway=False): 77198\n",
      "  - 已存在的反向边 (无需操作):     77198\n",
      "  - 缺失并新生成的反向边:         0\n",
      "\n",
      "✅ 结论：数据已经是完全拓扑展开的状态，没有生成新边。\n",
      "   (这说明你的 Step 3 数据已经非常干净了)\n",
      "----------------------------------------\n",
      "💾 处理完成！文件已保存为:\n",
      "D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step4.csv\n",
      "最终数据集行数: 91227\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shapely.wkt\n",
    "from shapely.geometry import LineString\n",
    "import os\n",
    "\n",
    "# ================= 配置区域：绝对路径 =================\n",
    "# 输入文件路径\n",
    "input_file = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step3.csv\"\n",
    "# 输出文件路径 (保存在同一目录下)\n",
    "output_file = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step4.csv\"\n",
    "# ===================================================\n",
    "\n",
    "def process_bidirectional_edges():\n",
    "    print(f\"正在读取文件: {input_file} ...\")\n",
    "    \n",
    "    # 检查文件是否存在\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"❌ 错误: 找不到文件，请检查路径是否正确：\\n{input_file}\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # 1. 清洗 oneway 字段，确保它是标准的 Boolean 类型\n",
    "    def parse_bool(x):\n",
    "        if isinstance(x, str):\n",
    "            return x.lower() == 'true'\n",
    "        return bool(x)\n",
    "\n",
    "    df['oneway'] = df['oneway'].apply(parse_bool)\n",
    "    print(\"✅ oneway 字段标准化完成。\")\n",
    "\n",
    "    # 2. 建立索引以加速查找 (u, v)\n",
    "    existing_edges = set(zip(df['u'], df['v']))\n",
    "\n",
    "    # 3. 筛选出需要检查的双向道 (oneway = False)\n",
    "    bidirectional_df = df[df['oneway'] == False].copy()\n",
    "    \n",
    "    new_rows = []\n",
    "    count_already_exist = 0\n",
    "    count_need_expansion = 0\n",
    "\n",
    "    print(f\"正在检查 {len(bidirectional_df)} 条双向道路的连通性...\")\n",
    "\n",
    "    # 4. 遍历检查与展开\n",
    "    for index, row in bidirectional_df.iterrows():\n",
    "        u, v = row['u'], row['v']\n",
    "        \n",
    "        # 核心逻辑：检查反向边 (v -> u) 是否已经存在\n",
    "        if (v, u) in existing_edges:\n",
    "            count_already_exist += 1\n",
    "        else:\n",
    "            count_need_expansion += 1\n",
    "            # 如果不存在，则创建反向边\n",
    "            new_row = row.copy()\n",
    "            new_row['u'] = v\n",
    "            new_row['v'] = u\n",
    "            \n",
    "            # 翻转几何信息 (LineString)\n",
    "            if 'geometry' in new_row and isinstance(new_row['geometry'], str):\n",
    "                try:\n",
    "                    geom = shapely.wkt.loads(new_row['geometry'])\n",
    "                    if isinstance(geom, LineString):\n",
    "                        reversed_geom = LineString(list(geom.coords)[::-1])\n",
    "                        new_row['geometry'] = shapely.wkt.dumps(reversed_geom)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            \n",
    "            new_rows.append(new_row)\n",
    "\n",
    "    # 5. 输出统计报告\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"📊 检查报告 (Step 4: Bidirectional Expansion)\")\n",
    "    print(f\"  - 双向道总记录数 (oneway=False): {len(bidirectional_df)}\")\n",
    "    print(f\"  - 已存在的反向边 (无需操作):     {count_already_exist}\")\n",
    "    print(f\"  - 缺失并新生成的反向边:         {count_need_expansion}\")\n",
    "    \n",
    "    if count_need_expansion == 0:\n",
    "        print(\"\\n✅ 结论：数据已经是完全拓扑展开的状态，没有生成新边。\")\n",
    "        print(\"   (这说明你的 Step 3 数据已经非常干净了)\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️ 结论：检测到拓扑缺失，已补全 {count_need_expansion} 条边。\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # 6. 合并数据并保存\n",
    "    if new_rows:\n",
    "        new_df = pd.DataFrame(new_rows)\n",
    "        final_df = pd.concat([df, new_df], ignore_index=True)\n",
    "    else:\n",
    "        final_df = df\n",
    "\n",
    "    # 保存\n",
    "    try:\n",
    "        final_df.to_csv(output_file, index=False)\n",
    "        print(f\"💾 处理完成！文件已保存为:\\n{output_file}\")\n",
    "        print(f\"最终数据集行数: {len(final_df)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 保存失败: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_bidirectional_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beb7e0f4-9537-4788-8772-a8b45959a02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 [Step 5] 正在读取数据: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step4.csv ...\n",
      "🕸️  正在构建有向图 (DiGraph)...\n",
      "   - 原始网络节点数: 37162\n",
      "   - 原始网络边数:   91227\n",
      "🔍 正在计算强连通分量 (SCC)...\n",
      "--------------------------------------------------\n",
      "🧩 连通性分析结果 (L-SCC):\n",
      "   - 最大主连通分量节点数: 36946\n",
      "   - 剔除孤岛/死胡同节点数: 216\n",
      "   - 节点保留率: 99.42%\n",
      "--------------------------------------------------\n",
      "✂️  正在根据主连通分量执行剪枝...\n",
      "💾 正在保存清洗后的数据...\n",
      "✅ 保存成功: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step5.csv\n",
      "\n",
      "📊 最终统计报告:\n",
      "   - 最终保留边数: 90924\n",
      "   - 剔除无效边数: 303\n",
      "   - 边保留率: 99.67%\n",
      "\n",
      "🧐 数据质量评价:\n",
      "   🟢 [完美] 保留率 > 95%。路网连通性极好，几乎没有断头路。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "# ================= 配置区域：绝对路径 =================\n",
    "# 输入文件 (Step 4 的产出)\n",
    "input_file = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step4.csv\"\n",
    "# 输出文件 (Step 5 的产出)\n",
    "output_file = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step5.csv\"\n",
    "# ===================================================\n",
    "\n",
    "def filter_island_nodes():\n",
    "    print(f\"🔄 [Step 5] 正在读取数据: {input_file} ...\")\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"❌ 错误: 找不到文件，请检查路径:\\n{input_file}\")\n",
    "        return\n",
    "\n",
    "    # 读取数据，low_memory=False 防止列类型推断警告\n",
    "    df = pd.read_csv(input_file, low_memory=False)\n",
    "    original_edge_count = len(df)\n",
    "    \n",
    "    # 【关键优化】强制将 u, v 列转换为字符串，防止因 int/str 类型混杂导致匹配失败\n",
    "    df['u'] = df['u'].astype(str)\n",
    "    df['v'] = df['v'].astype(str)\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 1. 构建有向图 (Construct Directed Graph)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"🕸️  正在构建有向图 (DiGraph)...\")\n",
    "    # 使用 DiGraph 确保方向性 (A->B 不等于 B->A)\n",
    "    G = nx.from_pandas_edgelist(df, source='u', target='v', create_using=nx.DiGraph)\n",
    "    \n",
    "    original_node_count = G.number_of_nodes()\n",
    "    print(f\"   - 原始网络节点数: {original_node_count}\")\n",
    "    print(f\"   - 原始网络边数:   {original_edge_count}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. 提取最大强连通分量 (Extract Largest SCC)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"🔍 正在计算强连通分量 (SCC)...\")\n",
    "    # nx.strongly_connected_components 返回的是一个生成器\n",
    "    # 这里的逻辑是：找出所有“强连通”的子图，然后取节点数最多的那一个\n",
    "    scc_generator = nx.strongly_connected_components(G)\n",
    "    largest_scc_nodes = max(scc_generator, key=len)\n",
    "    \n",
    "    # 转换为集合，提升查找速度至 O(1)\n",
    "    valid_nodes_set = set(largest_scc_nodes)\n",
    "    \n",
    "    kept_node_count = len(valid_nodes_set)\n",
    "    removed_node_count = original_node_count - kept_node_count\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"🧩 连通性分析结果 (L-SCC):\")\n",
    "    print(f\"   - 最大主连通分量节点数: {kept_node_count}\")\n",
    "    print(f\"   - 剔除孤岛/死胡同节点数: {removed_node_count}\")\n",
    "    print(f\"   - 节点保留率: {kept_node_count / original_node_count * 100:.2f}%\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. 反向过滤 DataFrame (Back-Filtering)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"✂️  正在根据主连通分量执行剪枝...\")\n",
    "    \n",
    "    # 核心逻辑：保留“起点”和“终点”都在主连通分量里的边\n",
    "    # 只要有一端在孤岛上，这条边就必须切除，否则后续算最短路会报错\n",
    "    mask = df['u'].isin(valid_nodes_set) & df['v'].isin(valid_nodes_set)\n",
    "    df_clean = df[mask].copy()\n",
    "    \n",
    "    new_edge_count = len(df_clean)\n",
    "    removed_edge_count = original_edge_count - new_edge_count\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4. 保存与验证\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"💾 正在保存清洗后的数据...\")\n",
    "    try:\n",
    "        df_clean.to_csv(output_file, index=False)\n",
    "        print(f\"✅ 保存成功: {output_file}\")\n",
    "    except PermissionError:\n",
    "        print(f\"❌ 保存失败: 文件可能被占用，请关闭 Excel 后重试。\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n📊 最终统计报告:\")\n",
    "    print(f\"   - 最终保留边数: {new_edge_count}\")\n",
    "    print(f\"   - 剔除无效边数: {removed_edge_count}\")\n",
    "    print(f\"   - 边保留率: {new_edge_count / original_edge_count * 100:.2f}%\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 5. 合理性自检\n",
    "    # ---------------------------------------------------------\n",
    "    retention_rate = new_edge_count / original_edge_count\n",
    "    print(\"\\n🧐 数据质量评价:\")\n",
    "    if retention_rate > 0.95:\n",
    "        print(\"   🟢 [完美] 保留率 > 95%。路网连通性极好，几乎没有断头路。\")\n",
    "    elif retention_rate > 0.85:\n",
    "        print(\"   🟢 [优秀] 保留率 > 85%。正常的城市路网，剔除了边缘噪声。\")\n",
    "    elif retention_rate > 0.70:\n",
    "        print(\"   🟡 [警告] 保留率 70%-85%。请检查是否误删了重要区域（如因单行道设置错误导致整个区不可达）。\")\n",
    "    else:\n",
    "        print(\"   🔴 [严重错误] 保留率 < 70%！路网破碎严重，主干道可能中断，请回溯检查 Step 3 或 Step 4。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filter_island_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43e6c6f3-1b38-48d8-b4be-7145ca5de148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 [Step 6] 读取 Step 5 数据: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step5.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kam1\\AppData\\Local\\Temp\\ipykernel_29108\\2167630227.py:19: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file, dtype={'u': str, 'v': str})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱️  正在计算通行时间 (travel_time)...\n",
      "   - 通行时间计算完成。示例: 长度 55.48935589611431m / 速度 8.94m/s = 6.2069s\n",
      "📍 正在从几何列提取节点坐标 (Node Extraction)...\n",
      "   - 已处理 20000/90924 条边...\n",
      "   - 已处理 40000/90924 条边...\n",
      "   - 已处理 60000/90924 条边...\n",
      "   - 已处理 80000/90924 条边...\n",
      "   - 提取完成！共找到 36946 个唯一节点。\n",
      "💾 正在保存 Edge 文件: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step6.csv\n",
      "💾 正在保存 Node 文件: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\nodes_drive_step6.csv\n",
      "----------------------------------------\n",
      "📊 [Step 6 校验报告]\n",
      "   ✅ 坐标完整性: 所有节点均有 (x, y) 坐标。\n",
      "   ✅ 时间合理性: 所有 travel_time 均为正数。\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shapely.wkt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ================= 配置区域 =================\n",
    "input_file = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step5.csv\"\n",
    "output_edges_file = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step6.csv\"\n",
    "output_nodes_file = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\nodes_drive_step6.csv\"\n",
    "# ===========================================\n",
    "\n",
    "def process_attributes_and_coordinates():\n",
    "    print(f\"🔄 [Step 6] 读取 Step 5 数据: {input_file} ...\")\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"❌ 错误: 找不到文件 {input_file}\")\n",
    "        return\n",
    "\n",
    "    # 读取数据，u 和 v 必须读为字符串以防 ID 精度丢失\n",
    "    df = pd.read_csv(input_file, dtype={'u': str, 'v': str})\n",
    "    \n",
    "    # =========================================================\n",
    "    # 任务 1: 计算通行时间 (Impedance Calculation)\n",
    "    # =========================================================\n",
    "    print(\"⏱️  正在计算通行时间 (travel_time)...\")\n",
    "    \n",
    "    # 检查除零错误 (虽然 Step 5 检查过，再保险一次)\n",
    "    if (df['maxspeed'] <= 0).any():\n",
    "        print(\"⚠️  警告: 发现 maxspeed <= 0 的记录，将用默认值 1.0 m/s 替换以避免除零错误。\")\n",
    "        df.loc[df['maxspeed'] <= 0, 'maxspeed'] = 1.0\n",
    "\n",
    "    # 计算时间 (秒)\n",
    "    df['travel_time'] = df['length'] / df['maxspeed']\n",
    "    \n",
    "    # 保留 4 位小数\n",
    "    df['travel_time'] = df['travel_time'].round(4)\n",
    "    \n",
    "    print(f\"   - 通行时间计算完成。示例: 长度 {df.iloc[0]['length']}m / 速度 {df.iloc[0]['maxspeed']}m/s = {df.iloc[0]['travel_time']}s\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 任务 2: 提取并构建节点坐标表 (Node Coordinate Extraction)\n",
    "    # =========================================================\n",
    "    print(\"📍 正在从几何列提取节点坐标 (Node Extraction)...\")\n",
    "    \n",
    "    # 这里的逻辑是：边的起点坐标 = u 的坐标，边的终点坐标 = v 的坐标\n",
    "    # 我们用字典来存储，key=node_id, value=(x, y)，利用字典特性自动去重\n",
    "    node_coords = {}\n",
    "    \n",
    "    # 为了效率，我们只解析 geometry 列\n",
    "    # 预先检查 geometry 是否存在且有效\n",
    "    valid_geom_mask = df['geometry'].notna()\n",
    "    \n",
    "    count = 0\n",
    "    total = len(df)\n",
    "    \n",
    "    # 使用 iterrows 可能会慢，改用 zip 遍历必要列会快很多\n",
    "    for u, v, wkt in zip(df.loc[valid_geom_mask, 'u'], \n",
    "                         df.loc[valid_geom_mask, 'v'], \n",
    "                         df.loc[valid_geom_mask, 'geometry']):\n",
    "        try:\n",
    "            line = shapely.wkt.loads(wkt)\n",
    "            if hasattr(line, 'coords'):\n",
    "                coords = list(line.coords)\n",
    "                # 起点对应 u\n",
    "                start_pt = coords[0]\n",
    "                # 终点对应 v\n",
    "                end_pt = coords[-1]\n",
    "                \n",
    "                # 存入字典 (x=lon, y=lat)\n",
    "                # 只有当节点不在字典里时才写入（避免重复写入，虽然覆盖也没事）\n",
    "                if u not in node_coords:\n",
    "                    node_coords[u] = {'osmid': u, 'x': start_pt[0], 'y': start_pt[1]}\n",
    "                \n",
    "                if v not in node_coords:\n",
    "                    node_coords[v] = {'osmid': v, 'x': end_pt[0], 'y': end_pt[1]}\n",
    "                    \n",
    "        except Exception as e:\n",
    "            # 极少数情况 geometry 解析失败\n",
    "            pass\n",
    "            \n",
    "        count += 1\n",
    "        if count % 20000 == 0:\n",
    "            print(f\"   - 已处理 {count}/{total} 条边...\")\n",
    "\n",
    "    # 将字典转为 DataFrame\n",
    "    nodes_df = pd.DataFrame.from_dict(node_coords, orient='index')\n",
    "    \n",
    "    print(f\"   - 提取完成！共找到 {len(nodes_df)} 个唯一节点。\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 任务 3: 校验与保存\n",
    "    # =========================================================\n",
    "    \n",
    "    # 1. 保存新的边文件 (带 travel_time)\n",
    "    print(f\"💾 正在保存 Edge 文件: {output_edges_file}\")\n",
    "    df.to_csv(output_edges_file, index=False)\n",
    "    \n",
    "    # 2. 保存新的点文件 (用于 KDTree)\n",
    "    print(f\"💾 正在保存 Node 文件: {output_nodes_file}\")\n",
    "    nodes_df.to_csv(output_nodes_file, index=False)\n",
    "    \n",
    "    # 3. 完整性检查\n",
    "    print(\"-\" * 40)\n",
    "    print(\"📊 [Step 6 校验报告]\")\n",
    "    \n",
    "    # 检查是否有 NaN 坐标\n",
    "    missing_coords = nodes_df[['x', 'y']].isnull().any(axis=1).sum()\n",
    "    if missing_coords == 0:\n",
    "        print(\"   ✅ 坐标完整性: 所有节点均有 (x, y) 坐标。\")\n",
    "    else:\n",
    "        print(f\"   ❌ 坐标缺失: 有 {missing_coords} 个节点无法提取坐标！\")\n",
    "        \n",
    "    # 检查 travel_time 异常\n",
    "    neg_time = (df['travel_time'] < 0).sum()\n",
    "    zero_time = (df['travel_time'] == 0).sum()\n",
    "    if neg_time == 0 and zero_time == 0:\n",
    "        print(\"   ✅ 时间合理性: 所有 travel_time 均为正数。\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ 时间异常: 发现 {neg_time} 个负值，{zero_time} 个零值。\")\n",
    "        \n",
    "    print(\"-\" * 40)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_attributes_and_coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "093a5e24-5a5a-4647-8605-8ca9abd9384f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 [Step 6] 读取 Step 5 数据: D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step5.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kam1\\AppData\\Local\\Temp\\ipykernel_29108\\2553082860.py:21: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file, dtype={'u': str, 'v': str})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱️  正在计算通行时间 (travel_time)...\n",
      "📍 正在解析 geometry 提取节点坐标...\n",
      "\n",
      "🧐 [数据质量自检报告]\n",
      "----------------------------------------\n",
      "   ✅ [完整性] 节点提取完美匹配 (边表中的每个点都找到了坐标)。\n",
      "   ✅ [属性] 通行时间范围: 0.0967s ~ 509.9792s (均值: 15.21s)\n",
      "   ✅ [坐标] 所有 36946 个节点的经纬度均在合法范围内。\n",
      "      示例坐标: ID 37293968 -> (-76.76243, 39.27487)\n",
      "----------------------------------------\n",
      "💾 正在保存 Edge 文件 (含 travel_time): D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step6.csv\n",
      "💾 正在保存 Node 文件 (含 x, y): D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\nodes_drive_step6.csv\n",
      "\n",
      "✅ Step 6 处理全部完成。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shapely.wkt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# ================= 配置区域：绝对路径 =================\n",
    "input_file = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step5.csv\"\n",
    "\n",
    "# 输出文件\n",
    "output_edges = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\edges_drive_step6.csv\"\n",
    "output_nodes = r\"D:\\PyCode\\论文复现与改进\\2025-D\\2507692\\论文复现与优化\\2025_Problem_D_Data\\nodes_drive_step6.csv\"\n",
    "# ===================================================\n",
    "\n",
    "def process_step6():\n",
    "    print(f\"🔄 [Step 6] 读取 Step 5 数据: {input_file} ...\")\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"❌ 错误: 找不到文件 {input_file}\")\n",
    "        return\n",
    "\n",
    "    # 读取数据，u 和 v 读为字符串，防止长数字被截断或精度丢失\n",
    "    df = pd.read_csv(input_file, dtype={'u': str, 'v': str})\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 任务 1: 计算物理阻抗 (travel_time)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"⏱️  正在计算通行时间 (travel_time)...\")\n",
    "    \n",
    "    # 防御性编程：检查 maxspeed 是否有 0 或负数（防止除零报错）\n",
    "    invalid_speed_mask = df['maxspeed'] <= 0\n",
    "    if invalid_speed_mask.any():\n",
    "        print(f\"⚠️  发现 {invalid_speed_mask.sum()} 条记录速度异常 (<=0)，已修正为 1.0 m/s。\")\n",
    "        df.loc[invalid_speed_mask, 'maxspeed'] = 1.0\n",
    "\n",
    "    # 核心公式：时间 = 距离 / 速度\n",
    "    df['travel_time'] = df['length'] / df['maxspeed']\n",
    "    \n",
    "    # 精度处理：保留 4 位小数（例如 0.1234 秒）\n",
    "    df['travel_time'] = df['travel_time'].round(4)\n",
    "    \n",
    "    # 再次检查计算后的时间是否有 0 值 (可能因为 length 极短)\n",
    "    # 如果时间为 0，这在图算法里会导致问题，强制设为 0.001 秒\n",
    "    zero_time_mask = df['travel_time'] == 0\n",
    "    if zero_time_mask.any():\n",
    "        print(f\"⚠️  发现 {zero_time_mask.sum()} 条记录计算时间为 0，已修正为 0.001s。\")\n",
    "        df.loc[zero_time_mask, 'travel_time'] = 0.001\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 任务 2: 从几何列提取节点坐标\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"📍 正在解析 geometry 提取节点坐标...\")\n",
    "    \n",
    "    node_coords = {} # 字典结构: {node_id: {'osmid': id, 'x': lon, 'y': lat}}\n",
    "    \n",
    "    # 使用 zip 高效遍历\n",
    "    # 逻辑：对于每一条边，起点坐标属于 u，终点坐标属于 v\n",
    "    for u, v, wkt_str in zip(df['u'], df['v'], df['geometry']):\n",
    "        try:\n",
    "            # 解析 WKT 字符串\n",
    "            geom = shapely.wkt.loads(wkt_str)\n",
    "            coords = list(geom.coords)\n",
    "            \n",
    "            # 提取首尾点\n",
    "            start_pt = coords[0]  # (x, y)\n",
    "            end_pt = coords[-1]   # (x, y)\n",
    "            \n",
    "            # 写入字典（自动去重）\n",
    "            if u not in node_coords:\n",
    "                node_coords[u] = {'osmid': u, 'x': start_pt[0], 'y': start_pt[1]}\n",
    "            \n",
    "            if v not in node_coords:\n",
    "                node_coords[v] = {'osmid': v, 'x': end_pt[0], 'y': end_pt[1]}\n",
    "                \n",
    "        except Exception as e:\n",
    "            # 仅在几何解析严重错误时触发，一般不会发生\n",
    "            pass\n",
    "\n",
    "    # 转换为 DataFrame\n",
    "    nodes_df = pd.DataFrame.from_dict(node_coords, orient='index')\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 任务 3: 深度自检 (Deep Self-Check)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n🧐 [数据质量自检报告]\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # --- 检查 1: 节点完整性 ---\n",
    "    # 边表里出现过的所有点，必须都有坐标\n",
    "    edges_nodes = set(df['u']).union(set(df['v']))\n",
    "    extracted_nodes = set(nodes_df['osmid'])\n",
    "    missing_nodes = edges_nodes - extracted_nodes\n",
    "    \n",
    "    if len(missing_nodes) == 0:\n",
    "        print(\"   ✅ [完整性] 节点提取完美匹配 (边表中的每个点都找到了坐标)。\")\n",
    "    else:\n",
    "        print(f\"   ❌ [错误] 有 {len(missing_nodes)} 个节点缺失坐标！这会导致后续建图失败。\")\n",
    "        # 如果有缺失，通常是因为 geometry 为空或解析失败，需要检查源数据\n",
    "    \n",
    "    # --- 检查 2: 时间合理性 ---\n",
    "    min_time = df['travel_time'].min()\n",
    "    max_time = df['travel_time'].max()\n",
    "    mean_time = df['travel_time'].mean()\n",
    "    \n",
    "    print(f\"   ✅ [属性] 通行时间范围: {min_time}s ~ {max_time}s (均值: {mean_time:.2f}s)\")\n",
    "    if max_time > 3600:\n",
    "        print(\"      ⚠️  注意：存在通行时间 > 1小时的边，请确认这是否为超长高速路段。\")\n",
    "    \n",
    "    # --- 检查 3: 坐标有效性 (Geo Validity) ---\n",
    "    # 检查经纬度是否在地球范围内\n",
    "    # x (经度): -180 ~ 180, y (纬度): -90 ~ 90\n",
    "    valid_geo = (\n",
    "        (nodes_df['x'] >= -180) & (nodes_df['x'] <= 180) &\n",
    "        (nodes_df['y'] >= -90) & (nodes_df['y'] <= 90)\n",
    "    )\n",
    "    if valid_geo.all():\n",
    "        print(f\"   ✅ [坐标] 所有 {len(nodes_df)} 个节点的经纬度均在合法范围内。\")\n",
    "        print(f\"      示例坐标: ID {nodes_df.iloc[0]['osmid']} -> ({nodes_df.iloc[0]['x']:.5f}, {nodes_df.iloc[0]['y']:.5f})\")\n",
    "    else:\n",
    "        invalid_count = (~valid_geo).sum()\n",
    "        print(f\"   ❌ [坐标] 发现 {invalid_count} 个节点坐标异常（超出地球范围）！\")\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 任务 4: 保存\n",
    "    # ---------------------------------------------------------\n",
    "    print(f\"💾 正在保存 Edge 文件 (含 travel_time): {output_edges}\")\n",
    "    df.to_csv(output_edges, index=False)\n",
    "    \n",
    "    print(f\"💾 正在保存 Node 文件 (含 x, y): {output_nodes}\")\n",
    "    nodes_df.to_csv(output_nodes, index=False)\n",
    "    \n",
    "    print(\"\\n✅ Step 6 处理全部完成。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_step6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4212ed-d83c-479b-aac3-f1016220f5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
