{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc53823b-fe77-45c3-aeac-0a267a5a61a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pulp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import inspect\n",
    "\n",
    "# å¿½ç•¥ Seaborn çš„ FutureWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "class IP_Solver_Capsule:\n",
    "    def __init__(self, name=\"IP_Optimization\", sense='max'):\n",
    "        self.name = name\n",
    "        self.sense = pulp.LpMaximize if sense == 'max' else pulp.LpMinimize\n",
    "        self.prob = pulp.LpProblem(name, self.sense)\n",
    "        self.vars = {}\n",
    "        self.matrix_vars = {}\n",
    "        self.constraints = {}\n",
    "        self.objective_expr = None\n",
    "        self.metadata = {'matrix_dims': {}, 'big_m_count': 0, 'var_count': 0}\n",
    "        self.is_solved = False\n",
    "        self.status = None\n",
    "\n",
    "    def generate_handshake(self, df_dict=None):\n",
    "        \"\"\"\n",
    "        [V6.1 æ ¸å¿ƒ] è‡ªåŠ¨ç”Ÿæˆå‘ç»™ AI çš„æ¡æ‰‹æç¤ºè¯\n",
    "        :param df_dict: åŒ…å«æ•°æ®çš„å­—å…¸ {'name': df}ï¼Œç”¨äºå‘Šè¯‰ AI æ•°æ®é•¿ä»€ä¹ˆæ ·\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ“‹ === è¯·å¤åˆ¶ä»¥ä¸‹å†…å®¹å‘é€ç»™ AI (Handshake Prompt) ===\\n\")\n",
    "        \n",
    "        # 1. èº«ä»½ä¸ç¯å¢ƒè®¾å®š\n",
    "        print(f\"ã€ç³»ç»Ÿè®¾å®šã€‘\\næˆ‘æ­£åœ¨ä½¿ç”¨ä¸€ä¸ªå°è£…å¥½çš„ç±» `{self.__class__.__name__}` å¤„ç†æ•°å­¦å»ºæ¨¡é—®é¢˜ã€‚\")\n",
    "        print(\"ç¯å¢ƒå·²åŠ è½½è¯¥ç±»ï¼Œè¯·å‹¿é‡æ–°å®šä¹‰ï¼Œç›´æ¥ä½¿ç”¨å®ä¾‹ `solver`ã€‚\")\n",
    "        \n",
    "        # 2. æ¥å£è¯´æ˜ (API Cheat Sheet) - å‘Šè¯‰ AI æœ‰å“ªäº›æ‹›æ•°\n",
    "        print(\"\\nã€å¯ç”¨æ¥å£ (API)ã€‘\")\n",
    "        print(f\"- solver = {self.__class__.__name__}(name='Model', sense='max/min')\")\n",
    "        \n",
    "        # ç¡¬ç¼–ç å…³é”®æ–¹æ³•çš„ç­¾åï¼Œç¡®ä¿ AI çŸ¥é“å‚æ•°\n",
    "        api_list = [\n",
    "            \"solver.add_variable_matrix(row_indices, col_indices, name='x', cat='Binary') # æ·»åŠ çŸ©é˜µå˜é‡\",\n",
    "            \"solver.add_big_M_constraint(bin_var, cont_var, M, relation='<=', name='Link') # æ·»åŠ Big-Mçº¦æŸ\",\n",
    "            \"solver.add_constraint(expr, sense, rhs, name) # æ·»åŠ æ™®é€šçº¦æŸ\",\n",
    "            \"solver.set_objective(expr) # è®¾ç½®ç›®æ ‡å‡½æ•°\",\n",
    "            \"solver.audit() # é€»è¾‘å®¡è®¡\",\n",
    "            \"solver.solve(time_limit=300) # æ±‚è§£\",\n",
    "            \"solver.analyze_sensitivity() # çº¿æ€§æ¾å¼›çµæ•åº¦åˆ†æ\",\n",
    "            \"solver.export_results() # å¯¼å‡ºç»“æœ\"\n",
    "        ]\n",
    "        for api in api_list:\n",
    "            print(f\"- {api}\")\n",
    "\n",
    "        # 3. æ•°æ®æƒ…æŠ¥ (Data Context)\n",
    "        if df_dict:\n",
    "            print(\"\\nã€å½“å‰æ•°æ®æƒ…æŠ¥ (Data Context)ã€‘\")\n",
    "            for name, df in df_dict.items():\n",
    "                print(f\"\\næ•°æ®é›†: {name}\")\n",
    "                print(f\"- åˆ—å: {list(df.columns)}\")\n",
    "                print(f\"- å‰2è¡Œæ ·ä¾‹:\\n{df.head(2).to_string(index=False)}\")\n",
    "        \n",
    "        print(\"\\nã€ä»»åŠ¡æŒ‡ä»¤ã€‘\")\n",
    "        print(\"è¯·åŸºäºä»¥ä¸Šæ¥å£å’Œæ•°æ®ï¼Œå¸®æˆ‘ç¼–å†™ Phase 2 (å˜é‡å®šä¹‰ä¸çº¦æŸæ„å»º) çš„ä»£ç ã€‚\")\n",
    "        print(\"æ³¨æ„ï¼šæå–å‚æ•°æ—¶è¯·ä½¿ç”¨å­—å…¸æ¨å¯¼å¼ (dict comprehension)ï¼Œä¸è¦è¯•å›¾è¯»å–æ–‡ä»¶ã€‚\")\n",
    "        print(\"=======================================================\")\n",
    "\n",
    "    def add_variable_matrix(self, row_indices, col_indices, name=\"x\", cat='Binary'):\n",
    "        \"\"\"æ·»åŠ çŸ©é˜µå˜é‡ x_ij\"\"\"\n",
    "        var_dict = pulp.LpVariable.dicts(name, (row_indices, col_indices), \n",
    "                                         cat=getattr(pulp, f\"Lp{cat}\"), lowBound=0)\n",
    "        self.matrix_vars[name] = var_dict\n",
    "        self.metadata['matrix_dims'][name] = (len(row_indices), len(col_indices))\n",
    "        for r in row_indices:\n",
    "            for c in col_indices:\n",
    "                self.vars[f\"{name}_{r}_{c}\"] = var_dict[r][c]\n",
    "                self.metadata['var_count'] += 1\n",
    "        print(f\"âœ… å·²æ³¨å†ŒçŸ©é˜µå˜é‡ {name}_ij: ç»´åº¦ {len(row_indices)}x{len(col_indices)} (ç±»å‹: {cat})\")\n",
    "        return var_dict\n",
    "\n",
    "    def add_big_M_constraint(self, bin_var, cont_var, M=100000, relation='<=', name=\"BigM_Link\"):\n",
    "        \"\"\"æ·»åŠ  Big-M æ··åˆé€»è¾‘çº¦æŸ\"\"\"\n",
    "        if relation == '<=': expr = (cont_var <= M * bin_var)\n",
    "        elif relation == '>=': expr = (cont_var >= bin_var / M)\n",
    "        else: raise ValueError(\"ä¸æ”¯æŒçš„å…³ç³»ç¬¦\")\n",
    "        self.prob += expr, name\n",
    "        self.constraints[name] = expr\n",
    "        self.metadata['big_m_count'] += 1\n",
    "        print(f\"ğŸ”— æ·»åŠ æ··åˆé€»è¾‘çº¦æŸ (Big-M): {name}\")\n",
    "\n",
    "    def set_objective(self, expr):\n",
    "        \"\"\"è®¾ç½®ç›®æ ‡å‡½æ•°\"\"\"\n",
    "        self.prob += expr\n",
    "        self.objective_expr = expr\n",
    "\n",
    "    def add_constraint(self, expr, sense, rhs, name):\n",
    "        \"\"\"é€šç”¨çº¦æŸæ·»åŠ \"\"\"\n",
    "        if sense == '<=': c = (expr <= rhs)\n",
    "        elif sense == '>=': c = (expr >= rhs)\n",
    "        elif sense == '==': c = (expr == rhs)\n",
    "        else: raise ValueError(\"Sense error\")\n",
    "        self.prob += c, name\n",
    "        self.constraints[name] = c\n",
    "\n",
    "    def audit(self):\n",
    "        \"\"\"é€»è¾‘å®¡è®¡ (å«å¯å‘å¼é¢„è­¦ & ä¾›éœ€å¹³è¡¡æ£€æŸ¥)\"\"\"\n",
    "        print(\"\\nğŸ›¡ï¸ === é€»è¾‘ä¸¥è°¨æ€§å®¡è®¡ (Audit Phase) ===\")\n",
    "        issues = []\n",
    "        if self.metadata['var_count'] > 10000:\n",
    "            issues.append(f\"âš ï¸ [éš¾åº¦é¢„è­¦] å˜é‡æ•° {self.metadata['var_count']} > 10000ã€‚å»ºè®®ï¼šè‹¥æ±‚è§£è¶…æ—¶ï¼Œæ”¹ç”¨å¯å‘å¼ç®—æ³•ã€‚\")\n",
    "        for name, dims in self.metadata['matrix_dims'].items():\n",
    "            if dims[0] != dims[1]:\n",
    "                issues.append(f\"âš ï¸ [ä¸å¹³è¡¡é¢„è­¦] çŸ©é˜µ '{name}' ç»´åº¦ {dims} éæ–¹é˜µã€‚\")\n",
    "        if not self.constraints: issues.append(\"âŒ [é€»è¾‘é”™è¯¯] æ— çº¦æŸæ¡ä»¶ã€‚\")\n",
    "        if self.objective_expr is None: issues.append(\"âŒ [é€»è¾‘é”™è¯¯] æ— ç›®æ ‡å‡½æ•°ã€‚\")\n",
    "        \n",
    "        if not issues:\n",
    "            print(\"âœ… å®¡è®¡é€šè¿‡ã€‚\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"ğŸš¨ å®¡è®¡å‘ç°æ½œåœ¨é£é™©ï¼š\")\n",
    "            for i in issues: print(i)\n",
    "            return True # å…è®¸æŒ‡æŒ¥å®˜å¼ºè¡Œç»§ç»­\n",
    "\n",
    "    def solve(self, time_limit=300):\n",
    "        \"\"\"æ±‚è§£ (å¸¦è¶…æ—¶ä¿æŠ¤)\"\"\"\n",
    "        print(\"\\nğŸš€ å¼€å§‹æ±‚è§£...\")\n",
    "        solver = pulp.PULP_CBC_CMD(msg=1, timeLimit=time_limit)\n",
    "        try:\n",
    "            status = self.prob.solve(solver)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æ±‚è§£å™¨é”™è¯¯: {e}\")\n",
    "            return\n",
    "        self.status = pulp.LpStatus[status]\n",
    "        self.is_solved = True\n",
    "        print(f\"ğŸ“Š æ±‚è§£çŠ¶æ€: {self.status}\")\n",
    "        if self.status == 'Optimal':\n",
    "            val = pulp.value(self.prob.objective)\n",
    "            print(f\"ğŸ’ ç›®æ ‡å‡½æ•°å€¼: {val:,.2f}\")\n",
    "        else:\n",
    "            print(\"âš ï¸ æœªæ‰¾åˆ°æœ€ä¼˜è§£ (Infeasible/Unbounded)ã€‚\")\n",
    "\n",
    "    def analyze_sensitivity(self):\n",
    "        \"\"\"çµæ•åº¦åˆ†æ (çº¿æ€§æ¾å¼›æ³•)\"\"\"\n",
    "        if not self.is_solved: return\n",
    "        print(\"\\nğŸ” === çµæ•åº¦åˆ†æ (åŸºäºçº¿æ€§æ¾å¼›) ===\")\n",
    "        relaxed_prob = self.prob.copy()\n",
    "        for v in relaxed_prob.variables():\n",
    "            v.cat = pulp.LpContinuous\n",
    "        relaxed_prob.solve(pulp.PULP_CBC_CMD(msg=0))\n",
    "        \n",
    "        if relaxed_prob.status == 1:\n",
    "            shadow_data = []\n",
    "            for name, c in relaxed_prob.constraints.items():\n",
    "                if abs(c.pi) > 1e-5:\n",
    "                    shadow_data.append({'Constraint': name, 'Marginal_Value': c.pi})\n",
    "            \n",
    "            if not shadow_data:\n",
    "                print(\"â„¹ï¸ æœªå‘ç°æ˜¾è‘—çš„è¾¹é™…ä»·å€¼çº¦æŸã€‚\")\n",
    "                return\n",
    "\n",
    "            df_shadow = pd.DataFrame(shadow_data).sort_values(by='Marginal_Value', key=abs, ascending=False).head(10)\n",
    "            print(\"ğŸ”¥ å…³é”®èµ„æºç“¶é¢ˆ (Top 10):\")\n",
    "            print(df_shadow.to_string(index=False))\n",
    "            \n",
    "            # ç»˜å›¾ä¿®å¤ç‰ˆ (è§£å†³ hue è­¦å‘Š)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            sns.barplot(data=df_shadow, x='Marginal_Value', y='Constraint', hue='Constraint', legend=False, palette='viridis')\n",
    "            plt.title('Resource Sensitivity (Linear Relaxation Proxy)')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"âš ï¸ çº¿æ€§æ¾å¼›æ±‚è§£å¤±è´¥ã€‚\")\n",
    "\n",
    "    def export_results(self):\n",
    "        \"\"\"äº¤ä»˜ç‰©å¯¼å‡º\"\"\"\n",
    "        if not self.is_solved: return\n",
    "        data = [{'Variable': v.name, 'Value': v.varValue} for v in self.prob.variables() if abs(v.varValue) > 1e-5]\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_excel(f\"{self.name}_Solution.xlsx\", index=False)\n",
    "        print(f\"\\nğŸ’¾ ç»“æœå·²ä¿å­˜: {self.name}_Solution.xlsx\")\n",
    "        \n",
    "        # æ‰“å° LaTeX å˜é‡è¯´æ˜\n",
    "        print(\"\\nğŸ“ LaTeX Variable Description:\")\n",
    "        print(r\"\\begin{itemize}\")\n",
    "        print(r\"  \\item $x_{ij}$: Binary decision variable, equals 1 if assignment is selected.\")\n",
    "        print(r\"  \\item $M$: Large constant used for logical constraints.\")\n",
    "        print(r\"\\end{itemize}\")\n",
    "        return df\n",
    "\n",
    "    def get_methodology(self):\n",
    "        \"\"\"åŠ¨æ€æ–¹æ³•è®ºç”Ÿæˆ\"\"\"\n",
    "        return f\"\"\"\n",
    "        \\\\subsection{{Integer Programming Model}}\n",
    "        We formulated the problem as a {self.name.replace('_', ' ')} model.\n",
    "        Decision variables are defined as binary/integer types.\n",
    "        The objective is to {self.sense} the target metric.\n",
    "        Constraints include resource limits and logical dependencies (handled via Big-M method).\n",
    "        Sensitivity analysis was conducted via Linear Relaxation.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "696a01b5-751a-41fe-876b-19a5b8cbca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ === è¯·å¤åˆ¶ä»¥ä¸‹å†…å®¹å‘é€ç»™ AI (Handshake Prompt) ===\n",
      "\n",
      "ã€ç³»ç»Ÿè®¾å®šã€‘\n",
      "æˆ‘æ­£åœ¨ä½¿ç”¨ä¸€ä¸ªå°è£…å¥½çš„ç±» `IP_Solver_Capsule` å¤„ç†æ•°å­¦å»ºæ¨¡é—®é¢˜ã€‚\n",
      "ç¯å¢ƒå·²åŠ è½½è¯¥ç±»ï¼Œè¯·å‹¿é‡æ–°å®šä¹‰ï¼Œç›´æ¥ä½¿ç”¨å®ä¾‹ `solver`ã€‚\n",
      "\n",
      "ã€å¯ç”¨æ¥å£ (API)ã€‘\n",
      "- solver = IP_Solver_Capsule(name='Model', sense='max/min')\n",
      "- solver.add_variable_matrix(row_indices, col_indices, name='x', cat='Binary') # æ·»åŠ çŸ©é˜µå˜é‡\n",
      "- solver.add_big_M_constraint(bin_var, cont_var, M, relation='<=', name='Link') # æ·»åŠ Big-Mçº¦æŸ\n",
      "- solver.add_constraint(expr, sense, rhs, name) # æ·»åŠ æ™®é€šçº¦æŸ\n",
      "- solver.set_objective(expr) # è®¾ç½®ç›®æ ‡å‡½æ•°\n",
      "- solver.audit() # é€»è¾‘å®¡è®¡\n",
      "- solver.solve(time_limit=300) # æ±‚è§£\n",
      "- solver.analyze_sensitivity() # çº¿æ€§æ¾å¼›çµæ•åº¦åˆ†æ\n",
      "- solver.export_results() # å¯¼å‡ºç»“æœ\n",
      "\n",
      "ã€å½“å‰æ•°æ®æƒ…æŠ¥ (Data Context)ã€‘\n",
      "\n",
      "æ•°æ®é›†: Sites\n",
      "- åˆ—å: ['Site_ID', 'Build_Cost', 'Capacity', 'X', 'Y']\n",
      "- å‰2è¡Œæ ·ä¾‹:\n",
      "Site_ID  Build_Cost  Capacity         X         Y\n",
      "    S01       95758       703 74.732011 53.969213\n",
      "    S02      122409       670 58.675117 96.525531\n",
      "\n",
      "æ•°æ®é›†: Districts\n",
      "- åˆ—å: ['District_ID', 'EV_Demand', 'X', 'Y']\n",
      "- å‰2è¡Œæ ·ä¾‹:\n",
      "District_ID  EV_Demand         X         Y\n",
      "        D01        152  2.058449 96.990985\n",
      "        D02        229 83.244264 21.233911\n",
      "\n",
      "ã€ä»»åŠ¡æŒ‡ä»¤ã€‘\n",
      "è¯·åŸºäºä»¥ä¸Šæ¥å£å’Œæ•°æ®ï¼Œå¸®æˆ‘ç¼–å†™ Phase 2 (å˜é‡å®šä¹‰ä¸çº¦æŸæ„å»º) çš„ä»£ç ã€‚\n",
      "æ³¨æ„ï¼šæå–å‚æ•°æ—¶è¯·ä½¿ç”¨å­—å…¸æ¨å¯¼å¼ (dict comprehension)ï¼Œä¸è¦è¯•å›¾è¯»å–æ–‡ä»¶ã€‚\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: è¿è¡Œ IP_Solver_Capsule ç±»å®šä¹‰\n",
    "# Cell 2:\n",
    "import pandas as pd\n",
    "# åªæœ‰ä½ è‡ªå·±çŸ¥é“æ–‡ä»¶åœ¨å“ªé‡Œï¼Œè¿™ä¸€æ­¥è‡ªå·±å†™æœ€å¿«ï¼Œç»å¯¹ä¸ä¼šæŠ¥é”™\n",
    "df_sites = pd.read_excel('2026_MCM_Problem_D.xlsx', sheet_name='Sites')\n",
    "df_districts = pd.read_excel('2026_MCM_Problem_D.xlsx', sheet_name='Districts')\n",
    "\n",
    "# åˆå§‹åŒ–å¹¶ç”Ÿæˆæ¡æ‰‹ä¿¡æ¯\n",
    "solver = IP_Solver_Capsule()\n",
    "solver.generate_handshake({'Sites': df_sites, 'Districts': df_districts})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a293e3b-3c96-4995-946f-0734f11c645c",
   "metadata": {},
   "source": [
    "# é…åˆ V6.1 èƒ¶å›Šçš„â€œåç»­æŒ‡ä»¤æ¨¡æ¿â€ (Command Manual)\n",
    "\n",
    "> **æŒ‡æŒ¥å®˜ï¼Œæ‚¨çš„ç†è§£éå¸¸ç²¾å‡†ã€‚**\n",
    ">\n",
    "> æ˜¯çš„ï¼ŒV6.1 çš„ `generate_handshake` ä¸»è¦æ˜¯è§£å†³â€œä¸Šä¸‹æ–‡æ³¨å…¥â€å’Œâ€œå·¥å…·è®¤çŸ¥â€çš„é—®é¢˜ï¼ˆå³ Phase 0ï¼‰ã€‚å®ƒç¡®ä¿äº† AI çŸ¥é“â€œæˆ‘æ˜¯è°ï¼ˆæœ‰å“ªäº› APIï¼‰â€ä»¥åŠâ€œæœ‰ä»€ä¹ˆæ•°æ®â€ã€‚\n",
    ">\n",
    "> ä½†æ˜¯ï¼ŒAI ä¾ç„¶ä¸çŸ¥é“â€œé¢˜ç›®è¦æ±‚ä»€ä¹ˆâ€ã€‚å®ƒä¸çŸ¥é“çº¦æŸæ˜¯â€œæ¯äººåªèƒ½åšä¸€ä¸ªä»»åŠ¡â€è¿˜æ˜¯â€œæ¯äººæœ€å¤šåšä¸‰ä¸ªâ€ï¼›å®ƒä¹Ÿä¸çŸ¥é“ç›®æ ‡æ˜¯â€œæˆæœ¬æœ€ä½â€è¿˜æ˜¯â€œæ—¶é—´æœ€çŸ­â€ã€‚\n",
    ">\n",
    "> è¿™é‡Œçš„æ¨¡æ¿å°†å¸®åŠ©æ‚¨æåº¦ç®€æ´å’Œæ ‡å‡†åŒ–åœ°**â€œæ³¨å…¥é€»è¾‘â€**ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ åœºæ™¯è¯´æ˜\n",
    "\n",
    "1.  æ‚¨åˆšåˆšè¿è¡Œäº† `solver.generate_handshake(df_dict)`ã€‚\n",
    "2.  æ‚¨æŠŠè¾“å‡ºçš„ä¸€å¤§æ®µâ€œæ¡æ‰‹ä¿¡æ¯â€å‘ç»™äº† AIã€‚\n",
    "3.  **AI å›å¤**ï¼šâ€œæ”¶åˆ°ï¼Œæˆ‘å·²ç†è§£ API å’Œæ•°æ®ï¼Œè¯·æŒ‡ç¤ºã€‚â€\n",
    "4.  **æ­¤æ—¶ï¼Œæ‚¨éœ€è¦æ ¹æ®ä¸åŒé˜¶æ®µï¼Œå‘é€ä»¥ä¸‹å¡«ç©ºå¼æŒ‡ä»¤ï¼š**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“œ Phase 2: æ³¨å…¥ä¸šåŠ¡é€»è¾‘ (Business Logic Injection)\n",
    "\n",
    "**æ¨¡æ¿æ–‡ä»¶å**ï¼š`Prompt_Phase_2_Logic.txt`\n",
    "**æ“ä½œ**ï¼šå¤åˆ¶ä¸‹æ–¹å†…å®¹ï¼Œå¡«ç©ºåå‘é€ã€‚\n",
    "\n",
    "```markdown\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šæ„å»ºçº¦æŸä¸ç›®æ ‡ã€‘\n",
    "\n",
    "åŸºäºåˆšæ‰çš„æ¡æ‰‹ä¿¡æ¯ï¼Œè¯·ä½¿ç”¨ `solver` å¯¹è±¡ç¼–å†™ä»¥ä¸‹é€»è¾‘çš„ä»£ç ï¼š\n",
    "\n",
    "1. **å˜é‡å®šä¹‰ (Variables)**:\n",
    "   - ä½¿ç”¨ `add_variable_matrix` å®šä¹‰çŸ©é˜µå˜é‡ï¼š[ä¾‹å¦‚ï¼šx[Site][District], Binary, è¡¨ç¤ºæŒ‡æ´¾]\n",
    "   - ä½¿ç”¨ `add_variable_list` å®šä¹‰åˆ—è¡¨å˜é‡ï¼š[ä¾‹å¦‚ï¼šy[Site], Binary, è¡¨ç¤ºæ˜¯å¦å»ºè®¾]\n",
    "\n",
    "2. **çº¦æŸæ¡ä»¶ (Constraints)**:\n",
    "   - **ç¡¬çº¦æŸ A**: [ä¾‹å¦‚ï¼šæ¯ä¸ª District å¿…é¡»è¢«è¦†ç›– (sum(x) >= 1)]\n",
    "   - **èµ„æºçº¦æŸ B**: [ä¾‹å¦‚ï¼šSite çš„æœåŠ¡é‡ <= Capacity (ä½¿ç”¨å‚æ•°å­—å…¸)]\n",
    "   - **æ··åˆé€»è¾‘ C**: [ä¾‹å¦‚ï¼šåªæœ‰ y[i]=1 æ—¶ï¼Œx[i] æ‰èƒ½ > 0ã€‚ä½¿ç”¨ `add_big_M_constraint` æ¥å£]\n",
    "\n",
    "3. **ç›®æ ‡å‡½æ•° (Objective)**:\n",
    "   - ç›®æ ‡æ–¹å‘ï¼š[Minimize / Maximize]\n",
    "   - å…¬å¼ï¼š[ä¾‹å¦‚ï¼šå»ºè®¾æˆæœ¬(Fixed) + è¿è¾“æˆæœ¬(Dist * Flow)]\n",
    "\n",
    "4. **åŠ¨ä½œ**:\n",
    "   - å®šä¹‰å®Œä¸Šè¿°å†…å®¹åï¼Œè¯·ç›´æ¥è°ƒç”¨ `solver.audit()` è¿›è¡Œè‡ªæ£€ã€‚\n",
    "\n",
    "**æ³¨æ„**ï¼šè¯·ç›´æ¥è¾“å‡º Python ä»£ç å—ï¼Œæ— éœ€é‡æ–°å¯¼å…¥åº“æˆ–å®šä¹‰ç±»ã€‚\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“œ Phase 3 & 4: æ±‚è§£ä¸å¤ç›˜ (Solve & Analyze)\n",
    "\n",
    "**æ¨¡æ¿æ–‡ä»¶å**ï¼š`Prompt_Phase_3_Solve.txt`\n",
    "**æ—¶æœº**ï¼šå¦‚æœ Phase 2 çš„ Audit é€šè¿‡ï¼Œå‘é€æ­¤æ¡ã€‚\n",
    "\n",
    "```markdown\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šæ±‚è§£ä¸åˆ†æã€‘\n",
    "\n",
    "å®¡è®¡å·²é€šè¿‡ã€‚è¯·ç”Ÿæˆä»£ç æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š\n",
    "\n",
    "1. **æ±‚è§£**:\n",
    "   - è°ƒç”¨ `solver.solve(time_limit=60)`ã€‚\n",
    "\n",
    "2. **çµæ•åº¦åˆ†æ (å…³é”®åŠ åˆ†é¡¹)**:\n",
    "   - å¦‚æœæ±‚è§£æˆåŠŸ (Optimal)ï¼Œè°ƒç”¨ `solver.analyze_sensitivity()` è¿›è¡Œçº¿æ€§æ¾å¼›åˆ†æã€‚\n",
    "   - è¯·åœ¨ä»£ç æ³¨é‡Šä¸­ç®€è¦é¢„åˆ¤ï¼šå¦‚æœæŸä¸ªçº¦æŸçš„ Shadow Price å¾ˆé«˜ï¼Œä»£è¡¨ä»€ä¹ˆç‰©ç†æ„ä¹‰ï¼Ÿ\n",
    "\n",
    "3. **ç»“æœå¯¼å‡º**:\n",
    "   - è°ƒç”¨ `solver.export_results()` ç”Ÿæˆ Excel å’Œ LaTeXã€‚\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“œ Phase 5: è®ºæ–‡çº§å¯è§†åŒ– (Visualization)\n",
    "\n",
    "**æ¨¡æ¿æ–‡ä»¶å**ï¼š`Prompt_Phase_5_Viz.txt`\n",
    "**æ³¨æ„**ï¼šè¿™æ˜¯ V6.1 æœ€éœ€è¦äººå·¥å¹²é¢„çš„åœ°æ–¹ï¼Œå› ä¸ºç”»ä»€ä¹ˆå›¾å–å†³äºé¢˜ç›®ã€‚\n",
    "\n",
    "```markdown\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šå¯è§†åŒ–äº¤ä»˜ã€‘\n",
    "\n",
    "è¯·åŸºäº `solver.vars` ä¸­çš„ç»“æœï¼Œä½¿ç”¨ Seaborn ç»˜åˆ¶ä»¥ä¸‹å›¾è¡¨ï¼š\n",
    "\n",
    "**éœ€æ±‚æè¿°**:\n",
    "- [ä¾‹å¦‚ï¼šæˆ‘è¦ä¸€å¼ çƒ­åŠ›å›¾ (Heatmap)ã€‚è¡Œæ˜¯å·¥å‚ï¼Œåˆ—æ˜¯å®¢æˆ·ï¼Œé¢œè‰²æ·±æµ…ä»£è¡¨è¿è¾“é‡ã€‚]\n",
    "- [æˆ–è€…ï¼šæˆ‘è¦ä¸€å¼ æ•£ç‚¹å›¾ (Scatter)ã€‚ç”»å‡ºæ‰€æœ‰åæ ‡ç‚¹ï¼Œç”¨ä¸åŒé¢œè‰²æ ‡è®°â€œå·²é€‰å€â€å’Œâ€œæœªé€‰å€â€çš„ç‚¹ï¼Œå¹¶ç”¨è¿çº¿è¡¨ç¤ºæŒ‡æ´¾å…³ç³»ã€‚]\n",
    "\n",
    "**æŠ€æœ¯è¦æ±‚**:\n",
    "- å¿…é¡»å…ˆæå–å˜é‡å€¼æ„å»ºä¸€ä¸ªæ–°çš„ DataFrame ç”¨äºç»˜å›¾ã€‚\n",
    "- å›¾è¡¨é£æ ¼ï¼š`sns.set_style(\"whitegrid\")`ã€‚\n",
    "- å¿…é¡»åŒ…å«å›¾ä¾‹å’Œæ¸…æ™°çš„åæ ‡è½´æ ‡ç­¾ã€‚\n",
    "- æœ€åä½¿ç”¨ `plt.show()`ã€‚\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ V6.1 å·¥ä½œæµçš„æœ¬è´¨å˜åŒ–\n",
    "\n",
    "| æ­¥éª¤ | æ—§ç‰ˆå·¥ä½œæµ | V6.1 æ–°ç‰ˆå·¥ä½œæµ |\n",
    "| :--- | :--- | :--- |\n",
    "| **Phase 0** | æ‰‹å†™ prompt æè¿°ç±»ï¼Œå®¹æ˜“é”™ | **ä»£ç è‡ªåŠ¨ç”Ÿæˆ Promptï¼Œç›´æ¥å¤åˆ¶** |\n",
    "| **Phase 1** | æ‰‹å†™ `pd.read_csv` | **æŒ‡æŒ¥å®˜æœ¬åœ°å†™ï¼ŒAI åªéœ€è¦çŸ¥é“åˆ—å** |\n",
    "| **Phase 2** | AI çå†™å˜é‡åï¼Œå®¹æ˜“ Key Error | **AI æ ¹æ®æ¡æ‰‹ä¿¡æ¯ä¸­çš„åˆ—åï¼Œç²¾å‡†æ¨å¯¼** |\n",
    "| **Phase 3** | AI å¯èƒ½å¿˜è®°å†™ audit | **API åˆ—è¡¨é‡Œå¼ºåˆ¶æç¤ºäº† audit** |\n",
    "| **Phase 5** | ç”»å›¾ä»£ç ç»å¸¸æŠ¥é”™ (ç‰ˆæœ¬é—®é¢˜) | **ç±»å†…éƒ¨è§£å†³äº†éƒ¨åˆ†å…¼å®¹æ€§ï¼Œå¤–éƒ¨ Prompt åªéœ€æè¿°æ„å›¾** |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ æˆ˜ç•¥æ€»ç»“\n",
    "\n",
    "æŒ‡æŒ¥å®˜ï¼Œæ‚¨çš„æˆ˜ç•¥å›¾æ‹¼å›¾å·²å®Œæˆã€‚ç°åœ¨æ‚¨æ‹¥æœ‰ï¼š\n",
    "\n",
    "1.  **æ ¸å¿ƒæ­¦å™¨**ï¼š`IP_Solver_Capsule` (V6.1 ä»£ç )ã€‚\n",
    "2.  **å‘å°„æŒ‰é’®**ï¼š`generate_handshake` (è‡ªåŠ¨æ¡æ‰‹)ã€‚\n",
    "3.  **åˆ¶å¯¼ç³»ç»Ÿ**ï¼šä¸Šè¿°ä¸‰ä¸ªé˜¶æ®µçš„ `Command_Manual` (å¡«ç©ºæ¨¡æ¿)ã€‚\n",
    "\n",
    "è¿™å°±æ„æˆäº†ä¸€ä¸ªå®Œæ•´çš„é—­ç¯ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd0af9c-2f0b-429f-81dd-d597d20f2eb9",
   "metadata": {},
   "source": [
    "# ç¾èµ› NLP å»ºæ¨¡èƒ¶å›Š V6.2 (The Heavy Weapon)\n",
    "\n",
    "> **ç‰ˆæœ¬æ ¸å¿ƒ**ï¼šé’ˆå¯¹éçº¿æ€§è§„åˆ’ (NLP) çš„æ•°å­¦å¤æ‚æ€§ï¼ŒV6.2 ç‰ˆæœ¬å½»åº•ä¿®å¤äº† Scipy æ¥å£ä¸­å…³äºâ€œå…¨å±€æœç´¢æ— è§†çº¦æŸâ€çš„è‡´å‘½æ•°å­¦æ¼æ´ï¼Œå¹¶å¢åŠ äº†å‘é‡åŒ–å˜é‡å®šä¹‰å’Œå¯è§†åŒ–åœ°è²Œæ‰«æåŠŸèƒ½ã€‚è¿™æ˜¯ä¸€ä¸ªå…·å¤‡â€œæŠ—å±€éƒ¨æœ€ä¼˜â€èƒ½åŠ›çš„å·¥ä¸šçº§æ±‚è§£å™¨ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ›‘ 1. æ·±åº¦è´¨æ£€ï¼šå‘ç°çš„ 3 ä¸ªå…³é”®éšæ‚£\n",
    "\n",
    "ä½œä¸ºæ¶æ„å¸ˆï¼Œæˆ‘ä»¬å‘ç°äº† V6.1 ç‰ˆæœ¬åœ¨ NLP é¢†åŸŸçš„ä¸‰ä¸ªè‡´å‘½çŸ­æ¿ï¼š\n",
    "\n",
    "### 1. è‡´å‘½æ•°å­¦æ¼æ´ï¼šGlobal ç­–ç•¥â€œæ— è§†â€çº¦æŸ\n",
    "* **ç°è±¡**ï¼šAI ç”Ÿæˆçš„ä»£ç ä¸­ï¼Œ`differential_evolution` åªä¼ å…¥äº† boundsï¼Œæ²¡æœ‰ä¼ å…¥ constraintsã€‚\n",
    "* **åæœ**ï¼šå·®åˆ†è¿›åŒ–ç®—æ³•ä¼šå¿½ç•¥æ‰€æœ‰ç­‰å¼/ä¸ç­‰å¼çº¦æŸã€‚æ¯”å¦‚è¦æ±‚ $x+y \\le 10$ï¼Œå®ƒå¯èƒ½ä¼šç®—å‡º $x=100, y=100$ çš„è§£ã€‚\n",
    "* **ä¿®å¤**ï¼šScipy çš„å·®åˆ†è¿›åŒ–éœ€è¦ `NonlinearConstraint` å¯¹è±¡ï¼Œå¿…é¡»åœ¨æ·»åŠ çº¦æŸæ—¶åšåŒé‡å­˜å‚¨ã€‚\n",
    "\n",
    "### 2. å·¥ç¨‹ç¼ºå¤±ï¼šå¯è§†åŒ–ä¸å¯¼å‡ºâ€œå¤±è¸ªâ€\n",
    "* **ç°è±¡**ï¼šæ¡æ‰‹ä¿¡æ¯é‡Œå¹å˜˜äº† `visualize_landscape`ï¼Œä½†ç±»å®šä¹‰é‡Œæ ¹æœ¬æ²¡å†™ã€‚åŒæ—¶ï¼Œ`export_results` ä¹Ÿæ²¡æœ‰å®ç°ã€‚\n",
    "* **åæœ**ï¼šPhase 4 å’Œ Phase 5 ç›´æ¥æŠ¥é”™ï¼Œæ— æ³•ç”Ÿæˆè®ºæ–‡ç´ æã€‚\n",
    "\n",
    "### 3. æ“ä½œç¹çï¼šç¼ºä¹å‘é‡åŒ–æ”¯æŒ\n",
    "* **ç°è±¡**ï¼šNLP é—®é¢˜ï¼ˆå¦‚è½¨è¿¹ä¼˜åŒ–ï¼‰é€šå¸¸æ¶‰åŠæ•°ç»„å˜é‡ ($t_1, t_2... t_{100}$)ã€‚ç°åœ¨çš„ä»£ç éœ€è¦ä¸€ä¸ªä¸ªæ·»åŠ ï¼Œæ•ˆç‡æä½ã€‚\n",
    "* **ä¿®å¤**ï¼šå¢åŠ  `add_variable_array` æ¥å£ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ 2. V6.2 NLP Solver Capsule (ç»ˆæä¿®æ­£ç‰ˆ)\n",
    "\n",
    "è¯·ç”¨ä»¥ä¸‹ä»£ç å®Œå…¨æ›¿æ¢ä¹‹å‰çš„ NLP ç±»ã€‚æ­¤ç‰ˆæœ¬ä¿®å¤äº†ä¸Šè¿°æ‰€æœ‰é—®é¢˜ã€‚\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize, differential_evolution, Bounds, NonlinearConstraint\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# å¿½ç•¥ Scipy çš„ç¹çè­¦å‘Š\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class NLP_Solver_Capsule:\n",
    "    def __init__(self, name=\"NLP_Model\", sense='min'):\n",
    "        \"\"\"\n",
    "        [MCM/ICM NLP Solver V6.2]\n",
    "        ç­–ç•¥ï¼šGradient Descent (Local) + Multi-Start + Differential Evolution (Global)\n",
    "        ä¿®å¤ï¼šæ”¯æŒå…¨å±€ç­–ç•¥çš„éçº¿æ€§çº¦æŸï¼Œæ”¯æŒå‘é‡åŒ–å˜é‡ï¼Œæ”¯æŒç»“æœå¯¼å‡º\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.sense = 1.0 if sense == 'min' else -1.0 \n",
    "        \n",
    "        self.var_names = []      \n",
    "        self.var_bounds = []     \n",
    "        self.x0 = []             \n",
    "        self.objective_func = None \n",
    "        \n",
    "        # åŒé‡å­˜å‚¨çº¦æŸï¼šå…¼å®¹ minimize (dict) å’Œ differential_evolution (Object)\n",
    "        self.constraints = []      \n",
    "        self.de_constraints = []   \n",
    "        \n",
    "        self.result = None       \n",
    "        self.optimal_x = None\n",
    "        self.optimal_fun = None\n",
    "        self.is_solved = False\n",
    "        self.metadata = {'multi_start_history': []}\n",
    "\n",
    "    def generate_handshake(self, df_dict=None):\n",
    "        \"\"\"V6.1 æ¡æ‰‹åè®®\"\"\"\n",
    "        print(f\"\\nğŸ¤ === è¯·å¤åˆ¶ä»¥ä¸‹å†…å®¹å‘é€ç»™ AI (Handshake Prompt) ===\\n\")\n",
    "        print(f\"ã€ç³»ç»Ÿè®¾å®šã€‘\\næˆ‘æ­£åœ¨ä½¿ç”¨ `NLP_Solver_Capsule` (V6.2) å¤„ç†éçº¿æ€§è§„åˆ’é—®é¢˜ã€‚\")\n",
    "        print(f\"ç¯å¢ƒå·²åŠ è½½è¯¥ç±»ï¼Œè¯·ç›´æ¥ä½¿ç”¨å®ä¾‹ `solver`ã€‚\")\n",
    "        \n",
    "        print(\"\\nã€å¯ç”¨æ¥å£ (API)ã€‘\")\n",
    "        print(\"- solver.add_variables(names=['x', 'y'], bounds=[(0,10), (0,10)], init_guesses=[1, 1])\")\n",
    "        print(\"- solver.add_variable_array(prefix='t', count=50, bounds=(0, 100)) # [V6.2] æ‰¹é‡æ·»åŠ \")\n",
    "        print(\"- solver.set_objective(lambda x: x[0]**2 + x[1]) # x æ˜¯å…¨é‡æ‰å¹³æ•°ç»„\")\n",
    "        print(\"- solver.add_constraint(lambda x: x[0] + x[1] - 10, type='ineq') # ineq: f(x)>=0\")\n",
    "        print(\"- solver.audit(is_convex=False)\")\n",
    "        print(\"- solver.solve(strategy='multi_start', n_starts=20)\")\n",
    "        print(\"- solver.analyze_sensitivity(param_idx=0, range_pct=0.2)\")\n",
    "        print(\"- solver.visualize_landscape(x_idx=0, y_idx=1) # [V6.2] äºŒç»´åœ°è²Œæ‰«æ\")\n",
    "        print(\"- solver.export_results() # å¯¼å‡ºç»“æœ\")\n",
    "        \n",
    "        print(\"\\nã€å…³é”®æŒ‡ä»¤ã€‘\")\n",
    "        print(\"1. å¿…é¡»ä½¿ç”¨ `import numpy as np` ä¸­çš„å‡½æ•° (å¦‚ np.sin)ã€‚\")\n",
    "        print(\"2. å˜é‡ x æ˜¯æ‰å¹³æ•°ç»„ï¼Œéœ€é€šè¿‡ x[0] è®¿é—®ã€‚\")\n",
    "        print(\"3. Scipy çº¦æŸç¬¦å·é™·é˜±ï¼šä¸ç­‰å¼(ineq) å¿…é¡»å†™æˆ `è¡¨è¾¾å¼ >= 0`ã€‚\")\n",
    "        \n",
    "        if df_dict:\n",
    "            print(\"\\nã€æ•°æ®æƒ…æŠ¥ã€‘\")\n",
    "            for name, df in df_dict.items():\n",
    "                print(f\"Dataset {name}: {list(df.columns)}\")\n",
    "\n",
    "    def add_variables(self, names, bounds, init_guesses=None):\n",
    "        \"\"\"æ·»åŠ ç¦»æ•£å˜é‡\"\"\"\n",
    "        self.var_names.extend(names)\n",
    "        self.var_bounds.extend(bounds)\n",
    "        if init_guesses:\n",
    "            self.x0.extend(init_guesses)\n",
    "        else:\n",
    "            for b in bounds:\n",
    "                # æ™ºèƒ½åˆå€¼ï¼šå–ä¸­ç‚¹\n",
    "                mid = (b[0] + b[1])/2 if (b[0] is not None and b[1] is not None) else 0\n",
    "                self.x0.append(mid)\n",
    "        print(f\"âœ… å·²æ·»åŠ  {len(names)} ä¸ªå˜é‡ã€‚æ€»ç»´åº¦: {len(self.var_names)}\")\n",
    "\n",
    "    def add_variable_array(self, prefix, count, bounds, init_val=None):\n",
    "        \"\"\"[V6.2] æ‰¹é‡æ·»åŠ å‘é‡å˜é‡\"\"\"\n",
    "        names = [f\"{prefix}_{i}\" for i in range(count)]\n",
    "        bound_list = [bounds] * count\n",
    "        init_list = [init_val] * count if init_val is not None else None\n",
    "        self.add_variables(names, bound_list, init_list)\n",
    "\n",
    "    def set_objective(self, func):\n",
    "        self.objective_func = lambda x: self.sense * func(x)\n",
    "\n",
    "    def add_constraint(self, func, type='ineq', name=\"Constraint\"):\n",
    "        \"\"\"\n",
    "        æ·»åŠ çº¦æŸ\n",
    "        type: 'ineq' (f(x)>=0) or 'eq' (f(x)==0)\n",
    "        \"\"\"\n",
    "        # 1. ä¸º minimize å­˜å‚¨å­—å…¸\n",
    "        self.constraints.append({'type': type, 'fun': func})\n",
    "        \n",
    "        # 2. [V6.2 ä¿®å¤] ä¸ºå·®åˆ†è¿›åŒ–å­˜å‚¨ NonlinearConstraint\n",
    "        if type == 'ineq':\n",
    "            # f(x) >= 0  =>  0 <= f(x) <= inf\n",
    "            self.de_constraints.append(NonlinearConstraint(func, 0, np.inf))\n",
    "        elif type == 'eq':\n",
    "            self.de_constraints.append(NonlinearConstraint(func, 0, 0))\n",
    "        print(f\"ğŸ”— å·²æ·»åŠ çº¦æŸ: {name}\")\n",
    "\n",
    "    def audit(self, is_convex=False):\n",
    "        print(\"\\nğŸ›¡ï¸ === NLP é€»è¾‘å®¡è®¡ ===\")\n",
    "        if not is_convex:\n",
    "            print(\"â„¹ï¸ [éå‡¸é¢„è­¦] å°†å¯ç”¨ Multi-Start ç­–ç•¥ä»¥é¿å…å±€éƒ¨æœ€ä¼˜ã€‚\")\n",
    "        \n",
    "        unbounded = sum(1 for b in self.var_bounds if b[0] is None or b[1] is None)\n",
    "        if unbounded > 0:\n",
    "            print(f\"âš ï¸ [é«˜é£é™©] {unbounded} ä¸ªå˜é‡æ— è¾¹ç•Œã€‚å»ºè®®è®¾ç½®ç‰©ç†è¾¹ç•Œé˜²æ­¢å‘æ•£ã€‚\")\n",
    "        return True\n",
    "\n",
    "    def solve(self, strategy='multi_start', n_starts=20, max_iter=1000):\n",
    "        print(f\"\\nğŸš€ å¼€å§‹æ±‚è§£ (ç­–ç•¥: {strategy})...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # æ„é€  Scipy Bounds\n",
    "        bounds_scipy = Bounds([b[0] if b[0] is not None else -np.inf for b in self.var_bounds],\n",
    "                              [b[1] if b[1] is not None else np.inf for b in self.var_bounds])\n",
    "        \n",
    "        best_res = None\n",
    "        best_fun = np.inf\n",
    "        \n",
    "        if strategy == 'multi_start':\n",
    "            success = 0\n",
    "            for i in range(n_starts):\n",
    "                # éšæœºç”Ÿæˆåˆå€¼\n",
    "                rand_x0 = [np.random.uniform(b[0] if b[0] else -10, b[1] if b[1] else 10) \n",
    "                           for b in self.var_bounds]\n",
    "                res = minimize(self.objective_func, rand_x0, method='SLSQP', \n",
    "                               bounds=bounds_scipy, constraints=self.constraints)\n",
    "                if res.success:\n",
    "                    success += 1\n",
    "                    real_fun = res.fun * self.sense\n",
    "                    self.metadata['multi_start_history'].append(real_fun)\n",
    "                    if res.fun < best_fun:\n",
    "                        best_fun = res.fun\n",
    "                        best_res = res\n",
    "            print(f\"   -> å¤šèµ·ç‚¹æ”¶æ•›ç‡: {success}/{n_starts}\")\n",
    "            if len(self.metadata['multi_start_history']) > 1:\n",
    "                std = np.std(self.metadata['multi_start_history'])\n",
    "                if std > 1e-4: print(f\"âš ï¸ [å¤šå³°è­¦å‘Š] ç»“æœæ ‡å‡†å·® {std:.4f}ï¼Œè§£ä¸ç¨³å®šã€‚\")\n",
    "\n",
    "        elif strategy == 'global':\n",
    "            print(\"   -> å¯åŠ¨å·®åˆ†è¿›åŒ– (Global Search)...\")\n",
    "            # [V6.2 ä¿®å¤] ä¼ å…¥ de_constraints, è®©å…¨å±€æœç´¢ä¹Ÿéµå®ˆçº¦æŸï¼\n",
    "            best_res = differential_evolution(self.objective_func, bounds=self.var_bounds, \n",
    "                                              constraints=self.de_constraints,\n",
    "                                              maxiter=max_iter, seed=42)\n",
    "\n",
    "        else: # local\n",
    "            best_res = minimize(self.objective_func, self.x0, method='SLSQP', \n",
    "                                bounds=bounds_scipy, constraints=self.constraints)\n",
    "\n",
    "        if best_res and best_res.success:\n",
    "            self.result = best_res\n",
    "            self.optimal_x = best_res.x\n",
    "            self.optimal_fun = best_res.fun * self.sense\n",
    "            self.is_solved = True\n",
    "            print(f\"ğŸ’ æœ€ä¼˜å€¼: {self.optimal_fun:,.4f}\")\n",
    "        else:\n",
    "            print(f\"âŒ æ±‚è§£å¤±è´¥: {best_res.message if best_res else 'No solution'}\")\n",
    "        print(f\"â±ï¸ è€—æ—¶: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "    def analyze_sensitivity(self, param_idx, range_pct=0.2):\n",
    "        \"\"\"å•å˜é‡çµæ•åº¦\"\"\"\n",
    "        if not self.is_solved: return\n",
    "        name = self.var_names[param_idx]\n",
    "        print(f\"\\nğŸ” çµæ•åº¦æ‰«æ: {name}\")\n",
    "        center = self.optimal_x[param_idx]\n",
    "        delta = abs(center * range_pct) if center != 0 else 1.0\n",
    "        vals = np.linspace(center - delta, center + delta, 50)\n",
    "        objs = []\n",
    "        base_x = self.optimal_x.copy()\n",
    "        for v in vals:\n",
    "            base_x[param_idx] = v\n",
    "            objs.append(self.objective_func(base_x) * self.sense)\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.plot(vals, objs)\n",
    "        plt.axvline(center, color='r', linestyle='--')\n",
    "        plt.title(f'Sensitivity: {name}')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_landscape(self, idx1=0, idx2=1, points=30):\n",
    "        \"\"\"[V6.2] äºŒç»´åœ°è²Œç­‰é«˜çº¿æ‰«æ\"\"\"\n",
    "        if not self.is_solved: return\n",
    "        print(f\"\\nğŸ—ºï¸ ç”Ÿæˆåœ°è²Œæ‰«æ: {self.var_names[idx1]} vs {self.var_names[idx2]}\")\n",
    "        c1, c2 = self.optimal_x[idx1], self.optimal_x[idx2]\n",
    "        r1 = abs(c1)*0.5 if c1!=0 else 1.0\n",
    "        r2 = abs(c2)*0.5 if c2!=0 else 1.0\n",
    "        x = np.linspace(c1-r1, c1+r1, points)\n",
    "        y = np.linspace(c2-r2, c2+r2, points)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.zeros_like(X)\n",
    "        base_x = self.optimal_x.copy()\n",
    "        for i in range(points):\n",
    "            for j in range(points):\n",
    "                base_x[idx1], base_x[idx2] = X[i,j], Y[i,j]\n",
    "                Z[i,j] = self.objective_func(base_x) * self.sense\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        cp = plt.contourf(X, Y, Z, levels=20, cmap='viridis')\n",
    "        plt.colorbar(cp, label='Objective')\n",
    "        plt.plot(c1, c2, 'r*', markersize=15, label='Optimal')\n",
    "        plt.xlabel(self.var_names[idx1])\n",
    "        plt.ylabel(self.var_names[idx2])\n",
    "        plt.title(f'Optimization Landscape')\n",
    "        plt.show()\n",
    "\n",
    "    def export_results(self):\n",
    "        \"\"\"[V6.1 è¡¥å…¨] ç»“æœå¯¼å‡º\"\"\"\n",
    "        if not self.is_solved: return\n",
    "        df = pd.DataFrame({\n",
    "            'Variable': self.var_names, 'Value': self.optimal_x,\n",
    "            'Lower': [b[0] for b in self.var_bounds], 'Upper': [b[1] for b in self.var_bounds]\n",
    "        })\n",
    "        filename = f\"{self.name}_Solution.xlsx\"\n",
    "        df.to_excel(filename, index=False)\n",
    "        print(f\"\\nğŸ’¾ å·²ä¿å­˜: {filename}\")\n",
    "        print(df.head(5).to_latex(index=False, float_format=\"%.4f\"))\n",
    "\n",
    "    def get_methodology(self):\n",
    "        return r\"\"\"\n",
    "        \\subsection{Non-Linear Optimization Strategy}\n",
    "        We formulated the problem as a Non-Linear Programming (NLP) model. \n",
    "        To mitigate the risk of local optima inherent in non-convex problems, we employed a **Multi-Start Strategy** using the SLSQP algorithm. \n",
    "        Global optimality was cross-validated using **Differential Evolution** under strict constraints.\n",
    "        \"\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ 3. V6.2 æŒ‡æŒ¥å®˜å·¥ä½œæµä¸ Prompt\n",
    "\n",
    "é’ˆå¯¹ NLP çš„æ•°å­¦ç‰¹æ®Šæ€§ï¼Œä½ çš„ Prompt å¿…é¡»åŒ…å«**ç¬¦å·è½¬åŒ–**å’Œ**ç‰©ç†æ„ä¹‰æ£€æŸ¥**ã€‚\n",
    "\n",
    "### Phase 2: é€»è¾‘æ³¨å…¥ (NLP ä¸“ç”¨ç‰ˆ)\n",
    "**æ¨¡æ¿æ–‡ä»¶å**ï¼š`Prompt_NLP_Phase_2_Logic.txt`\n",
    "\n",
    "```markdown\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šNLP å˜é‡ä¸é€»è¾‘æ„å»ºã€‘\n",
    "\n",
    "åŸºäºæ¡æ‰‹ä¿¡æ¯ï¼Œè¯·ç¼–å†™ä»£ç ï¼š\n",
    "\n",
    "1. **å˜é‡å®šä¹‰**:\n",
    "   - ä½¿ç”¨ `add_variable_array` å®šä¹‰å‘é‡å˜é‡ï¼š[ä¾‹å¦‚ï¼šprefix='t', count=50, bounds=(0, 100)]\n",
    "   - æˆ–ä½¿ç”¨ `add_variables` å®šä¹‰ç¦»æ•£å˜é‡ã€‚\n",
    "\n",
    "2. **æ•°å­¦é€»è¾‘ (å…³é”®)**:\n",
    "   - ç›®æ ‡å‡½æ•°ï¼š`solver.set_objective(lambda x: ...)`\n",
    "   - **æ³¨æ„**ï¼šå¿…é¡»ä½¿ç”¨ `np` åº“å‡½æ•°ï¼ˆå¦‚ `np.sin`ï¼‰ï¼Œä¸¥ç¦ä½¿ç”¨ `math` åº“ã€‚\n",
    "   - çº¦æŸå®šä¹‰ï¼š`solver.add_constraint(lambda x: ..., type='ineq')`\n",
    "   - **ç¬¦å·é™·é˜±**ï¼šScipy çš„ ineq å®šä¹‰æ˜¯ **f(x) >= 0**ã€‚\n",
    "     - å¦‚æœé¢˜ç›®è¦æ±‚ **A <= B**ï¼Œä»£ç å¿…é¡»å†™ä¸º **B - A**ã€‚\n",
    "     - å¦‚æœé¢˜ç›®è¦æ±‚ **A >= B**ï¼Œä»£ç å¿…é¡»å†™ä¸º **A - B**ã€‚\n",
    "\n",
    "3. **åŠ¨ä½œ**:\n",
    "   - è°ƒç”¨ `solver.audit(is_convex=False)`ã€‚\n",
    "```\n",
    "\n",
    "### Phase 3 & 4: æ±‚è§£ä¸éªŒè¯ (NLP ä¸“ç”¨ç‰ˆ)\n",
    "**æ¨¡æ¿æ–‡ä»¶å**ï¼š`Prompt_NLP_Phase_3_Solve.txt`\n",
    "\n",
    "```markdown\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šæ±‚è§£ä¸éªŒè¯ã€‘\n",
    "\n",
    "1. **æ±‚è§£**:\n",
    "   - è¿™æ˜¯ä¸€ä¸ªéå‡¸é—®é¢˜ï¼Œè¯·ä½¿ç”¨ **Multi-Start** ç­–ç•¥ä»¥è§„é¿å±€éƒ¨æœ€ä¼˜ã€‚\n",
    "   - ä»£ç ï¼š`solver.solve(strategy='multi_start', n_starts=20)`ã€‚\n",
    "\n",
    "2. **éªŒè¯ (å…³é”®)**:\n",
    "   - ç»˜åˆ¶å‰ä¸¤ä¸ªå…³é”®å˜é‡çš„åœ°è²Œå›¾ï¼š`solver.visualize_landscape(idx1=0, idx2=1)`ã€‚\n",
    "   - **ç‰©ç†æ£€æŸ¥**ï¼šè¯·åœ¨æ³¨é‡Šä¸­åˆ†æï¼šæœ€ä¼˜è§£æ˜¯å¦è½åœ¨äº†è¾¹ç•Œä¸Šï¼Ÿï¼ˆå¦‚æœåœ¨è¾¹ç•Œï¼Œè¯´æ˜è¯¥èµ„æºæ˜¯ç“¶é¢ˆï¼‰ã€‚\n",
    "\n",
    "3. **äº¤ä»˜**:\n",
    "   - `solver.export_results()`ã€‚\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“† 4. åç»­â€œé‡äº§â€è·¯çº¿å›¾\n",
    "\n",
    "ä½ ç°åœ¨æ‹¥æœ‰äº†æœ€å¼ºçš„ **IP (V6.1)** å’Œ **NLP (V6.2)** èƒ¶å›Šã€‚æ¥ä¸‹æ¥çš„å·¥ä½œæµåˆ¶ä½œï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹é¡ºåºæ”»å…‹ï¼š\n",
    "\n",
    "1.  **Graph (å›¾è®º)**ï¼šæ ¸å¿ƒç—›ç‚¹æ˜¯ç”»å›¾ä¸‘ï¼Œå¿…é¡»é›†æˆ `nx.kamada_kawai_layout`ã€‚\n",
    "2.  **ODE (å¾®åˆ†æ–¹ç¨‹)**ï¼šæ ¸å¿ƒç—›ç‚¹æ˜¯å‚æ•°éš¾å®šï¼Œå¿…é¡»å¢åŠ  `fit_parameters(real_data)` æ–¹æ³•ã€‚\n",
    "3.  **Stats (é¢„æµ‹)**ï¼šé›†æˆ `Prophet` è¿›è¡Œå‚»ç“œå¼æ—¶é—´åºåˆ—é¢„æµ‹ã€‚\n",
    "\n",
    "è¯·å…ˆæ›´æ–°ä½ çš„ NLP Notebookï¼Œç„¶åæŒ‰ç…§è¿™ä¸ªæ ‡å‡†å»ç”Ÿäº§ Graph èƒ¶å›Šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f9d078-5dbe-48ab-853e-2f9e6f46f267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
