{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8adef017-3a8a-45f4-9b5f-4fd59e525ad6",
   "metadata": {},
   "source": [
    "## âœ… V7.0 éœ€æ±‚éªŒæ”¶æ¸…å• (Checklist)\n",
    "\n",
    "| æ¨¡å— | éœ€æ±‚ç‚¹ | å®Œæˆæƒ…å†µ | V7.0 å¢å¼ºç‰¹æ€§ |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **åº“ä¾èµ–** | `networkx`, `pandas`, etc. | âœ… å·²å®ç° | åŠ å…¥ `community` å’Œ `scienceplots` çš„ try-except å…¼å®¹ä¿æŠ¤ã€‚ |\n",
    "| **1. æ¡æ‰‹** | `generate_handshake` | âœ… å·²å®ç° | ä¸»åŠ¨è¾“å‡º API æ¸…å•ã€æ•°æ®æ‘˜è¦ï¼Œå¹¶è­¦å‘Šè´Ÿæƒè¾¹ä¸è¿é€šæ€§é™·é˜±ã€‚ |\n",
    "| **2. æ„å»º** | `audit` è‡ªæ£€ | âœ… å·²å®ç° | è‡ªåŠ¨æ£€æµ‹å­¤ç«‹ç‚¹ã€è‡ªç¯ï¼›è‹¥ä¸è¿é€šï¼Œä¸»åŠ¨å»ºè®®æå–â€œæœ€å¤§è¿é€šå­å›¾â€ã€‚ |\n",
    "| **3. æŒ‡æ ‡** | `compute_centrality` | âœ… å·²å®ç° | æ¶µç›– Degree, Betweenness, Closeness, Eigenvectorã€‚ |\n",
    "| **4. æ ¸æ­¦å™¨** | `detect_communities` | âœ… å·²å®ç° | é›†æˆ Louvain ç®—æ³•ï¼Œè®¡ç®—æ¨¡å—åº¦ (Modularity)ï¼Œè‡ªåŠ¨åˆ†é… IDã€‚ |\n",
    "| **4. æ ¸æ­¦å™¨** | `analyze_robustness` | âœ… å·²å®ç° | åŒæ¨¡å¼æ”»å‡» (è“„æ„ vs éšæœº)ï¼›ç»˜åˆ¶å´©æºƒæ›²çº¿ (Giant Component & Efficiency)ã€‚ |\n",
    "| **5. å¯è§†åŒ–** | `plot_network` | âœ… å·²å®ç° | ä¼˜å…ˆä½¿ç”¨ `kamada_kawai`ï¼›æ™ºèƒ½é˜²å¡æ­» (èŠ‚ç‚¹>1000è‡ªåŠ¨é™çº§)ï¼›ä»…æ ‡æ³¨ Top 10ã€‚ |\n",
    "| **5. é«˜é˜¶** | `export_to_gephi` | âœ… å·²å®ç° | å¯¼å‡º `.gexf` æ–‡ä»¶ï¼Œå±æ€§ç±»å‹è‡ªåŠ¨æ¸…æ´— (é˜²æ­¢ Numpy ç±»å‹æŠ¥é”™)ã€‚ |\n",
    "| **6. äº¤ä»˜** | `export_results` | âœ… å·²å®ç° | è‡ªåŠ¨ç”Ÿæˆ Excel, SVG, GEXFï¼Œä»¥åŠåŒ…å«è‡ªç„¶è¯­è¨€ç»“è®ºçš„ `Report.md`ã€‚ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff255b78-2130-458c-a80b-1a8a24e4b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "# --- V7.0 ç»˜å›¾ç¾å­¦é…ç½® (Aesthetic Setup) ---\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'SimHei'] # é€‚é…ä¸­è‹±æ–‡\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "try:\n",
    "    import scienceplots\n",
    "    plt.style.use(['science', 'no-latex']) # å­¦æœ¯é£æ ¼\n",
    "except ImportError:\n",
    "    # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ Seaborn ä¼˜åŒ–\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"deep\", context=\"paper\")\n",
    "\n",
    "class Graph_Solver_Capsule:\n",
    "    def __init__(self, name=\"Graph_Model\", is_directed=False):\n",
    "        \"\"\"\n",
    "        [MCM Graph Solver V7.0 - Final Version]\n",
    "        æ¶æ„: 1.Audit -> 2.Metrics -> 3.Deep Analysis -> 4.Auto-Delivery\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.is_directed = is_directed\n",
    "        self.timestamp = int(time.time())\n",
    "        self.G = None\n",
    "        \n",
    "        # ç»“æœå­˜å‚¨å®¹å™¨\n",
    "        self.node_metrics = pd.DataFrame()\n",
    "        self.robustness_log = {} # è®°å½•æ”»å‡»æµ‹è¯•çš„å…³é”®ç»“è®º\n",
    "        \n",
    "        # è‡ªåŠ¨åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "        self.output_dir = f\"./Results_{name}_{self.timestamp}\"\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 0: æ¡æ‰‹ä¸åè®® (Setup & Handshake)\n",
    "    # ======================================================\n",
    "    def generate_handshake(self, df_dict=None):\n",
    "        print(f\"\\nğŸ¤ === å¤åˆ¶ä»¥ä¸‹ Prompt å‘é€ç»™ AI (V7.0 Graph) ===\\n\")\n",
    "        print(f\"ã€ç³»ç»Ÿè®¾å®šã€‘\\næˆ‘æ­£åœ¨ä½¿ç”¨ `Graph_Solver_Capsule` (V7.0)ã€‚\")\n",
    "        print(f\"å›¾ç±»å‹: {'æœ‰å‘å›¾ (DiGraph)' if self.is_directed else 'æ— å‘å›¾ (Graph)'}ã€‚\")\n",
    "        print(f\"è¾“å‡ºç›®å½•: `{self.output_dir}`\")\n",
    "        \n",
    "        print(\"\\nã€API æ¥å£æ¸…å•ã€‘\")\n",
    "        print(\"1. æ„å»º: solver.build_from_edgelist(df, source='S', target='T', weight='W')\")\n",
    "        print(\"2. è‡ªæ£€: solver.audit() # å¿…é¡»æ‰§è¡Œï¼Œé€»è¾‘è‡ªæ£€\")\n",
    "        print(\"3. æŒ‡æ ‡: solver.compute_centrality()\")\n",
    "        print(\"4. [æ ¸æ­¦å™¨] ç¤¾å›¢: solver.detect_communities(method='louvain')\")\n",
    "        print(\"5. [æ ¸æ­¦å™¨] é²æ£’æ€§: solver.analyze_robustness(attack_type='targeted', fraction=0.3)\")\n",
    "        print(\"6. [å¯è§†åŒ–] ç»˜å›¾: solver.plot_network(layout='kamada_kawai')\")\n",
    "        print(\"7. [äº¤ä»˜] å¯¼å‡º: solver.export_results() # ç”Ÿæˆå…¨å¥—äº¤ä»˜ç‰©\")\n",
    "        \n",
    "        print(\"\\nã€âš ï¸ å¿…é¡»æ³¨æ„çš„å›¾è®ºé™·é˜±ã€‘\")\n",
    "        print(\"1. **è´Ÿæƒè¾¹ (Negative Weights)**: å¦‚å­˜åœ¨ï¼ŒDijkstra å¤±æ•ˆï¼Œè¯·æç¤ºä½¿ç”¨ Bellman-Fordã€‚\")\n",
    "        print(\"2. **è¿é€šæ€§ (Connectivity)**: è‹¥å›¾ä¸è¿é€šï¼ŒGlobal Efficiency æ— ç‰©ç†æ„ä¹‰ã€‚å»ºè®®æå– LCC (Largest Connected Component)ã€‚\")\n",
    "        print(\"3. **å¼º/å¼±è¿é€š**: æœ‰å‘å›¾ä¸­è¯·åŒºåˆ† Strong (åŒå‘å¯è¾¾) vs Weak (å¿½ç•¥æ–¹å‘)ã€‚\")\n",
    "        \n",
    "        if df_dict:\n",
    "            print(\"\\nã€æ•°æ®æ‘˜è¦ã€‘\")\n",
    "            for name, df in df_dict.items():\n",
    "                print(f\"Dataset '{name}': {list(df.columns)} | Rows: {len(df)}\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 1: æ„å»ºä¸è‡ªæ£€ (Build & Audit)\n",
    "    # ======================================================\n",
    "    def build_from_edgelist(self, df, source, target, weight=None):\n",
    "        print(f\"\\nğŸ—ï¸ æ­£åœ¨æ„å»ºç½‘ç»œ...\")\n",
    "        create_using = nx.DiGraph() if self.is_directed else nx.Graph()\n",
    "        \n",
    "        try:\n",
    "            # è‡ªåŠ¨å¤„ç†åˆ—åç©ºæ ¼é—®é¢˜\n",
    "            self.G = nx.from_pandas_edgelist(df, source=source, target=target, edge_attr=weight, create_using=create_using)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æ„å»ºå¤±è´¥: {e}\")\n",
    "            return\n",
    "\n",
    "        print(f\"âœ… ç½‘ç»œæ„å»ºå®Œæˆã€‚Nodes: {self.G.number_of_nodes()}, Edges: {self.G.number_of_edges()}\")\n",
    "        # åˆå§‹åŒ–æŒ‡æ ‡è¡¨\n",
    "        self.node_metrics = pd.DataFrame(index=list(self.G.nodes()))\n",
    "        self.node_metrics.index.name = 'Node_ID'\n",
    "\n",
    "    def audit(self):\n",
    "        print(\"\\nğŸ›¡ï¸ === é€»è¾‘å®¡è®¡ (Network Audit) =====\")\n",
    "        if self.G is None: raise ValueError(\"âŒ å›¾æœªæ„å»ºã€‚\")\n",
    "        \n",
    "        # 1. è¿é€šæ€§æ£€æŸ¥\n",
    "        if self.is_directed:\n",
    "            n_comp = nx.number_strongly_connected_components(self.G)\n",
    "            n_weak = nx.number_weakly_connected_components(self.G)\n",
    "            print(f\"info: å¼ºè¿é€šåˆ†é‡: {n_comp}, å¼±è¿é€šåˆ†é‡: {n_weak}\")\n",
    "            if n_weak > 1: print(\"âš ï¸ è­¦å‘Š: ç½‘ç»œä¸æ˜¯(å¼±)è¿é€šçš„ï¼\")\n",
    "        else:\n",
    "            n_comp = nx.number_connected_components(self.G)\n",
    "            print(f\"info: è¿é€šåˆ†é‡: {n_comp}\")\n",
    "            if n_comp > 1:\n",
    "                largest = len(max(nx.connected_components(self.G), key=len))\n",
    "                ratio = largest / len(self.G)\n",
    "                print(f\"âš ï¸ è­¦å‘Š: ç½‘ç»œä¸è¿é€šï¼æœ€å¤§è¿é€šå­å›¾(LCC)å æ¯”: {ratio:.1%}\")\n",
    "                print(\"ğŸ’¡ å»ºè®®: åœ¨è®ºæ–‡ä¸­å£°æ˜â€œåç»­åˆ†æåŸºäºæœ€å¤§è¿é€šå­å›¾(LCC)â€ã€‚\")\n",
    "\n",
    "        # 2. å­¤ç«‹ç‚¹\n",
    "        isolates = list(nx.isolates(self.G))\n",
    "        if isolates:\n",
    "            print(f\"âš ï¸ è­¦å‘Š: å‘ç° {len(isolates)} ä¸ªå­¤ç«‹ç‚¹ (Isolates)ã€‚å»ºè®®é¢„å¤„ç†ç§»é™¤ã€‚\")\n",
    "            \n",
    "        # 3. è‡ªç¯\n",
    "        loops = list(nx.selfloop_edges(self.G))\n",
    "        if loops:\n",
    "            print(f\"âš ï¸ è­¦å‘Š: å‘ç° {len(loops)} æ¡è‡ªç¯ã€‚\")\n",
    "        \n",
    "        print(\"âœ… å®¡è®¡ç»“æŸã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 2: åŸºç¡€æŒ‡æ ‡ (Metrics)\n",
    "    # ======================================================\n",
    "    def compute_centrality(self):\n",
    "        print(f\"\\nğŸ“ è®¡ç®—ä¸­å¿ƒåº¦æŒ‡æ ‡...\")\n",
    "        \n",
    "        # Degree\n",
    "        if self.is_directed:\n",
    "            self.node_metrics['In_Degree'] = pd.Series(nx.in_degree_centrality(self.G))\n",
    "            self.node_metrics['Out_Degree'] = pd.Series(nx.out_degree_centrality(self.G))\n",
    "        else:\n",
    "            self.node_metrics['Degree'] = pd.Series(nx.degree_centrality(self.G))\n",
    "            \n",
    "        # Betweenness (å¤§å›¾ä¼˜åŒ–ï¼šé‡‡æ ·)\n",
    "        if len(self.G) > 2000:\n",
    "            print(\"âš ï¸ è­¦å‘Š: èŠ‚ç‚¹æ•°>2000ï¼Œå¯ç”¨ k=100 é‡‡æ ·åŠ é€Ÿè®¡ç®— Betweennessã€‚\")\n",
    "            bet = nx.betweenness_centrality(self.G, k=100)\n",
    "        else:\n",
    "            bet = nx.betweenness_centrality(self.G)\n",
    "        self.node_metrics['Betweenness'] = pd.Series(bet)\n",
    "        \n",
    "        # Closeness\n",
    "        self.node_metrics['Closeness'] = pd.Series(nx.closeness_centrality(self.G))\n",
    "        \n",
    "        # Eigenvector (å¤„ç†ä¸æ”¶æ•›)\n",
    "        try:\n",
    "            eig = nx.eigenvector_centrality(self.G, max_iter=600)\n",
    "            self.node_metrics['Eigenvector'] = pd.Series(eig)\n",
    "        except:\n",
    "            print(\"âš ï¸ Eigenvector æœªæ”¶æ•›ï¼Œå¡«å…… 0ã€‚\")\n",
    "            self.node_metrics['Eigenvector'] = 0.0\n",
    "\n",
    "        print(\"âœ… åŸºç¡€æŒ‡æ ‡å·²å­˜å…¥ self.node_metricsã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 3: æ·±åº¦åˆ†æ (Deep Analysis - Oå¥–æ ¸æ­¦å™¨)\n",
    "    # ======================================================\n",
    "    def detect_communities(self, method='louvain'):\n",
    "        print(f\"\\nğŸ§© å¯åŠ¨ç¤¾å›¢æ£€æµ‹ (Method: {method})...\")\n",
    "        if method == 'louvain':\n",
    "            try:\n",
    "                import community.community_louvain as community_louvain\n",
    "                # Louvain éœ€è½¬æ— å‘\n",
    "                g_temp = self.G.to_undirected() if self.is_directed else self.G\n",
    "                partition = community_louvain.best_partition(g_temp)\n",
    "                modularity = community_louvain.modularity(partition, g_temp)\n",
    "                \n",
    "                self.node_metrics['Community_ID'] = self.node_metrics.index.map(partition)\n",
    "                print(f\"âœ… ç¤¾å›¢åˆ’åˆ†å®Œæˆ (Louvain)ã€‚Modularity Q={modularity:.4f}\")\n",
    "                print(f\"   å…±å‘ç° {len(set(partition.values()))} ä¸ªç¤¾å›¢ã€‚\")\n",
    "                return modularity\n",
    "            except ImportError:\n",
    "                print(\"âŒ æœªå®‰è£… `python-louvain`ã€‚è¯· pip install python-louvainã€‚\")\n",
    "        else:\n",
    "            print(\"âš ï¸ ç›®å‰ä»…å°è£…äº† Louvain ç®—æ³•ã€‚\")\n",
    "\n",
    "    def analyze_robustness(self, attack_type='targeted', fraction=0.3):\n",
    "        \"\"\"\n",
    "        [æ ¸æ­¦å™¨] é²æ£’æ€§åˆ†æ\n",
    "        è¾“å‡ºï¼šRobustness_Curve.svg\n",
    "        \"\"\"\n",
    "        print(f\"\\nğŸ’£ å¯åŠ¨é²æ£’æ€§åˆ†æ (Type: {attack_type}, Remove: {fraction*100:.0f}%)...\")\n",
    "        \n",
    "        # 1. å‡†å¤‡å‰¯æœ¬ (è½¬æ— å‘ä»¥åˆ†æè¿é€šæ€§)\n",
    "        G_sim = self.G.copy()\n",
    "        if self.is_directed: G_sim = G_sim.to_undirected()\n",
    "        \n",
    "        N = G_sim.number_of_nodes()\n",
    "        remove_count = int(N * fraction)\n",
    "        \n",
    "        # 2. ç¡®å®šç§»é™¤åˆ—è¡¨\n",
    "        if attack_type == 'targeted':\n",
    "            # æŒ‰åº¦é™åº (è“„æ„æ”»å‡»)\n",
    "            nodes_sorted = sorted(G_sim.degree, key=lambda x: x[1], reverse=True)\n",
    "            targets = [n[0] for n in nodes_sorted]\n",
    "        else:\n",
    "            # éšæœºä¹±åº (éšæœºæ•…éšœ)\n",
    "            targets = list(G_sim.nodes())\n",
    "            random.shuffle(targets)\n",
    "            \n",
    "        targets = targets[:remove_count]\n",
    "        \n",
    "        # 3. æ¨¡æ‹Ÿæ”»å‡» (ä½¿ç”¨ np.linspace å‡å°‘ç»˜å›¾ç‚¹æ•°ï¼Œæé«˜æ•ˆç‡)\n",
    "        steps = np.unique(np.linspace(0, remove_count, 25, dtype=int))\n",
    "        \n",
    "        history = {'Removed_Pct': [], 'Giant_Component': [], 'Efficiency': []}\n",
    "        \n",
    "        # è®¡ç®—åŸºå‡†æ•ˆç‡ (å¤§å›¾è·³è¿‡)\n",
    "        calc_eff = N < 1500\n",
    "        base_eff = nx.global_efficiency(G_sim) if calc_eff else 1.0\n",
    "        \n",
    "        current_removed = 0\n",
    "        for target_count in steps:\n",
    "            # ç§»é™¤å¢é‡\n",
    "            to_remove = target_count - current_removed\n",
    "            if to_remove > 0:\n",
    "                nodes_to_drop = targets[current_removed : target_count]\n",
    "                G_sim.remove_nodes_from(nodes_to_drop)\n",
    "                current_removed = target_count\n",
    "            \n",
    "            # è®°å½• X è½´\n",
    "            history['Removed_Pct'].append(current_removed / N)\n",
    "            \n",
    "            # è®°å½• Y1: æœ€å¤§è¿é€šå­å›¾å æ¯”\n",
    "            if len(G_sim) > 0:\n",
    "                lc = len(max(nx.connected_components(G_sim), key=len))\n",
    "                history['Giant_Component'].append(lc / N)\n",
    "            else:\n",
    "                history['Giant_Component'].append(0)\n",
    "                \n",
    "            # è®°å½• Y2: å…¨å±€æ•ˆç‡ (ç›¸å¯¹å€¼)\n",
    "            if calc_eff:\n",
    "                eff = nx.global_efficiency(G_sim)\n",
    "                history['Efficiency'].append(eff / base_eff)\n",
    "            else:\n",
    "                history['Efficiency'].append(0)\n",
    "                \n",
    "        # 4. ç»˜å›¾\n",
    "        df_res = pd.DataFrame(history)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(df_res['Removed_Pct'], df_res['Giant_Component'], 'o-', label='Giant Component Size', color='#d62728', lw=2)\n",
    "        if calc_eff:\n",
    "            plt.plot(df_res['Removed_Pct'], df_res['Efficiency'], 's--', label='Global Efficiency', color='#1f77b4', lw=2)\n",
    "            \n",
    "        plt.title(f\"Network Robustness: {attack_type.title()} Attack\")\n",
    "        plt.xlabel(\"Fraction of Nodes Removed\")\n",
    "        plt.ylabel(\"Relative Metric Score\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(f\"{self.output_dir}/Robustness_Curve_{attack_type}.svg\", dpi=300)\n",
    "        plt.show()\n",
    "        \n",
    "        # è®°å½•ç»“è®º\n",
    "        collapse_val = df_res[df_res['Giant_Component'] < 0.5].iloc[0]['Removed_Pct'] if (df_res['Giant_Component'] < 0.5).any() else 1.0\n",
    "        self.robustness_log[attack_type] = collapse_val\n",
    "        print(f\"âœ… é²æ£’æ€§åˆ†æå®Œæˆã€‚å´©æºƒç‚¹ (GC<0.5) çº¦åœ¨ç§»é™¤ {collapse_val:.1%} èŠ‚ç‚¹æ—¶ã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 4: é¡¶çº§å¯è§†åŒ– (Visualization)\n",
    "    # ======================================================\n",
    "    def plot_network(self, layout='kamada_kawai'):\n",
    "        print(f\"\\nğŸ¨ ç»˜åˆ¶ç½‘ç»œå›¾ (Layout: {layout})...\")\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        \n",
    "        # 1. å¸ƒå±€å®‰å…¨é™çº§é€»è¾‘ (é˜²æ­¢ Kamada-Kawai å¡æ­»)\n",
    "        pos = None\n",
    "        if layout == 'kamada_kawai':\n",
    "            if len(self.G) > 1000:\n",
    "                print(\"âš ï¸ èŠ‚ç‚¹æ•° > 1000ï¼Œå¼ºåˆ¶é™çº§ä¸º spring_layout ä»¥é˜²å¡æ­»ã€‚\")\n",
    "                pos = nx.spring_layout(self.G, seed=42)\n",
    "            else:\n",
    "                try:\n",
    "                    pos = nx.kamada_kawai_layout(self.G)\n",
    "                except:\n",
    "                    pos = nx.spring_layout(self.G, seed=42)\n",
    "        else:\n",
    "            pos = nx.spring_layout(self.G, seed=42)\n",
    "            \n",
    "        # 2. æ ·å¼æ˜ å°„\n",
    "        deg = dict(self.G.degree())\n",
    "        # å¤§å°å½’ä¸€åŒ–\n",
    "        sizes = [v * 5 + 30 for v in deg.values()] \n",
    "        \n",
    "        # é¢œè‰²æ˜ å°„ (ç¤¾å›¢ or é»˜è®¤)\n",
    "        if 'Community_ID' in self.node_metrics.columns:\n",
    "            colors = self.node_metrics.loc[list(self.G.nodes()), 'Community_ID']\n",
    "            cmap = 'tab20'\n",
    "        else:\n",
    "            colors = '#69b3a2'\n",
    "            cmap = None\n",
    "            \n",
    "        # 3. ç»˜åˆ¶\n",
    "        nx.draw_networkx_nodes(self.G, pos, node_size=sizes, node_color=colors, cmap=cmap, alpha=0.9, edgecolors='white')\n",
    "        nx.draw_networkx_edges(self.G, pos, alpha=0.2, edge_color='gray')\n",
    "        \n",
    "        # 4. æ™ºèƒ½æ ‡ç­¾ (ä»… Top 10)\n",
    "        top_nodes = sorted(deg.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        for node, val in top_nodes:\n",
    "            x, y = pos[node]\n",
    "            plt.text(x, y+0.03, str(node), fontsize=11, fontweight='bold', ha='center', \n",
    "                     bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=1))\n",
    "\n",
    "        plt.title(f\"Network Visualization ({self.name})\", fontsize=16)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"{self.output_dir}/Network_Viz.svg\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    def export_to_gephi(self):\n",
    "        try:\n",
    "            # å±æ€§æ³¨å…¥ (ç±»å‹è½¬æ¢é˜²æ­¢æŠ¥é”™)\n",
    "            for col in self.node_metrics.columns:\n",
    "                attrs = {k: float(v) if isinstance(v, float) else int(v) \n",
    "                         for k, v in self.node_metrics[col].to_dict().items()}\n",
    "                nx.set_node_attributes(self.G, attrs, col)\n",
    "            nx.write_gexf(self.G, f\"{self.output_dir}/{self.name}.gexf\")\n",
    "            print(\"âœ… Gephi æ–‡ä»¶å·²ç”Ÿæˆ (.gexf)ã€‚\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Gephi å¯¼å‡ºè·³è¿‡: {e}\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 5: äº¤ä»˜ (Delivery)\n",
    "    # ======================================================\n",
    "    def export_results(self):\n",
    "        print(f\"\\nğŸ“¦ === ç”Ÿæˆäº¤ä»˜ç‰©è‡³ {self.output_dir} === \")\n",
    "        \n",
    "        # 1. Excel\n",
    "        self.node_metrics.to_excel(f\"{self.output_dir}/Node_Metrics.xlsx\")\n",
    "        \n",
    "        # 2. Gephi\n",
    "        self.export_to_gephi()\n",
    "        \n",
    "        # 3. æ™ºèƒ½æˆ˜æŠ¥ (Auto-Report.md)\n",
    "        report = f\"# V7.0 Graph Analysis Report: {self.name}\\n\\n\"\n",
    "        \n",
    "        report += \"## 1. Network Summary\\n\"\n",
    "        report += f\"- **Type**: {'Directed' if self.is_directed else 'Undirected'}\\n\"\n",
    "        report += f\"- **Nodes**: {self.G.number_of_nodes()}, **Edges**: {self.G.number_of_edges()}\\n\"\n",
    "        report += f\"- **Density**: {nx.density(self.G):.4f}\\n\\n\"\n",
    "        \n",
    "        report += \"## 2. Key Insights\\n\"\n",
    "        if not self.node_metrics.empty:\n",
    "            # æ‰¾å‡ºæŒ‡æ ‡æœ€é«˜çš„èŠ‚ç‚¹\n",
    "            col = 'Degree' if 'Degree' in self.node_metrics else 'In_Degree'\n",
    "            top_deg = self.node_metrics[col].idxmax()\n",
    "            report += f\"* **Hub Node**: Node `{top_deg}` has the highest degree centrality.\\n\"\n",
    "            \n",
    "            if 'Betweenness' in self.node_metrics:\n",
    "                top_bet = self.node_metrics['Betweenness'].idxmax()\n",
    "                report += f\"* **Bridge Node**: Node `{top_bet}` has the highest betweenness, controlling flow.\\n\"\n",
    "                \n",
    "            if 'Community_ID' in self.node_metrics.columns:\n",
    "                n_comm = self.node_metrics['Community_ID'].nunique()\n",
    "                report += f\"* **Community Structure**: The network divides into **{n_comm}** communities (Louvain).\\n\"\n",
    "        \n",
    "        if self.robustness_log:\n",
    "            report += \"\\n## 3. Resilience Analysis (Robustness)\\n\"\n",
    "            for atk, val in self.robustness_log.items():\n",
    "                status = \"Fragile\" if val < 0.1 else (\"Robust\" if val > 0.4 else \"Moderate\")\n",
    "                report += f\"* Under **{atk} attack**, the network collapses (Giant Component < 50%) after removing **{val:.1%}** of nodes. Rating: **{status}**.\\n\"\n",
    "        \n",
    "        with open(f\"{self.output_dir}/Report.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(report)\n",
    "            \n",
    "        print(f\"âœ… [1] æ•°æ®è¡¨: Node_Metrics.xlsx\")\n",
    "        print(f\"âœ… [2] çŸ¢é‡å›¾: Network_Viz.svg, Robustness_*.svg\")\n",
    "        print(f\"âœ… [3] äº¤äº’æ–‡ä»¶: {self.name}.gexf\")\n",
    "        print(f\"âœ… [4] æ™ºèƒ½æˆ˜æŠ¥: Report.md (å«è‡ªåŠ¨ç»“è®º)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d324a5d8-2814-4748-9412-cb31571304c7",
   "metadata": {},
   "source": [
    "## âš”ï¸ V7.0 å›¾è®ºæŒ‡æŒ¥å®˜å…¨æµç¨‹ä½œæˆ˜æ‰‹å†Œ (Final Detailed Ver.)\n",
    "\n",
    "> **æ ¸å¿ƒå®—æ—¨**ï¼šä»£ç åªæ˜¯å·¥å…·ï¼Œä½ çš„ç›®æ ‡æ˜¯æ„å»ºè¯æ®é“¾ã€‚æ¯ä¸€ä¸ª Python å‡½æ•°çš„è¿è¡Œï¼Œéƒ½å¿…é¡»å¯¹åº”è®ºæ–‡ä¸­çš„ä¸€ä¸ªå¾—åˆ†ç‚¹ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ›‘ Phase -1: èµ›å‰æ¼”ä¹  (God Mode Verification)\n",
    "\n",
    "> **æ­¤æ­¥éª¤å¿…é¡»åœ¨æ¯”èµ›å¼€å§‹å‰ï¼ˆæˆ–æ‹¿åˆ°é¢˜ç›®å‰ï¼‰æ‰§è¡Œä¸€æ¬¡ï¼Œç¡®ä¿â€œæªæ˜¯å‡†çš„â€ã€‚**\n",
    "\n",
    "1.  **æ„é€ å‡æ•°æ®**:\n",
    "    * **Prompt**: \"è¯·ç”Ÿæˆä¸€ä¸ªåŒ…å« 50 ä¸ªèŠ‚ç‚¹ã€3 ä¸ªæ˜æ˜¾ç¤¾å›¢çš„è¾¹è¡¨ CSVã€‚æ•…æ„è®¾ç½®èŠ‚ç‚¹ 0 å’ŒèŠ‚ç‚¹ 49 ä¸ºè¿æ¥ç¤¾å›¢çš„å”¯ä¸€æ¡¥æ¢ã€‚\"\n",
    "2.  **å®å¼¹å°„å‡»**:\n",
    "    * è¿è¡Œ `solver.build_from_edgelist(...)`ã€‚\n",
    "    * è¿è¡Œ `solver.compute_centrality()` å’Œ `solver.detect_communities()`ã€‚\n",
    "3.  **éªŒæ”¶æ ‡å‡†**:\n",
    "    * **Q1**: `Node_Metrics.xlsx` ä¸­ï¼ŒèŠ‚ç‚¹ 0 å’Œ 49 çš„ Betweenness æ˜¯å¦æ˜¾è‘—é«˜äºå…¶ä»–ç‚¹ï¼Ÿï¼ˆå¦‚æœæ˜¯ï¼Œè¯´æ˜æ•æ‰å…³é”®ç‚¹èƒ½åŠ›æ­£å¸¸ï¼‰ã€‚\n",
    "    * **Q2**: è¾“å‡ºçš„æ¨¡å—åº¦ $Q$ æ˜¯å¦ >0.4ï¼Ÿï¼ˆå¦‚æœæ˜¯ï¼Œè¯´æ˜ Louvain ç®—æ³•æ­£å¸¸ï¼‰ã€‚\n",
    "4.  **ç»“æœ**: âœ… é€šè¿‡ -> è¿›å…¥å¾…å‘½çŠ¶æ€ï¼›âŒ å¤±è´¥ -> æ£€æŸ¥ networkx ç‰ˆæœ¬æˆ–ä»£ç é€»è¾‘ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ•µï¸ Phase 0: æˆ˜åœºä¾¦å¯Ÿ (Recon & Setup)\n",
    "\n",
    "> **ç›®æ ‡**ï¼šæ¸…æ´—æ•°æ®ï¼Œè§„é¿æ•°å­¦é™·é˜±ï¼Œç¡®ç«‹æ¨¡å‹åŸºè°ƒã€‚\n",
    "\n",
    "#### æ­¥éª¤ 0.1: å¯åŠ¨ä¸æ¡æ‰‹\n",
    "* **åŠ¨ä½œ**: `solver = Graph_Solver_Capsule(name=\"Problem_D_Network\", is_directed=True)`\n",
    "* **åŠ¨ä½œ**: `solver.generate_handshake()`\n",
    "* **æŒ‡ä»¤**: å¤åˆ¶æ‰“å°å‡ºçš„ Prompt å‘é€ç»™ä½ çš„ AI åŠ©æ‰‹ï¼Œè®©å®ƒè¿›å…¥â€œV7.0 è¾…åŠ©æ¨¡å¼â€ã€‚\n",
    "\n",
    "#### æ­¥éª¤ 0.2: æ•°æ®è£…è½½ä¸æƒé‡å®šä¹‰\n",
    "* **åŠ¨ä½œ**: `df = pd.read_csv('data.csv')`\n",
    "* **å…³é”®å†³ç­– (Weight Definition)**:\n",
    "    * **åœºæ™¯ A (è·ç¦»/æˆæœ¬/å»¶è¿Ÿ)**: æƒé‡è¶Šå°è¶Šå¥½ã€‚ -> ç›´æ¥è£…è½½ã€‚\n",
    "    * **åœºæ™¯ B (æµé‡/äº²å¯†åº¦/å¸¦å®½)**: æƒé‡è¶Šå¤§è¶Šå¥½ã€‚ -> **å¿…é¡»å€’æ•°å¤„ç†**ã€‚\n",
    "    * **ä»£ç **: `df['weight'] = 1 / df['flow']` (å¦‚æœæ±‚æœ€çŸ­è·¯å¾„)ã€‚\n",
    "* **åŠ¨ä½œ**: `solver.build_from_edgelist(df, source='From', target='To', weight='weight')`\n",
    "\n",
    "#### æ­¥éª¤ 0.3: æ ¸å¿ƒå®¡è®¡ (The Audit) â€”â€” å†³å®šç”Ÿæ­»\n",
    "* **åŠ¨ä½œ**: `solver.audit()`\n",
    "* **æˆ˜æœ¯åˆ†æ”¯**:\n",
    "    * **æƒ…å½¢ A (ç†æƒ³)**: `\"Graph is connected.\"` -> å…¨å›¾åˆ†æã€‚\n",
    "    * **æƒ…å½¢ B (ç ´ç¢)**: `\"Graph has 5 connected components. Largest covers 92%.\"`\n",
    "        * **æ“ä½œ**: ä¸å¤„ç†ï¼Œç›´æ¥åˆ†æå…¨å›¾å¯èƒ½ä¼šå¯¼è‡´æŠ¥é”™ã€‚\n",
    "        * **è®ºæ–‡è¯æœ¯**: \"é‰´äºç½‘ç»œå­˜åœ¨ç¦»æ•£çš„è¾¹ç¼˜èŠ‚ç‚¹ï¼Œä¸ºç¡®ä¿æ‹“æ‰‘åˆ†æçš„ç¨³å¥æ€§ï¼Œæˆ‘ä»¬å°†ç ”ç©¶èŒƒå›´é”å®šåœ¨åŒ…å« 92% èŠ‚ç‚¹çš„æœ€å¤§è¿é€šå­å›¾ (Largest Connected Component, LCC) ä¸Šã€‚\"\n",
    "    * **æƒ…å½¢ C (è´Ÿæƒ)**: `\"Warning: Negative weights detected.\"`\n",
    "        * **æ“ä½œ**: **ç»ä¸ä½¿ç”¨ Dijkstra**ã€‚åç»­å¦‚æœæœ‰è·¯å¾„è§„åˆ’ï¼Œå¿…é¡»æŒ‡å®š Bellman-Ford ç®—æ³•ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‘‘ Phase 1: æƒåŠ›ç»“æ„åˆ†æ (Hierarchy)\n",
    "\n",
    "> **ç›®æ ‡**ï¼šé‡åŒ–èŠ‚ç‚¹çš„åœ°ä½ï¼Œä¸ºâ€œå…³é”®èŠ‚ç‚¹è¯†åˆ«â€é—®é¢˜æä¾›æ•°å­¦ä¾æ®ã€‚\n",
    "\n",
    "#### æ­¥éª¤ 1.1: å…¨é¢è®¡ç®—\n",
    "* **åŠ¨ä½œ**: `solver.compute_centrality()`\n",
    "* **æ•ˆæœ**: `self.node_metrics` è¡¨æ ¼è¢«å¡«æ»¡ã€‚\n",
    "\n",
    "#### æ­¥éª¤ 1.2: è§’è‰²å®šä¹‰ (Role Assignment) â€”â€” è®ºæ–‡æ ¸å¿ƒæ®µè½\n",
    "> ä½ ä¸èƒ½åªåˆ—æ•°å­—ï¼Œå¿…é¡»èµ‹äºˆèŠ‚ç‚¹â€œç‰©ç†æ„ä¹‰â€ã€‚\n",
    "\n",
    "* **è§’è‰² A: Hub (æ¢çº½)**\n",
    "    * **æŒ‡æ ‡**: Degree Centrality (åº¦ä¸­å¿ƒåº¦)\n",
    "    * **ç‰©ç†æ„ä¹‰**: ç½‘ç»œçš„ç¹å¿™ä¸­å¿ƒï¼Œç›´æ¥å½±å“åŠ›æœ€å¤§ã€‚\n",
    "    * **åº”ç”¨**: ç–«è‹—åˆ†å‘ç‚¹ã€ç‰©æµé›†æ•£ä¸­å¿ƒã€‚\n",
    "* **è§’è‰² B: Bridge (æ¡¥æ¢/å’½å–‰)**\n",
    "    * **æŒ‡æ ‡**: Betweenness Centrality (ä»‹æ•°ä¸­å¿ƒåº¦)\n",
    "    * **ç‰©ç†æ„ä¹‰**: æ§åˆ¶ä¿¡æ¯/ç‰©èµ„æµåŠ¨çš„æœ€çŸ­è·¯å¾„å¿…ç»ç‚¹ã€‚\n",
    "    * **åº”ç”¨**: è¿™æ˜¯é˜»æ–­ç½‘ç»œï¼ˆProblem D/Fï¼‰çš„æœ€ä½³æ”»å‡»ç‚¹ã€‚\n",
    "* **è§’è‰² C: Influencer (å¹•åå¤§ä½¬)**\n",
    "    * **æŒ‡æ ‡**: Eigenvector Centrality (ç‰¹å¾å‘é‡ä¸­å¿ƒåº¦)\n",
    "    * **ç‰©ç†æ„ä¹‰**: è¿æ¥äº†é‡è¦èŠ‚ç‚¹çš„äººã€‚\n",
    "    * **åº”ç”¨**: è°£è¨€ä¼ æ’­æºå¤´ã€æ ¸å¿ƒç§‘ç ”äººå‘˜ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸŒªï¸ Phase 2: èšç±»ä¸å¯¹æŠ— (Dynamics) â€”â€” O å¥–åˆ†æ°´å²­\n",
    "\n",
    "> **ç›®æ ‡**ï¼šä»é™æ€æŒ‡æ ‡ä¸Šå‡åˆ°åŠ¨æ€æ¼”åŒ–ï¼Œå±•ç¤ºç³»ç»Ÿçš„å†…éƒ¨ç»“æ„å’ŒæŠ—å‹èƒ½åŠ›ã€‚\n",
    "\n",
    "#### æ­¥éª¤ 2.1: ç¤¾å›¢å‘ç° (Community Detection)\n",
    "* **åŠ¨ä½œ**: `solver.detect_communities(method='louvain')`\n",
    "* **æ£€æŸ¥**: æ§åˆ¶å°è¾“å‡ºçš„æ¨¡å—åº¦ $Q$ å€¼ã€‚\n",
    "* **æˆ˜æœ¯åˆ†æ”¯**:\n",
    "    * **åˆ†æ”¯ A (Q>0.3)**: ç¤¾å›¢ç»“æ„æ¸…æ™°ã€‚\n",
    "        * **è®ºæ–‡è¯æœ¯**: \"ç½‘ç»œè¡¨ç°å‡ºæ˜¾è‘—çš„æ¨¡å—åŒ–ç‰¹å¾ (Modularity)ï¼ŒLouvain ç®—æ³•è¯†åˆ«å‡ºäº† X ä¸ªä¸»è¦é›†ç¾¤ã€‚æˆ‘ä»¬å°†å…¶å‘½åä¸º [å…·ä½“ä¸šåŠ¡åï¼Œå¦‚ï¼šåŒ—ç¾è´¸æ˜“åŒº]ã€‚\"\n",
    "    * **åˆ†æ”¯ B (Q<0.2)**: ç¤¾å›¢ç»“æ„æ¨¡ç³Šã€‚\n",
    "        * **è®ºæ–‡è¯æœ¯**: \"ä¿®æ­£å›è·¯å¯åŠ¨ï¼šä½æ¨¡å—åº¦è¡¨æ˜è¯¥ç½‘ç»œæ˜¯ä¸€ä¸ªé«˜åº¦æ•´åˆçš„æ•´ä½“ (Highly Integrated)ï¼Œä¸åŒåŒºåŸŸé—´å­˜åœ¨é¢‘ç¹çš„è·¨åŸŸè¿æ¥ï¼Œè¿™æœ‰åˆ©äºå…¨å±€èµ„æºçš„å¿«é€Ÿè°ƒé…ï¼Œä½†ä¹Ÿæ„å‘³ç€å±€éƒ¨é£é™©å®¹æ˜“æ‰©æ•£åˆ°å…¨å±€ã€‚\" â€”â€” (æŠŠâ€œåç»“æœâ€å˜æˆâ€œæ·±åˆ»æ´å¯Ÿâ€)\n",
    "\n",
    "#### æ­¥éª¤ 2.2: é²æ£’æ€§/æŠ—æ¯æ€§æµ‹è¯• (Robustness Analysis)\n",
    "* **åŠ¨ä½œ 1**: `solver.analyze_robustness(attack_type='targeted', fraction=0.3)` (è“„æ„æ”»å‡»)\n",
    "* **åŠ¨ä½œ 2**: `solver.analyze_robustness(attack_type='random', fraction=0.3)` (éšæœºæ•…éšœ)\n",
    "* **å¯¹æ¯”åˆ†æ (The Narrative)**:\n",
    "    * çœ‹ç”Ÿæˆçš„ `Robustness_Curve.svg`ã€‚\n",
    "    * **æ ‡å‡†å‰§æœ¬ (Scale-free)**: çº¢çº¿(è“„æ„)æ–­å´–ä¸‹è·Œï¼Œè“çº¿(éšæœº)å¹³ç¼“ã€‚\n",
    "        * **ç»“è®º**: \"ç½‘ç»œå…·æœ‰æ— æ ‡åº¦ç‰¹æ€§ (Scale-free property)ã€‚å®ƒå¯¹éšæœºæ•…éšœæå…¶é²æ£’ï¼ˆé€‚åˆåº”å¯¹è‡ªç„¶ç¾å®³ï¼‰ï¼Œä½†å¯¹é’ˆå¯¹ Hub ç‚¹çš„è“„æ„æ”»å‡»æå…¶è„†å¼±ï¼ˆéœ€è¦é‡ç‚¹é˜²å¾¡ææ€–è¢­å‡»ï¼‰ã€‚\"\n",
    "    * **éæ ‡å‰§æœ¬ (Random/Small-world)**: ä¸¤æ¡çº¿ä¸‹é™è¶‹åŠ¿ç›¸ä¼¼ã€‚\n",
    "        * **ç»“è®º**: \"ç½‘ç»œæ‹“æ‰‘ç»“æ„æ¥è¿‘éšæœºç½‘ç»œï¼Œæ„å‘³ç€å®ƒæ²¡æœ‰æ˜æ˜¾çš„å•ç‚¹æ•…éšœ (Single Point of Failure)ï¼Œç³»ç»Ÿå†—ä½™åº¦æé«˜ã€‚\"\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“¦ Phase 3: äº¤ä»˜ä¸æ”¶å‰² (Harvest)\n",
    "\n",
    "> **ç›®æ ‡**ï¼šç”Ÿæˆç›´æ¥å¯ç”¨çš„è®ºæ–‡ç´ æã€‚\n",
    "\n",
    "#### æ­¥éª¤ 3.1: ä¸€é”®å¯¼å‡º\n",
    "* **åŠ¨ä½œ**: `solver.export_results()`\n",
    "* **äº§ç‰©**: `Node_Metrics.xlsx`, `Network_Viz.svg`, `Report.md`, `model.gexf`ã€‚\n",
    "\n",
    "#### æ­¥éª¤ 3.2: æ™ºèƒ½æˆ˜æŠ¥éªŒæ”¶\n",
    "* **åŠ¨ä½œ**: æ‰“å¼€ `Report.md`ã€‚\n",
    "* **åº”ç”¨**: å¤åˆ¶é‡Œé¢çš„å…³é”®å¥ï¼ˆå¦‚ \"The network collapses after removing 15% of nodes...\"ï¼‰ç›´æ¥å¡«å…¥è®ºæ–‡çš„ Result ç« èŠ‚ã€‚\n",
    "\n",
    "#### æ­¥éª¤ 3.3: å¯è§†åŒ–ç»ˆæè£å†³\n",
    "* **å†³ç­–**:\n",
    "    * **å°å›¾ (<100 èŠ‚ç‚¹)**: ç›´æ¥ä½¿ç”¨ Python ç”Ÿæˆçš„ `Network_Viz.svg`ã€‚æ¸…æ™°ã€å¸¦æ ‡ç­¾ã€é£æ ¼å­¦æœ¯åŒ–ã€‚\n",
    "    * **å¤§å›¾ (>100 èŠ‚ç‚¹)**: Python ç”»å‡ºæ¥æ˜¯ä¸€å›¢é»‘ï¼Ÿ -> **å¯åŠ¨ Gephi åè®®**ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸŒŸ é™„å½•ï¼šGephi æ¸²æŸ“åè®® (The Visualization Protocol)\n",
    "\n",
    "> **å½“éœ€è¦ä¸€å¼ éœ‡æ’¼è¯„å§”çš„â€œå°é¢çº§â€å¤§å›¾æ—¶æ‰§è¡Œæ­¤æ­¥ã€‚**\n",
    "\n",
    "1.  **å¯åŠ¨**: æ‰“å¼€ Gephi è½¯ä»¶ã€‚\n",
    "2.  **å¯¼å…¥**: æ–‡ä»¶ -> æ‰“å¼€ -> é€‰æ‹© `Results_xxx/Graph_Model.gexf`ã€‚\n",
    "3.  **å¸ƒå±€ (Layout)**:\n",
    "    * å·¦ä¸‹è§’å¸ƒå±€é¢æ¿ -> é€‰æ‹© **\"Force Atlas 2\"**ã€‚\n",
    "    * å‹¾é€‰ **\"Dissuade Hubs\"** (é˜²æ­¢é‡å )ï¼Œå‹¾é€‰ **\"Prevent Overlap\"**ã€‚\n",
    "    * ç‚¹å‡» **è¿è¡Œ**ï¼Œç­‰å¾…å›¾å½¢å±•å¼€æˆæ¼‚äº®çš„æœ‰æœºå½¢çŠ¶ï¼Œç‚¹å‡» **åœæ­¢**ã€‚\n",
    "4.  **ç»Ÿè®¡ (Statistics)**:\n",
    "    * è™½ç„¶ Python ç®—è¿‡äº†ï¼Œä½†åœ¨ Gephi å³ä¾§ç‚¹å‡» **\"Modularity\" -> è¿è¡Œ**ï¼Œä»¥ä¾¿è®© Gephi è¯†åˆ«ç¤¾å›¢é¢œè‰²ã€‚\n",
    "5.  **å¤–è§‚ (Appearance)**:\n",
    "    * **é¢œè‰² (Color)**: èŠ‚ç‚¹(Nodes) -> Partition -> é€‰æ‹© Modularity Class (ç¤¾å›¢)ã€‚ -> **æ•ˆæœ**ï¼šä¸åŒåœˆå­ä¸åŒè‰²ã€‚\n",
    "    * **å¤§å° (Size)**: èŠ‚ç‚¹(Nodes) -> Ranking -> é€‰æ‹© Degree (åº¦)ã€‚ -> **æ•ˆæœ**ï¼šå¤§ä½¬èŠ‚ç‚¹æ›´å¤§ã€‚\n",
    "6.  **æ ‡ç­¾ (Labels)**:\n",
    "    * åº•éƒ¨å·¥å…·æ  -> ç‚¹å‡» **T** (æ˜¾ç¤ºæ ‡ç­¾)ã€‚\n",
    "    * å³ä¾§æ ‡ç­¾æ»‘å— -> è°ƒå¤§å­—å·ï¼Œåªæ˜¾ç¤ºæœ€æ ¸å¿ƒèŠ‚ç‚¹çš„æ ‡ç­¾ã€‚\n",
    "7.  **è¾“å‡º (Preview & Export)**:\n",
    "    * ç‚¹å‡»é¡¶éƒ¨ **é¢„è§ˆ (Preview)** -> åˆ·æ–°ã€‚\n",
    "    * å·¦ä¸‹è§’ **å¯¼å‡º** SVG/PDF/PNGã€‚\n",
    "\n",
    "**ğŸ† æˆå°±è¾¾æˆ: ä½ ç°åœ¨æ‹¥æœ‰äº†ä¸€å¼ ç¾èµ› O å¥–çº§åˆ«çš„ç½‘ç»œç»“æ„å›¾ã€‚**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80328c05-02ae-4ba6-8084-f43c7ca19c1c",
   "metadata": {},
   "source": [
    "ç»è¿‡å¯¹æœ€åä¸€éƒ¨åˆ†ï¼ˆäº¤äº’æŒ‡ä»¤é›† Phase 0.1 - Phase 3ï¼‰çš„æœ€ç»ˆå®¡æŸ¥ï¼Œæˆ‘ç¡®è®¤å®ƒå·²å®Œå…¨è¦†ç›–äº† V7.0 æ¶æ„çš„æ‰€æœ‰å…³é”®åŠ¨ä½œï¼ˆå®¡è®¡ã€ç¤¾å›¢å‘ç°ã€åŒæ¨¡å¼é²æ£’æ€§ã€Gephi å¯¼å‡ºï¼‰ï¼Œå¹¶ä¸”ä¸ä¹‹å‰çš„ä»£ç ç±»å’ŒæŒ‡æŒ¥å®˜æ‰‹å†Œå®Œç¾å¯¹åº”ã€‚\n",
    "\n",
    "è¿™æ˜¯æœ€ç»ˆå®šç‰ˆçš„ **V7.0 äº¤äº’æŒ‡ä»¤é›†**ã€‚æ¯”èµ›æ—¶ï¼Œè¯·ç›´æ¥å¤åˆ¶è¿™äº›å†…å®¹ä¸ AI è¿›è¡Œåä½œã€‚\n",
    "\n",
    "### ğŸ•¹ï¸ Phase 0.1: æœ¬åœ°å¯åŠ¨ (Local Launch)\n",
    "\n",
    "* **æ‰§è¡Œä½ç½®**ï¼šä½ çš„æœ¬åœ° Jupyter Notebook\n",
    "* **ç›®çš„**ï¼šåˆå§‹åŒ–æ ¸æ­¦å™¨åº“ï¼Œç”Ÿæˆæ¡æ‰‹åè®®ã€‚\n",
    "\n",
    "# [Copy code to Notebook]\n",
    "import pandas as pd\n",
    "# å‡è®¾ Graph_Solver_Capsule ç±»å·²åœ¨ä¸Šæ–¹å®šä¹‰æˆ–å¯¼å…¥\n",
    "# from graph_solver_v7 import Graph_Solver_Capsule \n",
    "\n",
    "# 1. è¯»å–æ•°æ®\n",
    "df = pd.read_csv('data.csv') # è¯·ä¿®æ”¹æ–‡ä»¶å\n",
    "\n",
    "# 2. å®ä¾‹åŒ– (å†³ç­–ç‚¹ï¼šæ˜¯å¦æœ‰å‘å›¾ï¼Ÿ)\n",
    "# True = å•è¡Œé“/å…³æ³¨/é£Ÿç‰©é“¾; False = åŒè¡Œé“/æœ‹å‹/å…±ç°\n",
    "solver = Graph_Solver_Capsule(name=\"MCM_Problem\", is_directed=True) \n",
    "\n",
    "# 3. ç”Ÿæˆæ¡æ‰‹åè®® (åŠ¡å¿…å¤åˆ¶è¾“å‡ºå†…å®¹)\n",
    "solver.generate_handshake(df_dict={'Edges': df})\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ Phase 1: æ„å›¾ä¸å®¡è®¡ (Prompt_Graph_Build.txt)\n",
    "\n",
    "* **æ‰§è¡Œä½ç½®**ï¼šå‘é€ç»™ AI\n",
    "* **ç›®çš„**ï¼šæ•°æ®æ³¨å…¥ä¸â€œæ’é›·â€ã€‚\n",
    "\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šPhase 1 - ç½‘ç»œæ„å»ºä¸å®¡è®¡ã€‘\n",
    "\n",
    "è¯·æ ¹æ® V7.0 æ ‡å‡†æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š\n",
    "\n",
    "1.  **æ•°æ®æ³¨å…¥ (Data Injection)**:\n",
    "    - è¾¹è¡¨æ•°æ®å·²åŠ è½½ä¸º `df`ã€‚\n",
    "    - æ˜ å°„è®¾ç½®: Source=`[å¡«åˆ—å]`, Target=`[å¡«åˆ—å]`, Weight=`[å¡«åˆ—å/None]`ã€‚\n",
    "    - **æƒé‡å†³ç­–**: \n",
    "       - å¦‚æœæƒé‡æ˜¯\"è·ç¦»/æˆæœ¬\" (è¶Šå°è¶Šå¥½) -> ç›´æ¥ä½¿ç”¨ã€‚\n",
    "       - å¦‚æœæƒé‡æ˜¯\"æµé‡/äº²å¯†åº¦\" (è¶Šå¤§è¶Šå¥½) -> è¯·å¯¹æ•°æ®å–å€’æ•° (1/w) æˆ–è®¾ä¸º None (ä»…æ‹“æ‰‘)ã€‚\n",
    "    - æ‰§è¡Œ: `solver.build_from_edgelist(...)`ã€‚\n",
    "\n",
    "2.  **å®¡è®¡ä¸ä¿®æ­£ (Audit Loop)**:\n",
    "    - æ‰§è¡Œ: `solver.audit()`ã€‚\n",
    "    - **é€»è¾‘åˆ¤æ–­**:\n",
    "      - **è‹¥å›¾ä¸è¿é€š**: ä¸”æœ€å¤§è¿é€šå­å›¾å æ¯” > 85%ï¼Œè¯·æ‰§è¡Œâ€œæå–æœ€å¤§è¿é€šå­å›¾â€è¦†ç›–åŸå›¾ï¼Œå¹¶åœ¨å›å¤ä¸­æ³¨æ˜ï¼šâ€œå·²é”å®š LCC è¿›è¡Œåˆ†æâ€ã€‚\n",
    "      - **è‹¥å‘ç°è´Ÿæƒè¾¹**: æ ‡è®°ä¸ºâ€œDijkstra å¤±æ•ˆé£é™©â€ï¼Œå»ºè®®åç»­åˆ†æè§„é¿æœ€çŸ­è·¯ç®—æ³•ã€‚\n",
    "\n",
    "3.  **çŠ¶æ€æ±‡æŠ¥**:\n",
    "    - æ±‡æŠ¥å½“å‰ç½‘ç»œçš„ èŠ‚ç‚¹æ•°ã€è¾¹æ•°ã€å¯†åº¦ã€‚\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸŒªï¸ Phase 2: æ·±åº¦ç»“æ„åˆ†æ (Prompt_Graph_Dynamics.txt)\n",
    "\n",
    "* **æ‰§è¡Œä½ç½®**ï¼šå‘é€ç»™ AI\n",
    "* **ç›®çš„**ï¼šæŒ–æ˜ O å¥–çº§è¯æ®ï¼ˆç¤¾å›¢ + é²æ£’æ€§ï¼‰ã€‚\n",
    "\n",
    "\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šPhase 2 - ç»“æ„ä¸é²æ£’æ€§åˆ†æ (Oå¥–çº§)ã€‘\n",
    "\n",
    "è¯·æŒ–æ˜ç½‘ç»œæ·±å±‚ç‰¹å¾ï¼š\n",
    "\n",
    "1.  **æƒåŠ›ç»“æ„ (Hierarchy)**:\n",
    "    - è®¡ç®—ä¸­å¿ƒæ€§ï¼š`solver.compute_centrality()`ã€‚\n",
    "    - **è§£è¯»**: è¯·æ‰¾å‡º Betweenness æœ€é«˜çš„ 3 ä¸ªèŠ‚ç‚¹ï¼Œè§£é‡Šä¸ºä»€ä¹ˆå®ƒä»¬æ˜¯ç½‘ç»œçš„â€œå’½å–‰ (Choke Points)â€ã€‚\n",
    "\n",
    "2.  **ç¤¾å›¢å‘ç° (Community)**:\n",
    "    - æ‰§è¡Œï¼š`solver.detect_communities(method='louvain')`ã€‚\n",
    "    - **è§£è¯»**: æ¨¡å—åº¦ Q å€¼æ˜¯å¤šå°‘ï¼Ÿ\n",
    "      - è‹¥ Q > 0.3 -> æè¿°å…¶â€œæ˜æ˜¾çš„ç¤¾å›¢ç»“æ„â€ã€‚\n",
    "      - è‹¥ Q < 0.2 -> æè¿°å…¶ä¸ºâ€œé«˜åº¦æ··åˆçš„æ•´ä½“ (Highly Integrated)â€ã€‚\n",
    "\n",
    "3.  **æŠ—æ¯æ€§å¯¹æŠ—æµ‹è¯• (Robustness - æ ¸æ­¦å™¨)**:\n",
    "    - æ¨¡æ‹Ÿä¸¤ç§æ”»å‡»æ¨¡å¼ï¼Œç”Ÿæˆå¯¹æ¯”æ›²çº¿ï¼š\n",
    "      - `solver.analyze_robustness(attack_type='targeted', fraction=0.4)` (è“„æ„æ”»å‡»æ¢çº½)\n",
    "      - `solver.analyze_robustness(attack_type='random', fraction=0.4)` (éšæœºæ•…éšœ)\n",
    "    - **å…³é”®åˆ¤æ–­**: \n",
    "       - è§‚å¯Ÿç”Ÿæˆçš„å›¾è¡¨ã€‚å¦‚æœâ€œè“„æ„æ”»å‡»â€å¯¼è‡´ç½‘ç»œå´©æºƒï¼ˆæ›²çº¿æ–­å´–ä¸‹è·Œï¼‰è€Œâ€œéšæœºæ•…éšœâ€å½±å“è¾ƒå°ï¼Œè¯·æ˜ç¡®ä¸‹ç»“è®ºï¼š**â€œè¯¥ç½‘ç»œå…·æœ‰æ— æ ‡åº¦ (Scale-free) ç‰¹æ€§ï¼Œé²æ£’ä½†è„†å¼±ã€‚â€**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“¦ Phase 3: é¡¶çº§å¯è§†åŒ–ä¸äº¤ä»˜ (Prompt_Graph_Viz.txt)\n",
    "\n",
    "* **æ‰§è¡Œä½ç½®**ï¼šå‘é€ç»™ AI\n",
    "* **ç›®çš„**ï¼šç”Ÿæˆäº¤ä»˜ç‰©ä¸æ™ºèƒ½æˆ˜æŠ¥ã€‚\n",
    "\n",
    "\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šPhase 3 - å¯è§†åŒ–ä¸äº¤ä»˜ã€‘\n",
    "\n",
    "1.  **Python å¿«é€Ÿé¢„è§ˆ**:\n",
    "    - `solver.plot_network(layout='kamada_kawai')`ã€‚\n",
    "    - è¦æ±‚ï¼šèŠ‚ç‚¹å¤§å°éš Degree å˜åŒ–ï¼Œåªæ ‡æ³¨ Top 10 å…³é”®èŠ‚ç‚¹ã€‚\n",
    "\n",
    "2.  **Gephi åè®®å¯¼å‡º**:\n",
    "    - `solver.export_to_gephi()`ã€‚\n",
    "    - **ç¡®è®¤**: æ˜¯å¦ç”Ÿæˆäº† `.gexf` æ–‡ä»¶ï¼Ÿ(å¦‚æœ Python ç»˜å›¾å¤ªä¹±ï¼Œæˆ‘å°†ä½¿ç”¨æ­¤æ–‡ä»¶åœ¨ Gephi ä¸­æ¸²æŸ“)ã€‚\n",
    "\n",
    "3.  **å…¨å¥—äº¤ä»˜ (Harvest)**:\n",
    "    - `solver.export_results()`ã€‚\n",
    "    - **æ™ºèƒ½æˆ˜æŠ¥éªŒæ”¶**: è¯·è¯»å–å¹¶æ‰“å° `Report.md` çš„å†…å®¹ã€‚æˆ‘å°†ç›´æ¥ä½¿ç”¨å…¶ä¸­çš„ç»“è®ºå¥å­ï¼ˆå¦‚å´©æºƒé˜ˆå€¼ã€å…³é”®èŠ‚ç‚¹IDï¼‰å†™å…¥è®ºæ–‡ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a38309-0f0b-4da2-9f29-c86b618ee35a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
