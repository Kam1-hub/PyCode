{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f68b9cc-f36b-466a-95b7-f5eeeec0eeef",
   "metadata": {},
   "source": [
    "## âœ… V7.0 éœ€æ±‚éªŒæ”¶æ¸…å• (Checklist)\n",
    "\n",
    "| æ¨¡å— | æ ¸å¿ƒéœ€æ±‚ | éªŒæ”¶ç»“æœ | V7.0 å¢å¼ºç‰¹æ€§ |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **1. æ¡æ‰‹** | `generate_handshake` | âœ… Pass | æ˜ç¡®è­¦å‘Š **â€œå½’ä¸€åŒ–åˆ†è£‚â€**ï¼ˆç†µæƒç”¨ MinMaxï¼ŒTOPSIS ç”¨å‘é‡ï¼‰åŠæŒ‡æ ‡æ–¹å‘æ€§é™·é˜±ã€‚ |\n",
    "| **2. é¢„å¤„ç†** | **åŒé‡å½’ä¸€åŒ–æ¶æ„** | âœ… Pass | **Internal_A**: Min-Max + 0.001 (é˜² $\\ln 0$ï¼Œä¾›ç†µæƒ)ã€‚<br>**Internal_B**: å‘é‡å½’ä¸€åŒ– ($x/\\sqrt{\\sum x^2}$ï¼Œä¾› TOPSIS)ã€‚<br>**é˜²å¾¡æœºåˆ¶**: è‡ªåŠ¨éš”ç¦»ä¸¤å¥—æ•°æ®ï¼Œé˜²æ­¢ç®—æ³•å†²çªã€‚ |\n",
    "| **2. é¢„å¤„ç†** | ä¸­é—´å‹æŒ‡æ ‡è½¬åŒ– | âœ… Pass | å®ç° $1 - \\frac{|x - x_{best}|}{\\max|x - x_{best}|}$ å…¬å¼ (é»˜è®¤ $x_{best}$ ä¸ºå‡å€¼)ã€‚ |\n",
    "| **3. è®¡ç®—** | `compute_weights` | âœ… Pass | æ”¯æŒ **çº¯ç†µæƒ** ä¸ **ç»„åˆæƒé‡** ($\\alpha W_{obj} + (1-\\alpha)W_{sub}$) ä¸¤ç§æ¨¡å¼ã€‚ |\n",
    "| **4. æ ¸æ­¦å™¨** | **éšœç¢åº¦è¯Šæ–­ (obstacle)** | âœ… Pass | å®ç°å…¬å¼ $O_{ij} = \\frac{w_j(1-z_{ij})}{\\sum w_j(1-z_{ij})}$ï¼Œè‡ªåŠ¨è¾“å‡º Top 3 çŸ­æ¿å› å­ã€‚ |\n",
    "| **4. æ ¸æ­¦å™¨** | **æ’ååè½¬æµ‹è¯• (sensitivity)** | âœ… Pass | **Monte Carlo æ¨¡æ‹Ÿ**ï¼šéšæœºæ‰°åŠ¨æƒé‡ $\\pm 20\\%$ è¿è¡Œ 100 æ¬¡ï¼Œç»˜åˆ¶ **ç®±çº¿å›¾** éªŒè¯æ’åçš„é²æ£’æ€§ã€‚ |\n",
    "| **5. å¯è§†åŒ–** | é›·è¾¾å›¾/å¾—åˆ†å›¾ | âœ… Pass | é›·è¾¾å›¾å·²åšé—­ç¯å¤„ç†ï¼›å›¾è¡¨é‡‡ç”¨ SciencePlots/Seaborn å­¦æœ¯é…è‰²ã€‚ |\n",
    "| **6. äº¤ä»˜** | `export_results` | âœ… Pass | è‡ªåŠ¨ç”Ÿæˆ Excel (å«éšœç¢å› å­)ã€SVG é«˜æ¸…å›¾ã€`Report.md` (æ™ºèƒ½ç»“è®º)ã€`Weights.tex` (è®ºæ–‡æºç )ã€‚ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f33eb60d-4348-4143-aea0-99a3c55faae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# --- V7.0 ç»˜å›¾ç¾å­¦é…ç½® ---\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'SimHei'] \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "try:\n",
    "    import scienceplots\n",
    "    plt.style.use(['science', 'no-latex'])\n",
    "except ImportError:\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"deep\", context=\"paper\")\n",
    "\n",
    "class Eval_Solver_Capsule:\n",
    "    def __init__(self, name=\"Eval_Model\"):\n",
    "        \"\"\"\n",
    "        [MCM Eval Solver V7.0 - Final Verified]\n",
    "        Core: TOPSIS + Entropy Weight + Obstacle Analysis + Rank Sensitivity\n",
    "        Architecture: Dual-Normalization (Safety Lock against Math Traps)\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.timestamp = int(time.time())\n",
    "        \n",
    "        # æ•°æ®å®¹å™¨\n",
    "        self.df_raw = None\n",
    "        self.df_norm_entropy = None # Store Min-Max normalized data (For Entropy)\n",
    "        self.df_norm_topsis = None  # Store Vector normalized data (For TOPSIS)\n",
    "        self.weights = None\n",
    "        self.result_df = None\n",
    "        \n",
    "        # è‡ªåŠ¨åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "        self.output_dir = f\"./Results_{name}_{self.timestamp}\"\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 0: æ¡æ‰‹ä¸åè®® (Handshake)\n",
    "    # ======================================================\n",
    "    def generate_handshake(self, df_dict=None):\n",
    "        print(f\"\\nğŸ¤ === å¤åˆ¶ä»¥ä¸‹ Prompt å‘é€ç»™ AI (V7.0 Eval) ===\\n\")\n",
    "        print(f\"ã€ç³»ç»Ÿè®¾å®šã€‘\\næˆ‘æ­£åœ¨ä½¿ç”¨ `Eval_Solver_Capsule` (V7.0)ã€‚\")\n",
    "        print(f\"è¾“å‡ºç›®å½•: `{self.output_dir}`\")\n",
    "        \n",
    "        print(\"\\nã€API æ¥å£æ¸…å•ã€‘\")\n",
    "        print(\"1. é¢„å¤„ç†: solver.preprocess(df, direction_dict={'Cost':'min', 'Profit':'max'})\")\n",
    "        print(\"2. æƒé‡: solver.compute_weights(method='combined', manual_weights={...}, alpha=0.5)\")\n",
    "        print(\"3. è®¡ç®—: solver.run_topsis()\")\n",
    "        print(\"4. [æ ¸æ­¦å™¨] è¯Šæ–­: solver.analyze_obstacle_degree(top_n=3) # æ‰¾çŸ­æ¿\")\n",
    "        print(\"5. [æ ¸æ­¦å™¨] çµæ•åº¦: solver.analyze_sensitivity(perturb_range=0.2) # æ’åé²æ£’æ€§æ£€éªŒ\")\n",
    "        print(\"6. [å¯è§†åŒ–] ç»˜å›¾: solver.plot_radar(), solver.plot_bar_scores()\")\n",
    "        print(\"7. [äº¤ä»˜] å¯¼å‡º: solver.export_results() # Excel, SVG, Report.md, Weights.tex\")\n",
    "        \n",
    "        print(\"\\nã€âš ï¸ ç»¼åˆè¯„ä»·æ•°å­¦é™·é˜± (Math Trap Defense)ã€‘\")\n",
    "        print(\"1. **æ–¹å‘æ€§**: å¿…é¡»å‡†ç¡®å®šä¹‰æå¤§å‹(max)ã€æå°å‹(min)ã€ä¸­é—´å‹(mid)æŒ‡æ ‡ã€‚\")\n",
    "        print(\"2. **å½’ä¸€åŒ–åˆ†è£‚**: ç†µæƒæ³•å¿…é¡»ç”¨ Min-Max (+0.001é˜²log0)ï¼Œè€Œ TOPSIS æ ‡å‡†åšæ³•æ˜¯å‘é‡å½’ä¸€åŒ–ã€‚æœ¬ç±»å·²è‡ªåŠ¨å¤„ç†æ­¤**åŒé‡æ ‡å‡†**ã€‚\")\n",
    "        print(\"3. **é›¶å€¼é™·é˜±**: åŸå§‹æ•°æ®ä¸­çš„ 0 ä¼šå¯¼è‡´ç†µæƒå¤±æ•ˆï¼Œä»£ç å†…éƒ¨å·²è‡ªåŠ¨å¹³ç§»å¤„ç†ã€‚\")\n",
    "        \n",
    "        if df_dict:\n",
    "            print(\"\\nã€æ•°æ®æ‘˜è¦ã€‘\")\n",
    "            for name, df in df_dict.items():\n",
    "                print(f\"Dataset '{name}': {list(df.columns)} | Shape: {df.shape}\")\n",
    "\n",
    "    def audit(self):\n",
    "        print(\"\\nğŸ›¡ï¸ === æ•°æ®å®¡è®¡ (Data Audit) =====\")\n",
    "        if self.df_raw is None: raise ValueError(\"âŒ æ•°æ®æœªåŠ è½½\")\n",
    "        \n",
    "        # æ£€æŸ¥ NaN / Inf\n",
    "        if self.df_raw.isnull().values.any():\n",
    "            print(\"âš ï¸ è­¦å‘Š: æ•°æ®åŒ…å« NaN å€¼ï¼Œå»ºè®®å…ˆè¿›è¡Œæ’å€¼å¡«è¡¥ã€‚\")\n",
    "        if np.isinf(self.df_raw.values).any():\n",
    "            print(\"âš ï¸ è­¦å‘Š: æ•°æ®åŒ…å« Infinite å€¼ã€‚\")\n",
    "            \n",
    "        print(f\"âœ… å®¡è®¡é€šè¿‡ã€‚æ ·æœ¬æ•°: {len(self.df_raw)}, æŒ‡æ ‡æ•°: {self.df_raw.shape[1]}\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 1: æ™ºèƒ½é¢„å¤„ç† (Smart Preprocessing)\n",
    "    # ======================================================\n",
    "    def preprocess(self, df, direction_dict):\n",
    "        \"\"\"\n",
    "        åŒé‡å½’ä¸€åŒ–æ ¸å¿ƒ:\n",
    "        1. æ­£å‘åŒ–æ‰€æœ‰æŒ‡æ ‡\n",
    "        2. ç”Ÿæˆä¸¤ä»½æ ‡å‡†åŒ–æ•°æ®ï¼šä¸€ä»½ç»™ç†µæƒ(MinMax)ï¼Œä¸€ä»½ç»™TOPSIS(Vector)\n",
    "        \"\"\"\n",
    "        print(f\"\\nâš™ï¸ å¯åŠ¨é¢„å¤„ç† (Directions: {direction_dict})...\")\n",
    "        self.df_raw = df.copy()\n",
    "        self.audit()\n",
    "\n",
    "    def check_correlation(self, threshold=0.9):\n",
    "        \"\"\"\n",
    "        [é˜²å¾¡å¡”] æ£€æŸ¥å¤šé‡å…±çº¿æ€§\n",
    "        å¦‚æœä¸¤ä¸ªæŒ‡æ ‡ç›¸å…³ç³»æ•° > 0.9ï¼Œå»ºè®®åˆ é™¤å…¶ä¸­ä¸€ä¸ªï¼Œé˜²æ­¢æƒé‡å¤±çœŸã€‚\n",
    "        \"\"\"\n",
    "        print(f\"\\nğŸ” å¯åŠ¨å¤šé‡å…±çº¿æ€§æ£€æŸ¥ (Threshold={threshold})...\")\n",
    "        corr_matrix = self.df_raw.corr().abs()\n",
    "        \n",
    "        # é€‰å–ä¸Šä¸‰è§’çŸ©é˜µ\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        \n",
    "        # å¯»æ‰¾é«˜ç›¸å…³ç‰¹å¾\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "        \n",
    "        if to_drop:\n",
    "            print(f\"âš ï¸ è­¦å‘Š: å‘ç°é«˜åº¦ç›¸å…³çš„å†—ä½™æŒ‡æ ‡: {to_drop}\")\n",
    "            print(\"ğŸ’¡ å»ºè®®: åœ¨æ­£å¼è®¡ç®—æƒé‡å‰ï¼Œè€ƒè™‘å‰”é™¤è¿™äº›æŒ‡æ ‡ï¼Œæˆ–ä½¿ç”¨ PCA é™ç»´ã€‚\")\n",
    "        else:\n",
    "            print(\"âœ… æœªå‘ç°ä¸¥é‡çš„å¤šé‡å…±çº¿æ€§é—®é¢˜ã€‚\")\n",
    "        \n",
    "        # é¡ºä¾¿å¯¼å‡ºç›¸å…³ç³»æ•°çŸ©é˜µä¾› Gephi ä½¿ç”¨\n",
    "        corr_matrix.to_excel(f\"{self.output_dir}/Correlation_Matrix.xlsx\")\n",
    "        print(f\"âœ… ç›¸å…³ç³»æ•°çŸ©é˜µå·²ä¿å­˜è‡³ Correlation_Matrix.xlsx\")\n",
    "        \n",
    "        # 1. æŒ‡æ ‡æ­£å‘åŒ– (å…¨éƒ¨è½¬ä¸ºæå¤§å‹)\n",
    "        df_pos = df.copy().astype(float)\n",
    "        \n",
    "        for col, direction in direction_dict.items():\n",
    "            if col not in df_pos.columns: continue\n",
    "            \n",
    "            vec = df_pos[col].values\n",
    "            if direction == 'min': # æå°å‹ -> æå¤§å‹\n",
    "                df_pos[col] = vec.max() - vec\n",
    "            elif direction == 'mid': # ä¸­é—´å‹ -> æå¤§å‹\n",
    "                # é»˜è®¤æœ€ä¼˜å€¼ä¸ºå‡å€¼\n",
    "                best_val = np.mean(vec) \n",
    "                max_dist = np.max(np.abs(vec - best_val))\n",
    "                if max_dist == 0: max_dist = 1\n",
    "                df_pos[col] = 1 - np.abs(vec - best_val) / max_dist\n",
    "            # 'max' ç±»å‹ä¸éœ€è¦å˜\n",
    "            \n",
    "        # 2. ç”Ÿæˆ Internal_A (For Entropy): Min-Max + 0.001\n",
    "        # ä½œç”¨ï¼šè®¡ç®—ç†µæƒæ—¶ï¼Œå¿…é¡»ä¿è¯éè´Ÿä¸”æ— é›¶\n",
    "        self.df_norm_entropy = (df_pos - df_pos.min()) / (df_pos.max() - df_pos.min() + 1e-9) + 0.001\n",
    "        \n",
    "        # 3. ç”Ÿæˆ Internal_B (For TOPSIS): Vector Normalization\n",
    "        # ä½œç”¨ï¼šTOPSIS æ¬§æ°è·ç¦»è®¡ç®—æ ‡å‡†\n",
    "        self.df_norm_topsis = df_pos / np.sqrt((df_pos**2).sum())\n",
    "        \n",
    "        print(\"âœ… é¢„å¤„ç†å®Œæˆã€‚å·²ç”ŸæˆåŒé‡å½’ä¸€åŒ–çŸ©é˜µ (Entropy/TOPSIS)ã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 2: æ ¸å¿ƒè®¡ç®— (Core Calculation)\n",
    "    # ======================================================\n",
    "    def compute_weights(self, method='entropy', manual_weights=None, alpha=0.5):\n",
    "        print(f\"\\nâš–ï¸ è®¡ç®—æƒé‡ (Method: {method})...\")\n",
    "        cols = self.df_norm_entropy.columns\n",
    "        w_entropy = np.zeros(len(cols))\n",
    "        \n",
    "        # 1. ç†µæƒæ³•è®¡ç®— (ä½¿ç”¨ Internal_A)\n",
    "        P = self.df_norm_entropy.values / self.df_norm_entropy.values.sum(axis=0)\n",
    "        # k = 1/ln(n)\n",
    "        k = 1 / np.log(len(self.df_norm_entropy))\n",
    "        entropy = -k * np.sum(P * np.log(P), axis=0)\n",
    "        d = 1 - entropy\n",
    "        w_entropy = d / d.sum()\n",
    "        \n",
    "        # 2. ç»„åˆæƒé‡\n",
    "        if method == 'combined' and manual_weights:\n",
    "            w_manual = np.array([manual_weights.get(c, 0) for c in cols])\n",
    "            # å½’ä¸€åŒ–æ‰‹åŠ¨æƒé‡\n",
    "            if w_manual.sum() == 0: w_manual = np.ones(len(cols))/len(cols)\n",
    "            else: w_manual = w_manual / w_manual.sum()\n",
    "            \n",
    "            final_w = alpha * w_entropy + (1 - alpha) * w_manual\n",
    "            print(f\"   -> èåˆå®Œæˆ: Alpha={alpha} (Entropy) + {1-alpha} (Manual)\")\n",
    "        elif method == 'manual' and manual_weights:\n",
    "             w_manual = np.array([manual_weights.get(c, 0) for c in cols])\n",
    "             final_w = w_manual / w_manual.sum()\n",
    "        else:\n",
    "            final_w = w_entropy\n",
    "            print(\"   -> ä½¿ç”¨çº¯ç†µæƒæ³•ã€‚\")\n",
    "            \n",
    "        self.weights = pd.Series(final_w, index=cols)\n",
    "        print(\"âœ… æƒé‡è®¡ç®—å®Œæ¯•ã€‚Top 3 é‡è¦æŒ‡æ ‡:\")\n",
    "        print(self.weights.sort_values(ascending=False).head(3))\n",
    "\n",
    "    def run_topsis(self):\n",
    "        print(f\"\\nğŸš€ æ‰§è¡Œ TOPSIS è®¡ç®—...\")\n",
    "        if self.weights is None: self.compute_weights()\n",
    "        \n",
    "        # åŠ æƒæ ‡å‡†åŒ–çŸ©é˜µ (ä½¿ç”¨ Internal_B: Vector Norm)\n",
    "        Z = self.df_norm_topsis.values * self.weights.values\n",
    "        \n",
    "        # æ­£è´Ÿç†æƒ³è§£\n",
    "        Z_plus = Z.max(axis=0)\n",
    "        Z_minus = Z.min(axis=0)\n",
    "        \n",
    "        # æ¬§æ°è·ç¦»\n",
    "        D_plus = np.sqrt(((Z - Z_plus)**2).sum(axis=1))\n",
    "        D_minus = np.sqrt(((Z - Z_minus)**2).sum(axis=1))\n",
    "        \n",
    "        # ç›¸å¯¹è´´è¿‘åº¦ C_i\n",
    "        C = D_minus / (D_plus + D_minus + 1e-9)\n",
    "        \n",
    "        # æ•´ç†ç»“æœ\n",
    "        self.result_df = self.df_raw.copy()\n",
    "        self.result_df['TOPSIS_Score'] = C\n",
    "        self.result_df['Rank'] = self.result_df['TOPSIS_Score'].rank(ascending=False).astype(int)\n",
    "        self.result_df = self.result_df.sort_values('Rank')\n",
    "        \n",
    "        print(\"âœ… TOPSIS è®¡ç®—å®Œæˆã€‚å‰ 5 å:\")\n",
    "        print(self.result_df[['TOPSIS_Score', 'Rank']].head())\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 3: æ·±åº¦åˆ†æ (Deep Analysis - Oå¥–æ ¸æ­¦å™¨)\n",
    "    # ======================================================\n",
    "    def analyze_obstacle_degree(self, top_n=3):\n",
    "        \"\"\"\n",
    "        éšœç¢åº¦è¯Šæ–­: æ‰¾å‡ºæ˜¯å“ªä¸ªæŒ‡æ ‡æ‹–äº†åè…¿\n",
    "        å…¬å¼: O_ij = w_j * (1 - z_ij) / sum(w_j * (1 - z_ij))\n",
    "        \"\"\"\n",
    "        print(f\"\\nğŸ” å¯åŠ¨éšœç¢åº¦è¯Šæ–­ (Obstacle Degree Analysis)...\")\n",
    "        # ä½¿ç”¨ Min-Max å½’ä¸€åŒ–æ•°æ® (Internal_A) è®¡ç®—åç¦»åº¦ (1-z)\n",
    "        z_ij = self.df_norm_entropy.values\n",
    "        w_j = self.weights.values\n",
    "        \n",
    "        numerator = (1 - z_ij) * w_j\n",
    "        denominator = numerator.sum(axis=1, keepdims=True)\n",
    "        obstacle_mat = numerator / (denominator + 1e-9) * 100 # è½¬ç™¾åˆ†æ¯”\n",
    "        \n",
    "        obs_df = pd.DataFrame(obstacle_mat, index=self.df_raw.index, columns=self.df_raw.columns)\n",
    "        \n",
    "        # ä¸ºæ¯ä¸ªæ ·æœ¬æ‰¾å‡º Top N éšœç¢å› å­\n",
    "        factors = []\n",
    "        for idx, row in obs_df.iterrows():\n",
    "            top_factors = row.nlargest(top_n).index.tolist()\n",
    "            factors.append(\", \".join(top_factors))\n",
    "            \n",
    "        # å°†ç»“æœæ‹¼æ¥åˆ° result_df (éœ€æŒ‰ç´¢å¼•å¯¹é½)\n",
    "        self.result_df['Obstacle_Factors'] = pd.Series(factors, index=obs_df.index)\n",
    "        \n",
    "        print(f\"âœ… éšœç¢å› å­å·²è¯†åˆ«ã€‚ç¤ºä¾‹: ç¬¬ä¸€å ({self.result_df.index[0]}) çš„çŸ­æ¿æ˜¯ [{self.result_df.iloc[0]['Obstacle_Factors']}]\")\n",
    "        return obs_df\n",
    "\n",
    "    def analyze_sensitivity(self, perturb_range=0.2, runs=100):\n",
    "        \"\"\"\n",
    "        [æ ¸æ­¦å™¨] æ’ååè½¬æµ‹è¯• (Rank Reversal Test)\n",
    "        Monte Carlo æ¨¡æ‹Ÿï¼šéšæœºæ‰°åŠ¨æƒé‡ï¼Œè§‚å¯Ÿæ’åçš„ç¨³å®šæ€§\n",
    "        \"\"\"\n",
    "        print(f\"\\nğŸŒªï¸ å¯åŠ¨æ’åçµæ•åº¦æµ‹è¯• (Range: Â±{perturb_range*100}%, Runs: {runs})...\")\n",
    "        \n",
    "        base_weights = self.weights.values\n",
    "        rank_history = []\n",
    "        \n",
    "        # é”å®šå½“å‰ Top 5 å¯¹è±¡çš„ ID\n",
    "        top_5_ids = self.result_df.head(5).index.tolist()\n",
    "        \n",
    "        for _ in range(runs):\n",
    "            # éšæœºæ‰°åŠ¨æƒé‡\n",
    "            noise = np.random.uniform(1-perturb_range, 1+perturb_range, size=len(base_weights))\n",
    "            new_w = base_weights * noise\n",
    "            new_w = new_w / new_w.sum() # é‡æ–°å½’ä¸€åŒ–\n",
    "            \n",
    "            # å¿«é€Ÿé‡ç®— TOPSIS (ä»…ç®—åˆ†)\n",
    "            Z = self.df_norm_topsis.values * new_w\n",
    "            Z_plus = Z.max(axis=0); Z_minus = Z.min(axis=0)\n",
    "            D_plus = np.sqrt(((Z - Z_plus)**2).sum(axis=1))\n",
    "            D_minus = np.sqrt(((Z - Z_minus)**2).sum(axis=1))\n",
    "            scores = D_minus / (D_plus + D_minus + 1e-9)\n",
    "            \n",
    "            # è®°å½• Top 5 ID åœ¨æ–°æƒé‡ä¸‹çš„æ’å\n",
    "            temp_df = pd.DataFrame({'Score': scores}, index=self.df_norm_topsis.index)\n",
    "            temp_df['Rank'] = temp_df['Score'].rank(ascending=False)\n",
    "            \n",
    "            rank_history.append(temp_df.loc[top_5_ids, 'Rank'].values)\n",
    "            \n",
    "        rank_matrix = np.array(rank_history)\n",
    "        \n",
    "        # ç»˜å›¾ï¼šç®±çº¿å›¾\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.boxplot(rank_matrix, labels=top_5_ids, patch_artist=True)\n",
    "        # ----------------------------------------------------------------------------------\n",
    "        # [Fix] ä½¿ç”¨ rf\"...\" (Raw F-String) ä¿®å¤æ— æ•ˆè½¬ä¹‰åºåˆ—è­¦å‘Š\n",
    "        # ----------------------------------------------------------------------------------\n",
    "        plt.title(rf\"Rank Robustness Test (Weight Perturbation $\\pm${perturb_range*100:.0f}\\%)\")\n",
    "        \n",
    "        plt.ylabel(\"Rank Distribution\")\n",
    "        plt.xlabel(\"Top 5 Objects (Original Rank)\")\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.gca().invert_yaxis() # æ’åè¶Šå°è¶Šå¥½ï¼Œæ‰€ä»¥åœ¨å›¾ä¸Šè¶Šé«˜è¶Šå¥½\n",
    "        \n",
    "        save_path = f\"{self.output_dir}/Sensitivity_Rank_Boxplot.svg\"\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"âœ… çµæ•åº¦æµ‹è¯•å®Œæˆã€‚å›¾è¡¨å·²ä¿å­˜è‡³ {save_path}\")\n",
    "        plt.show()\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 4: å¯è§†åŒ– (Visualization)\n",
    "    # ======================================================\n",
    "    def plot_radar(self, top_k=5):\n",
    "        print(f\"\\nğŸ¨ ç»˜åˆ¶ Top {top_k} é›·è¾¾å›¾...\")\n",
    "        target_ids = self.result_df.head(top_k).index\n",
    "        # ä½¿ç”¨ Min-Max å½’ä¸€åŒ–æ•°æ®æ¥ç”»é›·è¾¾å›¾ï¼ˆ0-1ä¹‹é—´å¥½çœ‹ï¼‰\n",
    "        data = self.df_norm_entropy.loc[target_ids]\n",
    "        labels = data.columns\n",
    "        num_vars = len(labels)\n",
    "        \n",
    "        # è§’åº¦è®¡ç®— (é—­åˆ)\n",
    "        angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "        angles += angles[:1] \n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "        \n",
    "        colors = sns.color_palette(\"husl\", top_k)\n",
    "        for idx, (row_id, row) in enumerate(data.iterrows()):\n",
    "            values = row.tolist()\n",
    "            values += values[:1] # é—­åˆ\n",
    "            ax.plot(angles, values, linewidth=2, label=str(row_id), color=colors[idx])\n",
    "            ax.fill(angles, values, alpha=0.1, color=colors[idx])\n",
    "            \n",
    "        ax.set_theta_offset(np.pi / 2)\n",
    "        ax.set_theta_direction(-1)\n",
    "        ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "        plt.title(f\"Radar Chart of Top {top_k} Candidates\")\n",
    "        plt.savefig(f\"{self.output_dir}/Radar_Chart.svg\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_bar_scores(self):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        # ä»…ç»˜åˆ¶ Top 20 é¿å…æ‹¥æŒ¤\n",
    "        plot_data = self.result_df.head(20)\n",
    "        sns.barplot(x=plot_data.index, y='TOPSIS_Score', data=plot_data, palette=\"viridis\")\n",
    "        plt.axhline(self.result_df['TOPSIS_Score'].mean(), color='r', linestyle='--', label='Average')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title(f\"Evaluation Scores (Top {len(plot_data)})\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.output_dir}/Score_Bar.svg\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 5: äº¤ä»˜ (Delivery)\n",
    "    # ======================================================\n",
    "    def export_results(self):\n",
    "        print(f\"\\nğŸ“¦ === æ­£åœ¨æ‰“åŒ…äº¤ä»˜ç‰©è‡³ {self.output_dir} === \")\n",
    "        \n",
    "   \n",
    "        # [å»ºè®®åœ¨è¿™é‡Œè‡ªåŠ¨è°ƒç”¨ä¸€æ¬¡ï¼Œç¡®ä¿æ–‡ä»¶ç”Ÿæˆ] ğŸ‘‡\n",
    "        self.export_correlation_gephi(threshold=0.6)    \n",
    "       \n",
    "        # 1. å¯¼å‡º Excel\n",
    "        self.result_df.to_excel(f\"{self.output_dir}/Evaluation_Result.xlsx\")\n",
    "        \n",
    "        # 2. å¯¼å‡º LaTeX æƒé‡è¡¨\n",
    "        # æ³¨æ„: æ­¤å¤„ä¸ºæ™®é€šå­—ç¬¦ä¸²ï¼ŒåŒåæ–œæ æ˜¯æ­£ç¡®çš„è½¬ä¹‰å†™æ³•\n",
    "        tex = \"\\\\begin{table}[h]\\n\\\\centering\\n\\\\begin{tabular}{lc} \\\\toprule\\nIndicator & Weight \\\\\\\\ \\\\midrule\\n\"\n",
    "        for idx, val in self.weights.items():\n",
    "            tex += f\"{idx} & {val:.4f} \\\\\\\\\\n\"\n",
    "        tex += \"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\caption{Weights calculated by Entropy/Combined Method}\\n\\\\end{table}\"\n",
    "        with open(f\"{self.output_dir}/Weights.tex\", \"w\") as f: f.write(tex)\n",
    "        \n",
    "        # 3. è‡ªåŠ¨ç”ŸæˆæŠ¥å‘Š\n",
    "        top_1 = self.result_df.iloc[0]\n",
    "        worst_factor = top_1['Obstacle_Factors'] if 'Obstacle_Factors' in top_1 else \"N/A\"\n",
    "        \n",
    "        report = f\"# Evaluation Report: {self.name}\\n\\n\"\n",
    "        report += f\"## 1. Ranking Summary\\n\"\n",
    "        report += f\"- **Best Candidate**: {top_1.name} (Score: {top_1['TOPSIS_Score']:.4f})\\n\"\n",
    "        report += f\"- **Primary Obstacle**: Even for the best candidate, the limiting factor is **{worst_factor}**.\\n\\n\"\n",
    "        report += f\"## 2. Weight Analysis\\n\"\n",
    "        report += f\"The most influential indicator is **{self.weights.idxmax()}** (Weight: {self.weights.max():.4f}).\\n\\n\"\n",
    "        report += f\"## 3. Robustness\\n\"\n",
    "        report += f\"Please refer to `Sensitivity_Rank_Boxplot.svg` to check if the top ranking is stable against weight perturbations.\\n\"\n",
    "        \n",
    "        with open(f\"{self.output_dir}/Report.md\", \"w\", encoding='utf-8') as f: f.write(report)\n",
    "        \n",
    "        print(f\"âœ… [1] ç»“æœè¡¨: Evaluation_Result.xlsx (å«éšœç¢å› å­)\")\n",
    "        print(f\"âœ… [2] æƒé‡è¡¨: Weights.tex (LaTeXæºç )\")\n",
    "        print(f\"âœ… [3] å¯è§†åŒ–: *.svg (é›·è¾¾å›¾, ç®±çº¿å›¾)\")\n",
    "        print(f\"âœ… [4] æ™ºèƒ½æŠ¥å‘Š: Report.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e653f53-e2c8-49db-bb68-ce85e78f23e3",
   "metadata": {},
   "source": [
    "# âš”ï¸ V7.0 ç»¼åˆè¯„ä»·æŒ‡æŒ¥å®˜å…¨æµç¨‹ä½œæˆ˜æ‰‹å†Œ (Final Detailed Ver.)\n",
    "\n",
    "> **æˆ˜ç•¥æ ¸å¿ƒ**ï¼šè¯„ä»·æ¨¡å‹çš„æœ¬è´¨ä¸æ˜¯â€œæ’åº§æ¬¡â€ï¼Œè€Œæ˜¯â€œæ‰¾çŸ­æ¿â€å’Œâ€œè¯ç¨³å¥â€ã€‚\n",
    "> **æ ¸å¿ƒå£å·**ï¼šå…ˆæ ¡å‡† (Calibrate)ï¼Œå†è®¡ç®— (Compute)ï¼Œåè¯Šæ–­ (Diagnose)ï¼Œæœ€åè¾©æŠ¤ (Defend)ã€‚\n",
    "> **æ³¨æ„**ï¼šæ–‡æ¡£ä¸­åŠ ç²—çš„éƒ¨åˆ†ï¼Œæ˜¯æ¯”èµ›ç°åœºä½ å¿…é¡»è°ƒåŠ¨å¤§è„‘è¿›è¡Œåˆ¤æ–­å’Œå†³ç­–çš„å…³é”®æ—¶åˆ»ï¼Œå…¶ä½™éƒ¨åˆ†åªéœ€æœºæ¢°æ‰§è¡Œä»£ç ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ›‘ Phase -1: èµ›å‰æ¼”ä¹  (God Mode Verification)\n",
    "\n",
    "> **æ­¤é˜¶æ®µä»…åœ¨æ¯”èµ›å¼€å§‹å‰æ‰§è¡Œä¸€æ¬¡ã€‚å¦‚æœè¿è¿™ä¸€æ­¥éƒ½é€šè¿‡ä¸äº†ï¼Œç»ä¸è¦ä¸Šæˆ˜åœºã€‚**\n",
    "\n",
    "1.  **æ„é€ å‡æ•°æ®**:\n",
    "    * åœ¨ Excel ä¸­æ‰‹æä¸€ä¸ªç®€å•çŸ©é˜µï¼ˆå¦‚ 3ä¸ªæ ·æœ¬ A, B, C; 3ä¸ªæŒ‡æ ‡ X, Y, Zï¼‰ã€‚\n",
    "    * **ä¸Šå¸è®¾å®š**: è®© A å…¨é¢ç¢¾å‹ Bï¼ˆä¾‹å¦‚ A çš„å„é¡¹æ•°å€¼éƒ½æ¯” B å¥½ï¼‰ã€‚\n",
    "\n",
    "2.  **ç›²æµ‹**:\n",
    "    * è¿è¡Œ `solver.preprocess` å’Œ `solver.run_topsis()`ã€‚\n",
    "\n",
    "3.  **éªŒæ”¶æ ‡å‡† (Critical Check)**:\n",
    "    * **Q1**: A çš„æ’åå¿…é¡»æ˜¯ Rank 1 å—ï¼Ÿ\n",
    "    * **Q2**: B çš„éšœç¢å› å­è¯Šæ–­æ˜¯å¦å‡†ç¡®æŒ‡å‡ºäº†å®ƒçš„åŠ£åŠ¿ï¼Ÿ\n",
    "\n",
    "4.  **å¦‚æœä¸é€šè¿‡**: **ç«‹å³æ£€æŸ¥ `direction_dict` ä¸­çš„æ­£è´Ÿæ–¹å‘æ˜¯å¦å†™åäº†**ã€‚è¿™æ˜¯è¯„ä»·ç±»é—®é¢˜æœ€è‡´å‘½çš„é”™è¯¯ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ•µï¸ Phase 0: ä¾¦å¯Ÿä¸å®šä¹‰ (Recon & Definition)\n",
    "\n",
    "> **æ­¤é˜¶æ®µå†³å®šæ¨¡å‹çš„ç”Ÿæ­»ï¼Œä»»ä½•æ•°å­¦è®¡ç®—éƒ½æ— æ³•æŒ½å›æ–¹å‘æ€§çš„é”™è¯¯ã€‚**\n",
    "\n",
    "#### æ­¥éª¤ 0.1: å¯åŠ¨ä¸æ¡æ‰‹\n",
    "\n",
    "```\n",
    "# åŠ¨ä½œ\n",
    "solver = Eval_Solver_Capsule(name=\"Problem_E_Eval\")\n",
    "solver.generate_handshake()\n",
    "# æŒ‡ä»¤: å¤åˆ¶æ‰“å°å‡ºçš„ Prompt å‘é€ç»™ AIã€‚\n",
    "```\n",
    "\n",
    "#### æ­¥éª¤ 0.2: æ ¸å¿ƒå®šä¹‰ (The Definition) â€”â€” äººç±»å”¯ä¸€è¦åšçš„äº‹\n",
    "\n",
    "* **åŠ¨ä½œ**: è¯»å–æ•°æ® `df = pd.read_csv(...)`ã€‚\n",
    "* **å…³é”®å†³ç­– (Direction Definition)**: ä½ å¿…é¡»é€ä¸ªå®¡è§†æŒ‡æ ‡çš„ç‰©ç†æ„ä¹‰ã€‚\n",
    "    * **Max (æå¤§)**: æ•ˆç›Šã€GDPã€åˆæ ¼ç‡ã€æ»¡æ„åº¦ã€‚ -> å†™å…¥ `direction={'col': 'max'}`\n",
    "    * **Min (æå°)**: æˆæœ¬ã€æ±¡æŸ“æ’æ”¾ã€æ•…éšœç‡ã€ç­‰å¾…æ—¶é—´ã€‚ -> å†™å…¥ `direction={'col': 'min'}`\n",
    "    * **Mid (ä¸­é—´)**: PHå€¼ã€å¸ˆç”Ÿæ¯”ï¼ˆè¿‡é«˜è¿‡ä½éƒ½ä¸å¥½ï¼‰ã€‚ -> å†™å…¥ `direction={'col': 'mid'}`ï¼Œå¹¶æ€è€ƒæœ€ä¼˜å€¼æ˜¯å¤šå°‘ï¼ˆå‡å€¼ï¼Ÿè¿˜æ˜¯ç‰¹å®šæ ‡å‡†å€¼ï¼Ÿï¼‰ã€‚\n",
    "\n",
    "* **åŠ¨ä½œ**ï¼š`df.describe()`\n",
    "* **å†³ç­–**ï¼šæ£€æŸ¥ `max` æ˜¯å¦è¿œå¤§äº `75%` åˆ†ä½æ•°ã€‚\n",
    "* **å¯¹ç­–**ï¼šå¦‚æœå‘ç°æç«¯å€¼ï¼Œå¿…é¡»åœ¨é¢„å¤„ç†å‰è¿›è¡Œ `Log å˜æ¢`ï¼ˆå¯¹æ•°åŒ–ï¼‰æˆ–è€… `Winsorize`ï¼ˆç¼©å°¾å¤„ç†ï¼‰ï¼Œå¦åˆ™ç†µæƒæ³•ä¼šå¤±çœŸã€‚\n",
    "\n",
    "#### æ­¥éª¤ 0.3: æƒé‡æˆ˜ç•¥ (Weight Strategy) â€”â€” å†³å®šè®ºæ–‡ç«‹åœº\n",
    "\n",
    "* **å…³é”®å†³ç­– (Philosophical Choice)**:\n",
    "    * **åœºæ™¯ A (ç›¸ä¿¡æ•°æ®)**: é¢˜ç›®æ²¡æœ‰æ˜æ˜¾åå‘ã€‚ -> ä½¿ç”¨ `method='entropy'` (ç†µæƒæ³•)ã€‚\n",
    "    * **åœºæ™¯ B (å¼ºæ”¿ç­–å¹²é¢„)**: é¢˜ç›®èƒŒæ™¯æ˜¯â€œå¯æŒç»­å‘å±•â€ï¼Œå¿…é¡»å¼ºè°ƒç¯ä¿ï¼›æˆ–è€…é¢˜ç›®æ˜¯â€œå®‰å…¨æ€§è¯„ä»·â€ï¼Œå¿…é¡»å¼ºè°ƒä½é£é™©ã€‚ -> **å¿…é¡»ä½¿ç”¨ `method='combined'`ï¼Œå¹¶æ‰‹åŠ¨è®¾ç½® `manual_weights={'Env': 0.4}`**ã€‚ä¸è¦è®©ç†µæƒæ³•æŠŠæ ¸å¿ƒæŒ‡æ ‡çš„æƒé‡ç®—å¾—å¤ªä½ï¼ˆå¦‚æœæ ¸å¿ƒæŒ‡æ ‡æ–¹å·®å°ï¼Œç†µæƒä¼šå¾ˆä½ï¼Œè¿™ä¼šå¯¼è‡´é€»è¾‘è°¬è¯¯ï¼‰ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‘‘ Phase 1: è¿ç®—ä¸å¹²é¢„ (Execution & Intervention)\n",
    "\n",
    "> ç”± V7.0 çš„â€œåŒé‡å½’ä¸€åŒ–æ¶æ„â€è‡ªåŠ¨æŠ¤èˆªã€‚\n",
    "\n",
    "#### æ­¥éª¤ 1.1: é¢„å¤„ç†ä¸è®¡ç®—\n",
    "```\n",
    "solver.preprocess(df, direction_dict)\n",
    "solver.compute_weights(...)\n",
    "```\n",
    "\n",
    "#### æ­¥éª¤ 1.2: æƒé‡å®¡è®¡ (The Sanity Check) â€”â€” é˜²æ­¢é—¹ç¬‘è¯\n",
    "* **è§‚å¯Ÿ**: ç¨‹åºæ‰“å°å‡ºçš„ `\"Top 3 Important Indicators\"`ã€‚\n",
    "* **å…³é”®åˆ¤æ–­**:\n",
    "    * **å¦‚æœ**ï¼šä¸€ä¸ªæ— å…³ç´§è¦çš„æŒ‡æ ‡ï¼ˆå¦‚â€œç»Ÿè®¡å‘˜ç¼–å·â€ã€â€œåœ°åŒºä»£ç â€ï¼‰è·å¾—äº†æé«˜çš„æƒé‡ã€‚\n",
    "    * **è¯Šæ–­**: è¯´æ˜è¯¥åˆ—æ•°æ®æ–¹å·®æå¤§æˆ–å­˜åœ¨å¼‚å¸¸å€¼ã€‚\n",
    "    * **è¡ŒåŠ¨**: **ç«‹å³å‰”é™¤è¯¥æŒ‡æ ‡ï¼Œæˆ–æ”¹ç”¨æ‰‹åŠ¨æƒé‡å¼ºè¡Œå‹ä½å…¶å½±å“**ã€‚ç»ä¸èƒ½æŠŠç”±å™ªéŸ³äº§ç”Ÿçš„æƒé‡å†™è¿›è®ºæ–‡ã€‚\n",
    "\n",
    "#### æ­¥éª¤ 1.3: è·‘åˆ†\n",
    "```\n",
    "solver.run_topsis()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§¬ Phase 2: æ·±åº¦è¯Šæ–­ (Diagnosis) â€”â€” O å¥–æ ¸å¿ƒå™äº‹\n",
    "\n",
    "> **æ™®é€šè®ºæ–‡å†™åˆ°æ’åå°±ç»“æŸäº†ï¼ŒO å¥–è®ºæ–‡ä»è¿™é‡Œå¼€å§‹ã€‚**\n",
    "\n",
    "#### æ­¥éª¤ 2.1: éšœç¢åº¦æ‰«æ\n",
    "```\n",
    "solver.analyze_obstacle_degree(top_n=3)\n",
    "# äº§ç‰©: Excel ä¸­çš„ Obstacle_Factors åˆ—ã€‚\n",
    "```\n",
    "\n",
    "#### æ­¥éª¤ 2.2: å½’å› åˆ†æ (Attribution) â€”â€” è®ºæ–‡å†™ä½œæ ¸å¿ƒ\n",
    "* **å…³é”®å†™ä½œé€»è¾‘**:\n",
    "    * **ä¸è¦åªå†™**ï¼šâ€œA ç¬¬ä¸€ï¼ŒB ç¬¬äºŒâ€ã€‚è¿™æ˜¯åºŸè¯ã€‚\n",
    "    * **è¦å†™**: â€œA èƒ½å¤Ÿå¤ºå† ï¼Œæ˜¯å› ä¸ºå…¶åœ¨æƒé‡æœ€é«˜çš„ [æŒ‡æ ‡X] ä¸Šè¡¨ç°å®Œç¾ï¼›è€Œ B è™½ç„¶åœ¨ç»æµæŒ‡æ ‡ä¸Šé¢†å…ˆï¼Œä½†è¢« [æŒ‡æ ‡Y] (éšœç¢åº¦ 45%) ä¸¥é‡æ‹–äº†åè…¿ï¼Œè¿™è¡¨æ˜ B çš„å‘å±•å­˜åœ¨ç»“æ„æ€§å¤±è¡¡ã€‚â€\n",
    "* **ä»·å€¼**: è¿™æŠŠâ€œæ•°å­¦è®¡ç®—â€å‡ç»´åˆ°äº†â€œæ”¿ç­–å»ºè®®â€ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ›¡ï¸ Phase 3: ç¨³å¥æ€§è¾©æŠ¤ (Defense)\n",
    "\n",
    "> **è¯„å§”æœ€å–œæ¬¢æ”»å‡»ç‚¹ï¼šä½ çš„æƒé‡å˜ä¸€ç‚¹ï¼Œæ’åæ˜¯ä¸æ˜¯å°±ä¹±äº†ï¼Ÿ**\n",
    "\n",
    "#### æ­¥éª¤ 3.1: å‹åŠ›æµ‹è¯•\n",
    "```\n",
    "# è®©æƒé‡éšæœºæ³¢åŠ¨ 20%\n",
    "solver.analyze_sensitivity(perturb_range=0.2, runs=100) \n",
    "```\n",
    "\n",
    "#### æ­¥éª¤ 3.2: è¾©æŠ¤è¯ (The Narrative) â€”â€” çœ‹å›¾è¯´è¯\n",
    "* **è§‚å¯Ÿ**: æ‰“å¼€ `Sensitivity_Rank_Boxplot.svg`ã€‚\n",
    "* **å…³é”®åˆ¤æ–­**:\n",
    "    * **æƒ…å½¢ A (ç®±å­å¾ˆçŸ­)**: â€œæåº¦é²æ£’â€ã€‚ç»“è®ºï¼šæ¨¡å‹å¯¹å‚æ•°ä¸æ•æ„Ÿï¼Œæ’åå¯ä¿¡åº¦æé«˜ã€‚\n",
    "    * **æƒ…å½¢ B (ç®±å­å¾ˆé•¿/äº’æ–¥)**: â€œç«äº‰æ¿€çƒˆâ€ã€‚ç»“è®ºï¼šâ€œRank 2 å’Œ Rank 3 å‡ºç°äº†é¢‘ç¹äº¤æ›¿ï¼Œè¿™æ­ç¤ºäº†ä¸¤è€…åœ¨ç»¼åˆå®åŠ›ä¸Šå¤„äºä¼¯ä»²ä¹‹é—´ (Trade-off)ï¼Œä¸ä»…å–å†³äºå•ä¸€æŒ‡æ ‡ï¼Œæ›´å–å†³äºå†³ç­–è€…å¯¹ [å·®å¼‚æŒ‡æ ‡] çš„åå¥½ã€‚â€ â€”â€” **è¯šå®åœ°è§£é‡Šæ³¢åŠ¨ï¼Œæ¯”æ©ç›–æ³¢åŠ¨æ›´å¾—åˆ†ã€‚**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“¦ Phase 4: äº¤ä»˜ä¸æ”¶å‰² (Harvest)\n",
    "\n",
    "> **ä¸€é”®ç”Ÿæˆï¼Œé™ç»´æ‰“å‡»ã€‚**\n",
    "\n",
    "#### æ­¥éª¤ 4.1: å¯è§†åŒ–ä¸å¯¼å‡º\n",
    "```\n",
    "solver.plot_radar(top_k=5)\n",
    "solver.export_results()\n",
    "```\n",
    "\n",
    "#### æ­¥éª¤ 4.2: ç´ æåº”ç”¨\n",
    "* **é›·è¾¾å›¾**: æ”¾æ­£æ–‡ã€‚é…åˆæ–‡å­—ï¼šâ€œä»é›·è¾¾å›¾é—­åˆåŒºåŸŸçš„å½¢çŠ¶å¯ä»¥çœ‹å‡ºï¼Œç¬¬ä¸€åæ˜¯å…¨èƒ½å‹é€‰æ‰‹ï¼Œè€Œç¬¬ä¸‰åæ˜¯åç§‘å‹é€‰æ‰‹ã€‚â€\n",
    "* **æ™ºèƒ½æˆ˜æŠ¥**: å¤åˆ¶ `Report.md` åˆ° Result ç« èŠ‚ã€‚\n",
    "* **æƒé‡è¡¨**: å¤åˆ¶ `Weights.tex` åˆ°é™„å½•ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸŒŸ é™„å½•ï¼šé«˜ç»´ç›¸å…³æ€§å¯è§†åŒ–åè®® (The Correlation Visualization Protocol)\n",
    "\n",
    "> **å¦‚æœä½ çš„è¯„ä»·æŒ‡æ ‡è¶…è¿‡ 10 ä¸ªï¼Œä¸”éœ€è¦åˆ†æâ€œæŒ‡æ ‡é—´çš„ååŒ/æ‹®æŠ—å…³ç³»â€ï¼ˆä¾‹å¦‚ï¼šGDPå¢é•¿æ˜¯å¦å¿…ç„¶å¯¼è‡´æ±¡æŸ“å¢åŠ ï¼Ÿï¼‰ï¼Œè¯·æ‰§è¡Œæ­¤æ­¥ã€‚**\n",
    "> *æ³¨æ„ï¼šè¯„ä»·æ¨¡å‹é€šå¸¸ä¸éœ€è¦ Gephi ç”»èŠ‚ç‚¹å…³ç³»ï¼Œä½†å¯ä»¥ç”¨ Gephi ç”»æŒ‡æ ‡å…³ç³»ç½‘ã€‚*\n",
    "\n",
    "1.  **å‡†å¤‡æ•°æ®**:\n",
    "    * è®¡ç®—æŒ‡æ ‡é—´çš„ç›¸å…³ç³»æ•°çŸ©é˜µ (Pearson Correlation)ã€‚\n",
    "    * å°†ç›¸å…³ç³»æ•° >0.6 (å¼ºç›¸å…³) æˆ– <âˆ’0.6 (å¼ºè´Ÿç›¸å…³) çš„å…³ç³»æå–ä¸ºè¾¹è¡¨ã€‚\n",
    "\n",
    "2.  **å¯åŠ¨ Gephi**:\n",
    "    * å¯¼å…¥è¾¹è¡¨ã€‚èŠ‚ç‚¹æ˜¯â€œæŒ‡æ ‡åâ€ï¼Œè¾¹çš„æƒé‡æ˜¯â€œç›¸å…³ç³»æ•°ç»å¯¹å€¼â€ã€‚\n",
    "\n",
    "3.  **å¸ƒå±€ (Layout)**:\n",
    "    * ä½¿ç”¨ **\"Force Atlas 2\"**ã€‚\n",
    "    * **æ•ˆæœ**: å¼ºç›¸å…³çš„æŒ‡æ ‡ä¼šèšåœ¨ä¸€èµ·ï¼Œå½¢æˆâ€œæŒ‡æ ‡ç°‡â€ï¼ˆå¦‚ç»æµç°‡ã€ç¯ä¿ç°‡ï¼‰ã€‚\n",
    "\n",
    "4.  **æ¸²æŸ“**:\n",
    "    * **é¢œè‰²**ï¼šæ ¹æ®æ¨¡å—åº¦ (Modularity) æŸ“è‰²ã€‚\n",
    "    * **è®ºæ–‡è§£é‡Š**: â€œé€šè¿‡ Gephi ç½‘ç»œæ‹“æ‰‘åˆ†æï¼Œæˆ‘ä»¬å‘ç° [ç»æµæŒ‡æ ‡] ä¸ [æ•™è‚²æŒ‡æ ‡] å½¢æˆäº†ç´§å¯†çš„ååŒé›†ç¾¤ï¼Œè€Œä¸ [ç¯å¢ƒæŒ‡æ ‡] å¤„äºç½‘ç»œçš„å¯¹ç«‹ç«¯ï¼Œç›´è§‚åœ°æ­ç¤ºäº†å‘å±•ä¸­çš„çŸ›ç›¾ä¸åˆ¶çº¦ã€‚â€\n",
    "    * *æ³¨: è¿™æ˜¯ä¸€å¼ éå¸¸é«˜çº§çš„å›¾ï¼Œé€šå¸¸ç”¨äºæ›¿ä»£æ¯ç‡¥çš„ç›¸å…³ç³»æ•°çƒ­åŠ›å›¾ã€‚*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859d5ba3-28e0-463b-8f33-b3d3028b4a1d",
   "metadata": {},
   "source": [
    "æ”¶åˆ°ã€‚é’ˆå¯¹ ç¬¬ä¸‰éƒ¨åˆ†ï¼šæœ¬åœ°äº¤äº’ä¸AIäº¤äº’å·¥ä½œæµï¼Œæˆ‘è¿›è¡Œäº†æœ€ç»ˆçš„é€»è¾‘é—­ç¯è‡ªæ£€ (Final Logic Audit)ã€‚\n",
    "\n",
    "æœ¬æ¬¡è‡ªæ£€é‡ç‚¹ä¿®æ­£äº†ä»¥ä¸‹ä¸‰ä¸ªâ€œéšå½¢å‘â€ï¼š\n",
    "\n",
    "1.  **ä¸Šä¸‹æ–‡æ–­å±‚ (Context Gap)**ï¼šæ˜ç¡®äº† AI åœ¨â€œå¤±å¿†â€çŠ¶æ€ä¸‹ï¼Œå¿…é¡»å…ˆæ¥æ”¶ä»£ç å®šä¹‰æ‰èƒ½å·¥ä½œã€‚\n",
    "2.  **Gephi åè®®çš„å‡†ç¡®æ€§**ï¼šä¿®æ­£äº† Gephi å¯¼å‡ºçš„æŒ‡ä»¤ï¼ˆå› ä¸ºè¯„ä»·ç±»ä»£ç æ²¡æœ‰å†…ç½® Gephi å¯¼å‡ºï¼Œå¿…é¡»æ˜ç¡®æŒ‡ç¤º AI ä½¿ç”¨ Pandas ç”Ÿæˆç›¸å…³ç³»æ•°çŸ©é˜µï¼‰ã€‚\n",
    "3.  **å†³ç­–ç‚¹æ˜¾æ€§åŒ–**ï¼šå°†æ‰€æœ‰éœ€è¦äººç±»ä»‹å…¥çš„å‚æ•°ï¼ˆå¦‚æŒ‡æ ‡æ–¹å‘ã€æƒé‡åå¥½ï¼‰åšäº†é«˜äº®å¤„ç†ã€‚\n",
    "\n",
    "ä»¥ä¸‹æ˜¯æœ€ç»ˆä¿®æ­£ã€ç»å¯¹å¯ç”¨çš„äº¤äº’å·¥ä½œæµã€‚\n",
    "\n",
    "## ğŸ¤– ç¬¬ä¸‰éƒ¨åˆ†ï¼šAI äº¤äº’å·¥ä½œæµ (Final RPG Prompts)\n",
    "\n",
    "**æ“ä½œé€»è¾‘**: è¿™æ˜¯ä½ ä¸ AI (ChatGPT/Claude) çš„å¯¹è¯å‰§æœ¬ã€‚è¯·æŒ‰é¡ºåºå¤åˆ¶å‘é€ã€‚\n",
    "\n",
    "### ğŸ•¹ï¸ Phase 0.1: æœ¬åœ°å¯åŠ¨ (Local Preparation)\n",
    "\n",
    "* **æ‰§è¡Œä½ç½®**: æœ¬åœ° Jupyter Notebook\n",
    "* **ç›®çš„**: ç¡®ç«‹åŸºå‡†ï¼Œç”Ÿæˆæ¡æ‰‹åè®®ã€‚\n",
    "\n",
    "```\n",
    "# [Action] åœ¨æœ¬åœ°è¿è¡Œ\n",
    "import pandas as pd\n",
    "# åŠ¡å¿…ç¡®ä¿ Eval_Solver_Capsule ç±»ä»£ç å·²åœ¨ä¸Šæ–¹å•å…ƒæ ¼è¿è¡Œè¿‡\n",
    "\n",
    "# 1. è¯»å–æ•°æ® (è¯·ä¿®æ”¹æ–‡ä»¶å)\n",
    "df = pd.read_csv('data.csv', index_col=0) \n",
    "\n",
    "# 2. å®ä¾‹åŒ–\n",
    "solver = Eval_Solver_Capsule(name=\"MCM_Problem_E\")\n",
    "\n",
    "# 3. ç”Ÿæˆæ¡æ‰‹åè®® (å…³é”®æ­¥éª¤)\n",
    "# è¿™å°†è¾“å‡ºä¸€æ®µåŒ…å« API æ¸…å•å’Œæ•°å­¦é™·é˜±çš„æ–‡æœ¬ï¼Œè¯·å…¨éƒ¨å¤åˆ¶\n",
    "solver.generate_handshake(df_dict={'Raw_Data': df})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ Phase 1: åˆå§‹åŒ–ä¸å®šä¹‰ (Prompt_Eval_Init.txt)\n",
    "\n",
    "* **æ‰§è¡Œä½ç½®**: å‘é€ç»™ AI\n",
    "* **å‰ç½®åŠ¨ä½œ (å¿…é¡»æ‰§è¡Œ)**:\n",
    "    1.  å…ˆå‘ **Eval_Solver_Capsule ç±»ä»£ç ** ç»™ AIã€‚\n",
    "    2.  å†å‘ **æ•°æ® (CSVæ–‡æœ¬)** ç»™ AIã€‚\n",
    "    3.  æœ€åå‘ **Phase 0.1 ç”Ÿæˆçš„æ¡æ‰‹åè®®** ç»™ AIã€‚\n",
    "* **ç„¶åå‘é€ä»¥ä¸‹æŒ‡ä»¤**:\n",
    "\n",
    "\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šPhase 1 - è¯„ä»·æ¨¡å‹åˆå§‹åŒ–ã€‘\n",
    "\n",
    "æˆ‘å·²åŠ è½½ V7.0 ç±»å’Œæ•°æ®ã€‚è¯·æ‰§è¡Œï¼š\n",
    "\n",
    "1.  **å®ä¾‹åŒ–**: `solver = Eval_Solver_Capsule(name='Impact_Eval')`ã€‚\n",
    "2.  **æŒ‡æ ‡å®šæ€§ (Critical Definition - äººç±»å†³ç­–)**:\n",
    "    - **è¯·ä¸¥æ ¼æŒ‰ç…§æˆ‘çš„ä¸šåŠ¡é€»è¾‘å®šä¹‰æ–¹å‘**ï¼š\n",
    "      - **æ•ˆç›Šå‹ ('max')**: `[å¡«å…¥åˆ—å, å¦‚: ç»æµå¢é•¿, æ»¡æ„åº¦]`\n",
    "      - **æˆæœ¬å‹ ('min')**: `[å¡«å…¥åˆ—å, å¦‚: æ±¡æŸ“æŒ‡æ•°, æ•…éšœç‡]`\n",
    "      - **ä¸­é—´å‹ ('mid')**: `[å¡«å…¥åˆ—å, å¦‚: PHå€¼, å·®å¼‚åº¦]`\n",
    "    - æ‰§è¡Œ: `solver.preprocess(df, direction_dict=...)`ã€‚\n",
    "3.  **åŒé‡å®¡è®¡**:\n",
    "    - æ‰§è¡Œ `solver.audit()`ã€‚\n",
    "    - **æ£€æŸ¥ç‚¹**: ç¡®ä¿é¢„å¤„ç†æœªäº§ç”Ÿ NaNã€‚ç¡®è®¤ `df_norm_entropy` (ç”¨äºç†µæƒ) å’Œ `df_norm_topsis` (ç”¨äºè·‘åˆ†) å‡å·²ç”Ÿæˆã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§¬ Phase 2: è®¡ç®—ä¸è¯Šæ–­ (Prompt_Eval_Run.txt)\n",
    "\n",
    "* **æ‰§è¡Œä½ç½®**: å‘é€ç»™ AI\n",
    "* **ç›®çš„**: è·‘å‡ºæ’åï¼Œå¹¶æŒ–æ˜â€œä¸ºä»€ä¹ˆä»–æ˜¯ç¬¬äºŒåâ€çš„æ·±å±‚åŸå› ã€‚\n",
    "\n",
    "\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šPhase 2 - æ ¸å¿ƒè®¡ç®—ä¸æ·±åº¦è¯Šæ–­ã€‘\n",
    "\n",
    "è¯·æ‰§è¡Œè¯„ä»·æµç¨‹ï¼š\n",
    "\n",
    "1.  **èµ‹æƒ (Weighting)**:\n",
    "    - **å†³ç­–åˆ†æ”¯**:\n",
    "      - è‹¥é¢˜ç›®æ— åå¥½: æ‰§è¡Œ `solver.compute_weights(method='entropy')`ã€‚\n",
    "      - **è‹¥é¢˜ç›®å¼ºè°ƒæŸæŒ‡æ ‡(å¦‚ç¯ä¿)**: æ‰§è¡Œ `solver.compute_weights(method='combined', manual_weights={'ç¯ä¿': 0.4}, alpha=0.5)`ã€‚\n",
    "    - **è¾“å‡º**: æ‰“å° Top 3 æƒé‡ã€‚**å¦‚æœæ— å…³æŒ‡æ ‡æƒé‡è¿‡é«˜ï¼Œè¯·ç«‹å³åœæ­¢å¹¶è­¦å‘Šæˆ‘ã€‚**\n",
    "2.  **è®¡ç®— (Scoring)**:\n",
    "    - æ‰§è¡Œ `solver.run_topsis()`ã€‚\n",
    "    - æ‰“å°ç»¼åˆæ’åå‰ 5 çš„å¯¹è±¡ã€‚\n",
    "3.  **æ·±åº¦è¯Šæ–­ (Obstacle Analysis - Oå¥–æ ¸å¿ƒ)**:\n",
    "    - æ‰§è¡Œ `solver.analyze_obstacle_degree(top_n=3)`ã€‚\n",
    "    - **å½’å› åˆ†æ (å¿…é¡»æ‰§è¡Œ)**:\n",
    "      - ä¸è¦åªæŠ¥æ•°å­—ï¼è¯·ç”¨è‡ªç„¶è¯­è¨€å‘Šè¯‰æˆ‘ï¼š**â€œæ’åç¬¬ 2 çš„å¯¹è±¡ï¼Œå…¶ä¸»è¦çŸ­æ¿ï¼ˆéšœç¢å› å­ï¼‰æ˜¯ä»€ä¹ˆï¼Ÿä¸ç¬¬ 1 åçš„å·®è·ä¸»è¦ä½“ç°åœ¨å“ªä¸ªæŒ‡æ ‡ï¼Ÿâ€**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ›¡ï¸ Phase 3: ç¨³å¥æ€§ä¸äº¤ä»˜ (Prompt_Eval_Harvest.txt)\n",
    "\n",
    "* **æ‰§è¡Œä½ç½®**: å‘é€ç»™ AI\n",
    "* **ç›®çš„**: ç”¨è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿå µä½è¯„å§”çš„å˜´ï¼Œå¹¶å¯¼å‡ºç´ æã€‚\n",
    "\n",
    "\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šPhase 3 - ç¨³å¥æ€§è¾©æŠ¤ä¸äº¤ä»˜ã€‘\n",
    "\n",
    "1.  **ç¨³å¥æ€§è¾©æŠ¤ (Defense)**:\n",
    "    - æ‰§è¡Œ `solver.analyze_sensitivity(perturb_range=0.2, runs=100)`ã€‚\n",
    "    - **å›¾è¡¨è§£è¯»**: \n",
    "      - ç”Ÿæˆ `Sensitivity_Rank_Boxplot.svg`ã€‚\n",
    "      - **ç»“è®ºé€»è¾‘**: \n",
    "        - è‹¥ç®±å­çŸ­ -> \"æ¨¡å‹é²æ£’ï¼Œæ’åå¯ä¿¡\"ã€‚\n",
    "        - è‹¥ç®±å­é•¿ -> \"å‰æ’ç«äº‰æ¿€çƒˆï¼Œå­˜åœ¨ Trade-off\"ã€‚\n",
    "2.  **å¯è§†åŒ– (Visualization)**:\n",
    "    - `solver.plot_radar(top_k=5)`ã€‚\n",
    "    - `solver.plot_bar_scores()`ã€‚\n",
    "    - **Gephi åè®® (å¯é€‰)**: è‹¥æŒ‡æ ‡ > 10 ä¸”éœ€åˆ†ææŒ‡æ ‡é—´å…³ç³»ï¼š\n",
    "      - è¯·ä½¿ç”¨ `df.corr()` è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µï¼Œå¹¶ä¿å­˜ä¸º `Correlation_Matrix.xlsx`ï¼Œä»¥ä¾¿æˆ‘è¿›è¡Œç½‘ç»œåˆ†æã€‚\n",
    "3.  **å…¨å¥—äº¤ä»˜ (Harvest)**:\n",
    "    - `solver.export_results()`ã€‚\n",
    "    - **æ™ºèƒ½æˆ˜æŠ¥éªŒæ”¶**: è¯»å–å¹¶æ‰“å° `Report.md` å†…å®¹ã€‚\n",
    "    - **æœ€ç»ˆæ£€æŸ¥**: ç¡®è®¤ `Evaluation_Result.xlsx` (å«éšœç¢å› å­) å’Œ `Weights.tex` (LaTeXä»£ç ) å·²ç”Ÿæˆ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267051f3-3591-4c39-92b4-840c81268e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
