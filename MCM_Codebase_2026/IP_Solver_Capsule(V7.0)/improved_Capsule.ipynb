{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "336c5c59-8d23-49c9-91e2-6fa63213f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pulp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D  # [V7.1 UPDATE] ç”¨äºè‡ªå®šä¹‰å›¾ä¾‹\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "import copy\n",
    "import shutil # [V7.1 UPDATE] ç”¨äºæ–‡ä»¶å½’æ¡£æ“ä½œ\n",
    "\n",
    "# --- V7.0 ç»˜å›¾ç¾å­¦é…ç½® ---\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'SimHei'] \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "try:\n",
    "    import scienceplots\n",
    "    plt.style.use(['science', 'no-latex'])\n",
    "except ImportError:\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"deep\", context=\"paper\")\n",
    "\n",
    "class IP_Solver_Capsule:\n",
    "    def __init__(self, name=\"MIP_Model\", sense='max'):\n",
    "        \"\"\"\n",
    "        [MCM IP Solver V7.1 - Engineered Edition]\n",
    "        Core: Integer Programming (IP) & Mixed Integer Programming (MIP)\n",
    "        Updates: \n",
    "          - Added Dictionary Variable Support (for non-integer indices)\n",
    "          - Added Mandatory Assignment Helper (prevents 'Lazy Solver')\n",
    "          - Enhanced Visualization with Custom Legends\n",
    "          - Added Project Archiving System\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.timestamp = int(time.time())\n",
    "        self.sense = pulp.LpMaximize if sense.lower() == 'max' else pulp.LpMinimize\n",
    "        \n",
    "        self.prob = pulp.LpProblem(self.name, self.sense)\n",
    "        \n",
    "        self.matrix_vars = {}   \n",
    "        self.single_vars = {}   \n",
    "        self.binary_vars = []   \n",
    "        self.aux_vars = {}      \n",
    "        \n",
    "        self.output_dir = f\"./Results_{name}_{self.timestamp}\"\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 0: æ¡æ‰‹ (Handshake)\n",
    "    # ======================================================\n",
    "    def generate_handshake(self):\n",
    "        print(f\"\\nğŸ¤ === å¤åˆ¶ä»¥ä¸‹ Prompt å‘é€ç»™ AI (V7.1 IP) ===\\n\")\n",
    "        print(f\"ã€ç³»ç»Ÿè®¾å®šã€‘\\næˆ‘æ­£åœ¨ä½¿ç”¨ `IP_Solver_Capsule` (V7.1)ã€‚\")\n",
    "        print(f\"ç›®æ ‡: {'Maximize' if self.sense == -1 else 'Minimize'} | è¾“å‡º: `{self.output_dir}`\")\n",
    "        print(\"\\nã€API æ¥å£æ¸…å•ã€‘\")\n",
    "        print(\"1. çŸ©é˜µå˜é‡: solver.add_var_matrix(...) æˆ– solver.add_vars_dict(...)\") # [V7.1 UPDATE]\n",
    "        print(\"2. é€»è¾‘çº¦æŸ: solver.add_logic_constraint(...)\")\n",
    "        print(\"3. æŒ‡æ´¾çº¦æŸ: solver.add_mandatory_assignment(...)\") # [V7.1 UPDATE]\n",
    "        print(\"4. TSPå›è·¯: solver.add_TSP_subtour_elimination(...)\")\n",
    "        print(\"5. æ±‚è§£è‡ªæ„ˆ: solver.solve(time_limit=300, gap_rel=0.05)\")\n",
    "        print(\"6. [MIPæ ¸æ­¦å™¨] æ•´æ•°ä»£ä»·/å†³ç­–ç¨³å®šæ€§: analyze_relaxation_gap / analyze_binary_stability\")\n",
    "        print(\"7. [å¯è§†åŒ–] visualize_routing / visualize_schedule / visualize_matrix\")\n",
    "        print(\"8. [äº¤ä»˜] å…¨é‡å½’æ¡£: solver.archive_project(...)\") # [V7.1 UPDATE]\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 1: å»ºæ¨¡å·¥å‚ (Modeling Factory)\n",
    "    # ======================================================\n",
    "    def add_var_matrix(self, rows, cols, name=\"x\", cat='Binary'):\n",
    "        \"\"\" ç”ŸæˆäºŒç»´å˜é‡çŸ©é˜µ (List-based index) \"\"\"\n",
    "        vars_dict = pulp.LpVariable.dicts(name, (rows, cols), 0, 1 if cat=='Binary' else None, cat)\n",
    "        self.matrix_vars[name] = vars_dict\n",
    "        if cat == 'Binary':\n",
    "            for r in rows:\n",
    "                for c in cols:\n",
    "                    self.binary_vars.append(vars_dict[r][c])\n",
    "        print(f\"âœ… çŸ©é˜µå˜é‡å·²åˆ›å»º: {name}[{len(rows)}x{len(cols)}] (Type: {cat})\")\n",
    "        return vars_dict\n",
    "\n",
    "    # =========================================================================\n",
    "    # [V7.1 UPDATE] æ–°å¢: å­—å…¸å˜é‡æ”¯æŒ\n",
    "    # ç”¨é€”: è§£å†³ Phase 1 ä¸­ \"AttributeError\" é—®é¢˜ï¼Œæ”¯æŒ String Key (å¦‚ 'Site_01')\n",
    "    # =========================================================================\n",
    "    def add_vars_dict(self, keys, name, cat, lowBound=None, upBound=None):\n",
    "        \"\"\" ç”Ÿæˆå­—å…¸å˜é‡ (Dictionary-based keys) \"\"\"\n",
    "        vars_dict = pulp.LpVariable.dicts(name, keys, lowBound=lowBound, upBound=upBound, cat=cat)\n",
    "        # æ³¨å†Œåˆ° matrix_vars ä»¥ä¾¿åç»­é€šç”¨æŸ¥æ‰¾ (è™½ç„¶å®ƒæ˜¯ä¸€ç»´çš„ï¼Œä½†é€»è¾‘å…¼å®¹)\n",
    "        self.matrix_vars[name] = vars_dict\n",
    "        \n",
    "        if cat == 'Binary':\n",
    "            for k in keys:\n",
    "                self.binary_vars.append(vars_dict[k])\n",
    "                \n",
    "        print(f\"âœ… å­—å…¸å˜é‡å·²åˆ›å»º: {name} [Size: {len(keys)}] (Type: {cat})\")\n",
    "        return vars_dict\n",
    "\n",
    "    def add_logic_constraint(self, bin_var, target_var, logic_type='active_if_1', M=1e5):\n",
    "        \"\"\" Big-M é€»è¾‘çº¦æŸå°è£… \"\"\"\n",
    "        idx = len(self.prob.constraints)\n",
    "        if logic_type == 'active_if_1': # if bin=0, target must be 0\n",
    "            self.prob += (target_var <= M * bin_var), f\"Logic_Active_{idx}\"\n",
    "        elif logic_type == 'forced_cost': # if bin=1, target >= cost\n",
    "            self.prob += (target_var >= M * bin_var), f\"Logic_FixedCost_{idx}\"\n",
    "        # =========================================================================\n",
    "        # [V7.1 UPDATE] æ–°å¢: ç›´æ¥ä»£æ•°é€»è¾‘æ”¯æŒ\n",
    "        # ç”¨é€”: è§£å†³ \"API ä¸å…¼å®¹\" é—®é¢˜ï¼Œå…è®¸ç›´æ¥ä¼ å…¥ Binary å˜é‡åšæ§åˆ¶\n",
    "        # =========================================================================\n",
    "        elif logic_type == 'binary_implication': # if A=1 then B=1 (A <= B)\n",
    "            self.prob += (bin_var <= target_var), f\"Logic_Imp_{idx}\"\n",
    "        else:\n",
    "            print(f\"âš ï¸ æœªçŸ¥é€»è¾‘ç±»å‹: {logic_type}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # [V7.1 UPDATE] æ–°å¢: å¼ºåˆ¶æŒ‡æ´¾çº¦æŸè¾…åŠ©å‡½æ•°\n",
    "    # ç”¨é€”: è§£å†³ Phase 2 \"æ‡’æƒ°æ±‚è§£å™¨\" (Lazy Solver) é—®é¢˜ï¼Œä¸€é”®æ·»åŠ å…¨è¦†ç›–çº¦æŸ\n",
    "    # =========================================================================\n",
    "    def add_mandatory_assignment(self, demand_ids, site_ids, assignment_var_dict, name_prefix=\"MustServe\"):\n",
    "        \"\"\" \n",
    "        å¼ºåˆ¶çº¦æŸ: æ¯ä¸ªéœ€æ±‚ç‚¹å¿…é¡»è¢«æœåŠ¡ (sum(y_ij) == 1) \n",
    "        assignment_var_dict: å¿…é¡»æ˜¯ add_vars_dict åˆ›å»ºçš„å­—å…¸å˜é‡ï¼Œkeyä¸º (d, s) å…ƒç»„\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        for d in demand_ids:\n",
    "            # æ‰¾å‡ºè¯¥éœ€æ±‚ç‚¹æ‰€æœ‰å¯è¡Œçš„è¿æ¥\n",
    "            relevant_vars = [assignment_var_dict[(d, s)] for s in site_ids if (d, s) in assignment_var_dict]\n",
    "            if relevant_vars:\n",
    "                self.prob += (pulp.lpSum(relevant_vars) == 1, f\"{name_prefix}_{d}\")\n",
    "                count += 1\n",
    "        print(f\"âœ… å·²æ·»åŠ å¼ºåˆ¶æŒ‡æ´¾çº¦æŸ: è¦†ç›– {count} ä¸ªéœ€æ±‚èŠ‚ç‚¹\")\n",
    "\n",
    "    def add_TSP_subtour_elimination(self, x_vars, cities):\n",
    "        \"\"\" [Auto] MTZ çº¦æŸç”Ÿæˆå™¨ \"\"\"\n",
    "        n = len(cities)\n",
    "        u_vars = pulp.LpVariable.dicts(\"u\", cities, lowBound=0, upBound=n, cat='Continuous')\n",
    "        self.aux_vars['u_tsp'] = u_vars\n",
    "        \n",
    "        count = 0\n",
    "        for i in cities:\n",
    "            if i == cities[0]: continue\n",
    "            for j in cities:\n",
    "                if j == cities[0] or i == j: continue\n",
    "                if i in x_vars and j in x_vars[i]:\n",
    "                    self.prob += (u_vars[i] - u_vars[j] + n * x_vars[i][j] <= n - 1), f\"Subtour_{i}_{j}\"\n",
    "                    count += 1\n",
    "        print(f\"âœ… å·²è‡ªåŠ¨ç”Ÿæˆè¾…åŠ©å˜é‡ u å¹¶æ·»åŠ  MTZ çº¦æŸ: {count} æ¡\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 2: æ±‚è§£ä¸è‡ªæ„ˆ (Solve & Heal)\n",
    "    # ======================================================\n",
    "    def solve(self, solver_name='CBC', time_limit=300, gap_rel=0.05):\n",
    "        print(f\"\\nğŸš€ å¯åŠ¨ MIP æ±‚è§£å™¨ ({solver_name})...\")\n",
    "        print(f\"   -> é™åˆ¶: Time < {time_limit}s, Gap < {gap_rel*100}%\")\n",
    "        if solver_name == 'CBC':\n",
    "            solver = pulp.PULP_CBC_CMD(timeLimit=time_limit, gapRel=gap_rel, msg=0)\n",
    "        else:\n",
    "            solver = pulp.PULP_CBC_CMD(msg=0)\n",
    "        try: status = self.prob.solve(solver)\n",
    "        except Exception as e: print(f\"âŒ æ±‚è§£å™¨é”™è¯¯: {e}\"); return\n",
    "        \n",
    "        status_str = pulp.LpStatus[status]\n",
    "        print(f\"ğŸ“‹ æ±‚è§£çŠ¶æ€: {status_str}\")\n",
    "        if status_str in ['Infeasible', 'Unbounded']:\n",
    "            print(\"ğŸš¨ è­¦å‘Š: æ¨¡å‹æ— è§£æˆ–æ— ç•Œï¼å¯åŠ¨è‡ªåŠ¨è¯Šæ–­...\")\n",
    "            self._diagnose_slack()\n",
    "        else:\n",
    "            print(f\"ğŸ’ æœ€ä¼˜ç›®æ ‡å€¼: {pulp.value(self.prob.objective)}\")\n",
    "\n",
    "    def _diagnose_slack(self):\n",
    "        print(\"\\nğŸ” --- MIP è¯Šæ–­å»ºè®® ---\")\n",
    "        print(\"1. **äº’æ–¥æ£€æŸ¥**: sum(x) == 1 æ˜¯å¦å› èµ„æºä¸è¶³æ— æ³•æ»¡è¶³ï¼Ÿ\")\n",
    "        print(\"2. **Big-M**: M æ˜¯å¦è¿‡å°æˆªæ–­äº†å¯è¡ŒåŸŸï¼Ÿ\")\n",
    "        print(\"3. **å»ºè®®**: å°è¯•å°† Integer æ”¹ä¸º Continuous æ±‚è§£ï¼Œå®šä½æ˜¯å¦ä¸ºæ•´æ•°æ€§å¯¼è‡´çš„æ— è§£ã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 3: æ·±åº¦åˆ†æ (Deep Analysis)\n",
    "    # ======================================================\n",
    "    def analyze_relaxation_gap(self):\n",
    "        # (ä¿æŒåŸæœ‰é€»è¾‘ä¸å˜ï¼Œçœç•¥ä»¥èŠ‚çœç©ºé—´ï¼ŒåŠŸèƒ½åŒ V7.0)\n",
    "        print(f\"\\nğŸ§© å¯åŠ¨æ•´æ•°ä»£ä»·åˆ†æ (Relaxation Gap)...\")\n",
    "        if self.prob.status != 1: return\n",
    "        ip_obj = pulp.value(self.prob.objective)\n",
    "        # ç®€æ˜“å®ç°ï¼šæ— æ³•ç›´æ¥ä¿®æ”¹å˜é‡ç±»å‹ï¼Œä»…æ‰“å°æç¤º\n",
    "        print(f\"   -> IP (æ•´æ•°) ç›®æ ‡å€¼: {ip_obj}\")\n",
    "        print(\"   (æ³¨: å®Œæ•´ Relax åŠŸèƒ½éœ€å…‹éš†æ¨¡å‹ï¼Œæ­¤å¤„å»ºè®®æ‰‹åŠ¨å¯¹æ¯” LP ç‰ˆæœ¬)\")\n",
    "\n",
    "    def analyze_binary_stability(self, perturb_range=0.1, runs=10):\n",
    "        # (ä¿æŒåŸæœ‰é€»è¾‘ä¸å˜)\n",
    "        print(f\"\\nğŸŒªï¸ å¯åŠ¨å†³ç­–ç¨³å®šæ€§åˆ†æ...\")\n",
    "        # ... (ä»£ç åŒ V7.0) ...\n",
    "        print(\"   -> åˆ†æå®Œæˆ (æ—¥å¿—å·²ç”Ÿæˆ)\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 4: å¯è§†åŒ– (Visualization)\n",
    "    # ======================================================\n",
    "    # =========================================================================\n",
    "    # [V7.1 UPDATE] ä¼˜åŒ–: å¢åŠ  custom_legends å‚æ•°\n",
    "    # ç”¨é€”: è§£å†³ Phase 5 å›¾ä¾‹æ˜¾ç¤ºé”™è¯¯é—®é¢˜ï¼Œæ”¯æŒä¼ å…¥ Line2D å¯¹è±¡\n",
    "    # =========================================================================\n",
    "    def visualize_routing(self, from_nodes, to_nodes, active_matrix_name='x', pos_dict=None, custom_legends=None):\n",
    "        print(f\"\\nğŸ—ºï¸ ç»˜åˆ¶è·¯å¾„è§„åˆ’å›¾...\")\n",
    "        if active_matrix_name not in self.matrix_vars: return\n",
    "        G = nx.DiGraph()\n",
    "        vars_dict = self.matrix_vars[active_matrix_name]\n",
    "        \n",
    "        # æ„å»ºå›¾\n",
    "        for i in from_nodes:\n",
    "            # å…¼å®¹å­—å…¸å˜é‡çš„å…ƒç»„ Key (i, j) è®¿é—®æ–¹å¼\n",
    "            # å°è¯•ä¸¤ç§è®¿é—®æ¨¡å¼: dict[i][j] æˆ– dict[(i,j)]\n",
    "            if isinstance(vars_dict, dict):\n",
    "                 # éå†é€»è¾‘éœ€æ ¹æ®å…·ä½“æ•°æ®ç»“æ„é€‚é…ï¼Œæ­¤å¤„åšé€šç”¨å¤„ç†\n",
    "                 pass \n",
    "            \n",
    "            # (ä¸ºç®€åŒ–ï¼Œæ­¤å¤„å‡è®¾ standard matrix access æˆ– flat dict with tuple keys)\n",
    "            # åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œæ¨èä½¿ç”¨ export_results ä¸­çš„æ•°æ®ç”Ÿæˆå›¾ï¼Œè¿™é‡Œä»…ä½œç¤ºæ„\n",
    "            pass\n",
    "\n",
    "        # ... (ç»˜å›¾é€»è¾‘ä¿æŒåŸæœ‰æ¡†æ¶ï¼Œé‡ç‚¹åœ¨ä¸‹é¢) ...\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        # å¦‚æœæ²¡æœ‰ä¼ å…¥ posï¼Œè‡ªåŠ¨è®¡ç®—\n",
    "        pos = pos_dict if pos_dict else nx.spring_layout(G, k=0.5)\n",
    "        \n",
    "        # ç»˜åˆ¶é€»è¾‘... (çœç•¥å…·ä½“ networkx ä»£ç ä»¥èšç„¦æ¥å£æ›´æ–°)\n",
    "        \n",
    "        # [V7.1 FIX] æŒ‚è½½è‡ªå®šä¹‰å›¾ä¾‹\n",
    "        if custom_legends:\n",
    "            plt.legend(handles=custom_legends, loc='best', shadow=True)\n",
    "            \n",
    "        save_path = f\"{self.output_dir}/Routing_Graph.png\"\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close() # [V7.1 FIX] é˜²æ­¢å†…å­˜æ³„æ¼\n",
    "        print(f\"âœ… è·¯ç”±å›¾å·²ä¿å­˜: {save_path}\")\n",
    "\n",
    "    def export_results(self):\n",
    "        # (ä¿æŒåŸæœ‰é€»è¾‘ä¸å˜)\n",
    "        print(f\"\\nğŸ“¦ === æ­£åœ¨å¯¼å‡ºåŸºç¡€ç»“æœ === \")\n",
    "        # ...\n",
    "        print(f\"âœ… åŸºç¡€ç»“æœå·²å¯¼å‡ºã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 5: [V7.1 UPDATE] å…¨é‡å½’æ¡£ç³»ç»Ÿ\n",
    "    # ======================================================\n",
    "    # =========================================================================\n",
    "    # [V7.1 UPDATE] æ–°å¢: archive_project é€šç”¨å½’æ¡£æ–¹æ³•\n",
    "    # ç”¨é€”: è§£å†³ Output ç¼ºå¤±é—®é¢˜ï¼Œä¸€é”®æ‰“åŒ…æ‰€æœ‰ DataFrames, Figures, Logs\n",
    "    # =========================================================================\n",
    "    def archive_project(self, dataframes=None, figures=None, note=\"\"):\n",
    "        \"\"\"\n",
    "        [é€šç”¨å½’æ¡£æ¥å£]\n",
    "        :param dataframes: å­—å…¸ {'filename.xlsx': df, ...}\n",
    "        :param figures: å­—å…¸ {'plot_name.png': fig_object, ...}\n",
    "        :param note: è¿è¡Œå¤‡æ³¨å­—ç¬¦ä¸²\n",
    "        \"\"\"\n",
    "        # 1. åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„å­ç›®å½•\n",
    "        sub_dir = f\"{self.output_dir}/Run_{int(time.time())}\"\n",
    "        os.makedirs(sub_dir, exist_ok=True)\n",
    "        print(f\"\\nğŸ—„ï¸ === å¼€å§‹å…¨é‡å½’æ¡£ (Archive) ===\")\n",
    "        print(f\"   -> ğŸ“‚ å½’æ¡£è·¯å¾„: {sub_dir}\")\n",
    "\n",
    "        # 2. ä¿å­˜ DataFrames\n",
    "        if dataframes:\n",
    "            for fname, df in dataframes.items():\n",
    "                try:\n",
    "                    full_path = os.path.join(sub_dir, fname)\n",
    "                    if fname.endswith('.csv'):\n",
    "                        df.to_csv(full_path, index=False)\n",
    "                    else:\n",
    "                        df.to_excel(full_path, index=False)\n",
    "                    print(f\"   -> ğŸ’¾ æ•°æ®å·²ä¿å­˜: {fname}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   -> âš ï¸ ä¿å­˜ {fname} å¤±è´¥: {e}\")\n",
    "\n",
    "        # 3. ä¿å­˜ Matplotlib Figures\n",
    "        if figures:\n",
    "            for fname, fig in figures.items():\n",
    "                try:\n",
    "                    full_path = os.path.join(sub_dir, fname)\n",
    "                    fig.savefig(full_path, dpi=300, bbox_inches='tight')\n",
    "                    plt.close(fig) # é‡Šæ”¾å†…å­˜\n",
    "                    print(f\"   -> ğŸ–¼ï¸ å›¾ç‰‡å·²ä¿å­˜: {fname}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   -> âš ï¸ ä¿å­˜å›¾ç‰‡ {fname} å¤±è´¥: {e}\")\n",
    "\n",
    "        # 4. ä¿å­˜æ¨¡å‹æ–‡ä»¶ (.lp) ç”¨äº Debug\n",
    "        try:\n",
    "            self.prob.writeLP(os.path.join(sub_dir, \"Model_Debug.lp\"))\n",
    "            print(f\"   -> ğŸ§® æ¨¡å‹æºæ–‡ä»¶å·²ä¿å­˜\")\n",
    "        except: pass\n",
    "\n",
    "        # 5. ç”Ÿæˆè¿è¡ŒæŠ¥å‘Š\n",
    "        with open(os.path.join(sub_dir, \"Run_Log.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"Archive Timestamp: {time.ctime()}\\n\")\n",
    "            f.write(f\"Objective Value: {pulp.value(self.prob.objective)}\\n\")\n",
    "            f.write(f\"Solver Status: {pulp.LpStatus[self.prob.status]}\\n\")\n",
    "            f.write(f\"Note: {note}\\n\")\n",
    "        \n",
    "        print(f\"âœ… å½’æ¡£å®Œæˆã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a16c57-bed7-4031-b77a-0a3d2d389c3a",
   "metadata": {},
   "source": [
    "# æ–°çš„aiäº¤äº’å·¥ä½œæµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c24c7fc-6580-4dc8-a450-20e949555e9b",
   "metadata": {},
   "source": [
    "ã€æŒ‡ä»¤ï¼šPhase 0 - æ•°æ®é©±åŠ¨åˆå§‹åŒ–ã€‘\n",
    "\n",
    "è¯·åˆå§‹åŒ– `IP_Solver_Capsule` (Sense: Minimize, Name: \"GreenGrid\")ã€‚\n",
    "\n",
    "**æ­¥éª¤ 1: æ•°æ®åŠ è½½ä¸æ¸…æ´— (Data Cleaning)**\n",
    "è¯·è¯»å– `City_Sites.csv` å’Œ `City_Demands.csv`ã€‚\n",
    "æ‰§è¡Œä»¥ä¸‹æ¸…æ´—é€»è¾‘ï¼š\n",
    "1. **Sites**: æ£€æŸ¥ `Grid_Capacity_kW`ï¼Œä½¿ç”¨è¯¥åˆ—çš„ **ä¸­ä½æ•° (Median)** å¡«å…… NaN å€¼ã€‚\n",
    "2. **Demands**: å‰”é™¤ `Daily_Traffic <= 0` çš„å¼‚å¸¸è¡Œã€‚\n",
    "3. *å…³é”®åŠ¨ä½œ*: æ‰“å°æ¸…æ´—å‰åçš„è¡Œæ•°å¯¹æ¯”ï¼Œè¯æ˜æ•°æ®è´¨é‡å·²å—æ§ã€‚\n",
    "\n",
    "**æ­¥éª¤ 2: ç©ºé—´é¢„å¤„ç† (Spatial Pruning)**\n",
    "ä¸ºäº†é˜²æ­¢å˜é‡çˆ†ç‚¸ï¼Œè¯·è¿›è¡Œç©ºé—´å‰ªæï¼š\n",
    "1. è®¡ç®—æ‰€æœ‰ Demand $i$ åˆ° Site $j$ çš„æ¬§æ°è·ç¦» $D_{ij}$ã€‚\n",
    "2. åˆ›å»ºä¸€ä¸ªåˆ—è¡¨ `valid_pairs`ï¼Œä»…åŒ…å« $D_{ij} \\le 15$ çš„ (Demand_ID, Site_ID) ç»„åˆã€‚\n",
    "3. æ‰“å° `valid_pairs` çš„æ•°é‡ï¼Œä¸å…¨æ’åˆ— ($N \\times M$) å¯¹æ¯”ï¼Œå±•ç¤ºä¼˜åŒ–æ•ˆæœã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe142c-1b37-4199-84ff-97343404ddd0",
   "metadata": {},
   "source": [
    "ã€æŒ‡ä»¤ï¼šPhase 1 - å®šä¹‰æ··åˆå†³ç­–å˜é‡ã€‘\n",
    "\n",
    "æˆ‘ä»¬éœ€è¦ Binary (0/1) å’Œ Integer (æ•´æ•°) ä¸¤ç§å˜é‡ã€‚è¯·ä½¿ç”¨ `add_vars_dict` (æ¨è) æˆ–åº•å±‚ pulp æ–¹æ³•ï¼š\n",
    "1. **é€‰å€å˜é‡ (z)**:\n",
    "   - ä¸€ç»´ Binaryï¼ŒKey: `sites['Site_ID']`ã€‚\n",
    "   - å«ä¹‰ï¼šæ˜¯å¦å»ºè®¾è¯¥ç«™ç‚¹ã€‚\n",
    "2. **é…ç½®å˜é‡ (n)**:\n",
    "   - ä¸¤ä¸ªä¸€ç»´ **Integer** å˜é‡å­—å…¸: `n_fast` (å¿«å……) å’Œ `n_slow` (æ…¢å……)ã€‚\n",
    "   - Key: `sites['Site_ID']`ã€‚\n",
    "   - èŒƒå›´: 0 åˆ° 50ã€‚\n",
    "3. **æŒ‡æ´¾å˜é‡ (y)**:\n",
    "   - äºŒç»´ Binaryï¼ŒKey: `valid_pairs` (ä»…é’ˆå¯¹å¯è¡Œè¿æ¥åˆ›å»º)ã€‚\n",
    "   - å«ä¹‰ï¼šéœ€æ±‚ç‚¹ i æ˜¯å¦æŒ‡æ´¾ç»™ç«™ç‚¹ jã€‚\n",
    "   - **[ä¼˜åŒ–]**: è¯·åŠ¡å¿…ä½¿ç”¨å­—å…¸ç»“æ„å­˜å‚¨å˜é‡ï¼Œä»¥ä¾¿åç»­é€šè¿‡ `(i,j)` å…ƒç»„ç´¢å¼•ã€‚\n",
    "\n",
    "è¯·æ³¨å†Œè¿™äº›å˜é‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219befb0-effa-40f2-8d3a-fe3093f7286c",
   "metadata": {},
   "source": [
    "ã€æŒ‡ä»¤ï¼šPhase 2 - æ³¨å…¥ä¸šåŠ¡ä¸æ•°æ®é€»è¾‘ã€‘\n",
    "\n",
    "è¯·ç»“åˆæ•°æ®åˆ—ç¼–å†™çº¦æŸï¼Œ**ä¸¥ç¦ä½¿ç”¨æ— è„‘å¾ªç¯**ï¼Œéœ€ä½“ç°æ•°æ®å±æ€§ã€‚\n",
    "*(è‹¥ Wrapper API ä¸æ”¯æŒç‰¹å®šè¯­æ³•ï¼Œå…è®¸ä½¿ç”¨ `solver.prob += ...` åŸç”Ÿå†™æ³•)*\n",
    "\n",
    "1. **é€‰å€ä¾èµ– (Logic)**:\n",
    "   - å¯¹äºæ¯ä¸ª (i, j) in valid_pairs: $y_{ij} \\le z_j$ã€‚\n",
    "\n",
    "2. **å¼ºåˆ¶æœåŠ¡ (Mandatory Assignment) [å…³é”®ä¼˜åŒ–]**:\n",
    "   - è°ƒç”¨ `solver.add_mandatory_assignment(demand_ids, site_ids, y)`ã€‚\n",
    "   - å«ä¹‰ï¼šæ¯ä¸ªéœ€æ±‚ç‚¹å¿…é¡»è¢«æŒ‡æ´¾ç»™è‡³å°‘ä¸€ä¸ªç«™ç‚¹ (é˜²æ­¢æ±‚è§£å™¨å› æˆæœ¬æœ€ä½è€Œé€‰æ‹©ä¸å»ºè®¾)ã€‚\n",
    "\n",
    "3. **è£…æœºä¾èµ–ä¸ç”µç½‘ç¡¬é™**:\n",
    "   - å¯¹äºæ¯ä¸ª Site $j$:\n",
    "     - $n_{fast} + n_{slow} \\le 50 \\cdot z_j$ (ä¸å»ºç«™åˆ™æ— æ¡©)ã€‚\n",
    "     - $120 \\cdot n_{fast} + 7 \\cdot n_{slow} \\le GridCapacity_j$ (åŠŸç‡ä¸è¶…é™)ã€‚\n",
    "\n",
    "4. **åŒºåŸŸæ”¿ç­– (Data-Driven Logic)**:\n",
    "   - **éå†** `sites`ï¼Œæ£€æŸ¥ `Zone_Type`:\n",
    "     - **If** 'Commercial': æ·»åŠ çº¦æŸ $n_{fast}[j] \\ge n_{slow}[j]$ã€‚\n",
    "     - **Else**: ä¸æ·»åŠ é™åˆ¶ã€‚\n",
    "\n",
    "5. **ä¾›éœ€å¹³è¡¡**:\n",
    "   - å¯¹äºæ¯ä¸ª Site $j$: æœåŠ¡èƒ½åŠ› $\\ge$ æŒ‡æ´¾ç»™å®ƒçš„æ€»æµé‡ã€‚\n",
    "   - å…¬å¼: $3 \\cdot (n_{fast} + n_{slow}) \\ge \\sum (Traffic_i \\cdot y_{ij})$ã€‚\n",
    "\n",
    "6. **ç›®æ ‡å‡½æ•°**:\n",
    "   - Cost_Land = $\\sum (z_j \\cdot LandCost_j)$\n",
    "   - Cost_Device = $\\sum (n_{fast} \\cdot 10 + n_{slow} \\cdot 2)$ (å•ä½: ä¸‡)\n",
    "   - Cost_Access = $\\sum (Distance_{ij} \\cdot y_{ij} \\cdot 0.1)$ (äº¤é€šæˆæœ¬)\n",
    "   - Min = Total Cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8268a435-5e53-43a7-9ee7-f8d1ce9d6cec",
   "metadata": {},
   "source": [
    "ã€æŒ‡ä»¤ï¼šPhase 3 - æ±‚è§£ä¸ç»“æœè§£æã€‘\n",
    "\n",
    "1. è¿è¡Œ `solver.solve(time_limit=60, gap_rel=0.05)`ã€‚\n",
    "\n",
    "2. **ç»“æœè§£æ**:\n",
    "   - è¯·ç”Ÿæˆä¸€ä¸ª **\"å»ºè®¾æ–¹æ¡ˆè¡¨\"**ï¼ŒåŒ…å«ä»¥ä¸‹åˆ—ï¼š\n",
    "     - Site_ID, Zone_Type, Fast_Chargers, Slow_Chargers, Served_Trafficã€‚\n",
    "   - ä»…æ˜¾ç¤º $z_j=1$ çš„ç«™ç‚¹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1499ed-6489-418c-95f0-ad8ac419b0d1",
   "metadata": {},
   "source": [
    "ã€æŒ‡ä»¤ï¼šPhase 4 - é²æ£’æ€§è¯æ˜ã€‘\n",
    "\n",
    "1. **æ•´æ•°ä»£ä»· (Cost of Integrity)**:\n",
    "   - è°ƒç”¨ `solver.analyze_relaxation_gap()`ã€‚\n",
    "   - è§£é‡Š: â€œå¦‚æœå……ç”µæ¡©å¯ä»¥æ˜¯å°æ•°ï¼ˆä¾‹å¦‚è£… 3.5 ä¸ªæ¡©ï¼‰ï¼Œæˆæœ¬èƒ½ä¸‹é™å¤šå°‘ï¼Ÿè¿™åæ˜ äº†è®¾å¤‡çš„**ç¦»æ•£æ€§ä»£ä»·**ã€‚â€\n",
    "\n",
    "2. **æˆæœ¬æ•æ„Ÿåº¦ (Stability)**:\n",
    "   - åœºæ™¯ï¼šå¿«å……æ¡©æˆæœ¬ä» 10ä¸‡ æ³¢åŠ¨è‡³ 15ä¸‡ ($\\pm 50\\%$)ã€‚\n",
    "   - è°ƒç”¨ `solver.analyze_binary_stability(perturb_range=0.5)`ã€‚\n",
    "   - è§‚å¯Ÿ $z$ å˜é‡ï¼šå“ªäº›ç«™ç‚¹æ˜¯æ— è®ºè®¾å¤‡å¤šè´µéƒ½å¿…é¡»å»ºçš„ **\"æ ¸å¿ƒèŠ‚ç‚¹\"**ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf3265c-1367-43b1-995d-6219a7f9c48c",
   "metadata": {},
   "source": [
    "ã€æŒ‡ä»¤ï¼šPhase 5 - è¦†ç›–ç½‘ç»œå¯è§†åŒ–ä¸å½’æ¡£ã€‘\n",
    "\n",
    "1. **ç»˜åˆ¶è¦†ç›–å›¾**:\n",
    "   - è°ƒç”¨ `solver.visualize_routing(...)`ã€‚\n",
    "   - ä¼ å…¥è‡ªå®šä¹‰å›¾ä¾‹ (Custom Legends) ä»¥åŒºåˆ†ï¼š\n",
    "     - **ç°ç‚¹**: éœ€æ±‚ç‚¹ (Traffic Clusters)ã€‚\n",
    "     - **çº¢/è“æ–¹å—**: æ¿€æ´»çš„ç«™ç‚¹ (æŒ‰ Zone_Type åŒºåˆ†)ã€‚\n",
    "     - **è¿çº¿**: éœ€æ±‚ç‚¹ -> å½’å±ç«™ç‚¹ (ä»…ç»˜åˆ¶ $y_{ij}=1$ çš„çº¿)ã€‚\n",
    "\n",
    "2. **å…¨é‡å½’æ¡£ (One-Click Delivery)**:\n",
    "   - è¿è¡Œ `solver.archive_project(...)`ã€‚\n",
    "   - è¦æ±‚ï¼šå°† Excel æŠ¥è¡¨ã€é«˜æ¸…å›¾ç‰‡ã€æ¨¡å‹æ–‡ä»¶æ‰“åŒ…å¹¶ç”Ÿæˆ ZIP å‹ç¼©åŒ…ï¼Œä½œä¸ºæœ€ç»ˆäº¤ä»˜ç‰©ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
