{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2823ab9-e66d-4932-a83b-05d48d7d1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pulp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "import copy\n",
    "\n",
    "# --- V7.0 ç»˜å›¾ç¾å­¦é…ç½® ---\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'SimHei'] \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "try:\n",
    "    import scienceplots\n",
    "    plt.style.use(['science', 'no-latex'])\n",
    "except ImportError:\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"deep\", context=\"paper\")\n",
    "\n",
    "class IP_Solver_Capsule:\n",
    "    def __init__(self, name=\"MIP_Model\", sense='max'):\n",
    "        \"\"\"\n",
    "        [MCM IP Solver V7.0 - Final Patched]\n",
    "        Core: Integer Programming (IP) & Mixed Integer Programming (MIP)\n",
    "        Features: Big-M Logic, Auto-TSP Support, Relaxation Gap, Stability Test, Gephi Export\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.timestamp = int(time.time())\n",
    "        self.sense = pulp.LpMaximize if sense.lower() == 'max' else pulp.LpMinimize\n",
    "        \n",
    "        self.prob = pulp.LpProblem(self.name, self.sense)\n",
    "        \n",
    "        self.matrix_vars = {}   \n",
    "        self.single_vars = {}   \n",
    "        self.binary_vars = []   \n",
    "        self.aux_vars = {}      # å­˜å‚¨è¾…åŠ©å˜é‡ (å¦‚ TSP çš„ u_i)\n",
    "        \n",
    "        self.output_dir = f\"./Results_{name}_{self.timestamp}\"\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 0: æ¡æ‰‹ (Handshake)\n",
    "    # ======================================================\n",
    "    def generate_handshake(self):\n",
    "        print(f\"\\nğŸ¤ === å¤åˆ¶ä»¥ä¸‹ Prompt å‘é€ç»™ AI (V7.0 IP) ===\\n\")\n",
    "        print(f\"ã€ç³»ç»Ÿè®¾å®šã€‘\\næˆ‘æ­£åœ¨ä½¿ç”¨ `IP_Solver_Capsule` (V7.0)ã€‚\")\n",
    "        print(f\"ç›®æ ‡: {'Maximize' if self.sense == -1 else 'Minimize'} | è¾“å‡º: `{self.output_dir}`\")\n",
    "        print(\"\\nã€API æ¥å£æ¸…å•ã€‘\")\n",
    "        print(\"1. çŸ©é˜µå˜é‡: solver.add_var_matrix(rows, cols, name='x', cat='Binary')\")\n",
    "        print(\"2. é€»è¾‘çº¦æŸ: solver.add_logic_constraint(bin_var, cont_var, logic_type='active_if_1')\")\n",
    "        print(\"3. TSPå›è·¯: solver.add_TSP_subtour_elimination(x_vars, cities) # è‡ªåŠ¨åˆ›å»ºè¾…åŠ©å˜é‡\")\n",
    "        print(\"4. æ±‚è§£è‡ªæ„ˆ: solver.solve(time_limit=300, gap_rel=0.05)\")\n",
    "        print(\"5. [MIPæ ¸æ­¦å™¨] æ•´æ•°ä»£ä»·: solver.analyze_relaxation_gap()\")\n",
    "        print(\"6. [MIPæ ¸æ­¦å™¨] å†³ç­–ç¨³å®šæ€§: solver.analyze_binary_stability()\")\n",
    "        print(\"7. [å¯è§†åŒ–] åœºæ™¯å›¾: visualize_routing / visualize_schedule / visualize_matrix\")\n",
    "        print(\"8. [å¯è§†åŒ–] Gephiå¯¼å‡º: solver.export_routing_gephi(matrix_name='x')\")\n",
    "        print(\"9. [äº¤ä»˜] å¯¼å‡º: solver.export_results()\")\n",
    "        print(\"\\nã€âš ï¸ æ•´æ•°è§„åˆ’æ•°å­¦é™·é˜±ã€‘\")\n",
    "        print(\"1. **æ— å½±å­ä»·æ ¼**: MIP æ— å¯¹å¶è§£ã€‚è¯·å‹¿å°è¯•è·å– Sensitivityã€‚\")\n",
    "        print(\"2. **Big-M**: é€»è¾‘çº¦æŸä¸­ M è‹¥è¿‡å¤§å¯èƒ½å¯¼è‡´æ•°å€¼ä¸ç¨³å®šã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 1: å»ºæ¨¡å·¥å‚ (Modeling Factory)\n",
    "    # ======================================================\n",
    "    def add_var_matrix(self, rows, cols, name=\"x\", cat='Binary'):\n",
    "        \"\"\" ç”ŸæˆäºŒç»´å˜é‡çŸ©é˜µå¹¶è¿½è¸ª Binary å˜é‡ \"\"\"\n",
    "        vars_dict = pulp.LpVariable.dicts(name, (rows, cols), 0, 1 if cat=='Binary' else None, cat)\n",
    "        self.matrix_vars[name] = vars_dict\n",
    "        if cat == 'Binary':\n",
    "            for r in rows:\n",
    "                for c in cols:\n",
    "                    self.binary_vars.append(vars_dict[r][c])\n",
    "        print(f\"âœ… çŸ©é˜µå˜é‡å·²åˆ›å»º: {name}[{len(rows)}x{len(cols)}] (Type: {cat})\")\n",
    "        return vars_dict\n",
    "\n",
    "    def add_logic_constraint(self, bin_var, target_var, logic_type='active_if_1', M=1e5):\n",
    "        \"\"\" Big-M é€»è¾‘çº¦æŸå°è£… \"\"\"\n",
    "        idx = len(self.prob.constraints)\n",
    "        if logic_type == 'active_if_1':\n",
    "            self.prob += (target_var <= M * bin_var), f\"Logic_Active_{idx}\"\n",
    "        elif logic_type == 'forced_cost':\n",
    "            self.prob += (target_var >= M * bin_var), f\"Logic_FixedCost_{idx}\"\n",
    "        else:\n",
    "            print(f\"âš ï¸ æœªçŸ¥é€»è¾‘ç±»å‹: {logic_type}\")\n",
    "\n",
    "    def add_TSP_subtour_elimination(self, x_vars, cities):\n",
    "        \"\"\" [Auto] MTZ çº¦æŸç”Ÿæˆå™¨: è‡ªåŠ¨åˆ›å»ºè¾…åŠ©å˜é‡ u_i \"\"\"\n",
    "        n = len(cities)\n",
    "        u_vars = pulp.LpVariable.dicts(\"u\", cities, lowBound=0, upBound=n, cat='Continuous')\n",
    "        self.aux_vars['u_tsp'] = u_vars\n",
    "        \n",
    "        count = 0\n",
    "        for i in cities:\n",
    "            if i == cities[0]: continue\n",
    "            for j in cities:\n",
    "                if j == cities[0] or i == j: continue\n",
    "                # MTZ Constraint: u_i - u_j + n*x_ij <= n-1\n",
    "                if i in x_vars and j in x_vars[i]:\n",
    "                    self.prob += (u_vars[i] - u_vars[j] + n * x_vars[i][j] <= n - 1), f\"Subtour_{i}_{j}\"\n",
    "                    count += 1\n",
    "        print(f\"âœ… å·²è‡ªåŠ¨ç”Ÿæˆè¾…åŠ©å˜é‡ u å¹¶æ·»åŠ  MTZ çº¦æŸ: {count} æ¡\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 2: æ±‚è§£ä¸è‡ªæ„ˆ (Solve & Heal)\n",
    "    # ======================================================\n",
    "    def solve(self, solver_name='CBC', time_limit=300, gap_rel=0.05):\n",
    "        print(f\"\\nğŸš€ å¯åŠ¨ MIP æ±‚è§£å™¨ ({solver_name})...\")\n",
    "        print(f\"   -> é™åˆ¶: Time < {time_limit}s, Gap < {gap_rel*100}%\")\n",
    "        if solver_name == 'CBC':\n",
    "            solver = pulp.PULP_CBC_CMD(timeLimit=time_limit, gapRel=gap_rel, msg=0)\n",
    "        else:\n",
    "            solver = pulp.PULP_CBC_CMD(msg=0)\n",
    "        try: status = self.prob.solve(solver)\n",
    "        except Exception as e: print(f\"âŒ æ±‚è§£å™¨é”™è¯¯: {e}\"); return\n",
    "        \n",
    "        status_str = pulp.LpStatus[status]\n",
    "        print(f\"ğŸ“‹ æ±‚è§£çŠ¶æ€: {status_str}\")\n",
    "        if status_str in ['Infeasible', 'Unbounded']:\n",
    "            print(\"ğŸš¨ è­¦å‘Š: æ¨¡å‹æ— è§£æˆ–æ— ç•Œï¼å¯åŠ¨è‡ªåŠ¨è¯Šæ–­...\")\n",
    "            self._diagnose_slack()\n",
    "        else:\n",
    "            print(f\"ğŸ’ æœ€ä¼˜ç›®æ ‡å€¼: {pulp.value(self.prob.objective)}\")\n",
    "            try:\n",
    "                with open(f\"{self.output_dir}/model_checkpoint.pkl\", 'wb') as f:\n",
    "                    pickle.dump(self.prob, f)\n",
    "            except: pass\n",
    "\n",
    "    def _diagnose_slack(self):\n",
    "        print(\"\\nğŸ” --- MIP è¯Šæ–­å»ºè®® ---\")\n",
    "        print(\"1. **äº’æ–¥æ£€æŸ¥**: sum(x) == 1 æ˜¯å¦å› èµ„æºä¸è¶³æ— æ³•æ»¡è¶³ï¼Ÿ\")\n",
    "        print(\"2. **Big-M**: M æ˜¯å¦è¿‡å°æˆªæ–­äº†å¯è¡ŒåŸŸï¼Ÿ\")\n",
    "        print(\"3. **å»ºè®®**: å°è¯•å°† Integer æ”¹ä¸º Continuous æ±‚è§£ï¼Œå®šä½æ˜¯å¦ä¸ºæ•´æ•°æ€§å¯¼è‡´çš„æ— è§£ã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 3: æ·±åº¦åˆ†æ (Deep Analysis)\n",
    "    # ======================================================\n",
    "    def analyze_relaxation_gap(self):\n",
    "        print(f\"\\nğŸ§© å¯åŠ¨æ•´æ•°ä»£ä»·åˆ†æ (Relaxation Gap)...\")\n",
    "        if self.prob.status != 1: return\n",
    "        ip_obj = pulp.value(self.prob.objective)\n",
    "        original_cats = {}\n",
    "        for v in self.prob.variables():\n",
    "            original_cats[v.name] = v.cat\n",
    "            v.cat = pulp.LpContinuous\n",
    "        self.prob.solve(pulp.PULP_CBC_CMD(msg=0))\n",
    "        lp_obj = pulp.value(self.prob.objective)\n",
    "        for v in self.prob.variables(): v.cat = original_cats[v.name]\n",
    "        self.prob.solve(pulp.PULP_CBC_CMD(msg=0)) # Restore\n",
    "        if lp_obj is None: return\n",
    "        gap = abs(ip_obj - lp_obj)\n",
    "        gap_percent = (gap / abs(ip_obj)) * 100 if ip_obj != 0 else 0\n",
    "        print(f\"   -> IP (æ•´æ•°) ç›®æ ‡å€¼: {ip_obj}\")\n",
    "        print(f\"   -> LP (æ¾å¼›) ç›®æ ‡å€¼: {lp_obj}\")\n",
    "        print(f\"   -> æ•´æ•°ä»£ä»· (Cost of Integrity): {gap:.4f} ({gap_percent:.2f}%)\")\n",
    "        print(\"   ğŸ’¡ è§£é‡Š: ä¸ºäº†æ»¡è¶³ç¦»æ•£çº¦æŸï¼Œæˆ‘ä»¬ç‰ºç‰²äº† {:.2f}% çš„ç†è®ºæœ€ä¼˜æ•ˆç›Šã€‚\".format(gap_percent))\n",
    "        with open(f\"{self.output_dir}/Gap_Analysis.txt\", \"w\") as f:\n",
    "            f.write(f\"IP_Obj: {ip_obj}\\nLP_Obj: {lp_obj}\\nGap: {gap_percent:.2f}%\\n\")\n",
    "\n",
    "    def analyze_binary_stability(self, perturb_range=0.1, runs=10):\n",
    "        print(f\"\\nğŸŒªï¸ å¯åŠ¨å†³ç­–ç¨³å®šæ€§åˆ†æ (Runs={runs}, Perturb=Â±{perturb_range:.0%})...\")\n",
    "        if not self.binary_vars: return\n",
    "        base_sol = {v.name: v.varValue for v in self.binary_vars}\n",
    "        flip_counts = {v.name: 0 for v in self.binary_vars}\n",
    "        original_objective = self.prob.objective\n",
    "        try: coeffs = original_objective.to_dict()\n",
    "        except: return\n",
    "        valid_runs = 0\n",
    "        for r in range(runs):\n",
    "            new_obj = 0\n",
    "            for v, c in coeffs.items():\n",
    "                new_obj += c * (1 + np.random.uniform(-perturb_range, perturb_range)) * v\n",
    "            self.prob.setObjective(new_obj)\n",
    "            self.prob.solve(pulp.PULP_CBC_CMD(msg=0))\n",
    "            if self.prob.status == 1:\n",
    "                valid_runs += 1\n",
    "                for v in self.binary_vars:\n",
    "                    if abs(v.varValue - base_sol[v.name]) > 0.5:\n",
    "                        flip_counts[v.name] += 1\n",
    "            print(\".\", end=\"\")\n",
    "        print(f\" å®Œæˆ! (Valid Runs: {valid_runs})\")\n",
    "        self.prob.setObjective(original_objective) \n",
    "        self.prob.solve(pulp.PULP_CBC_CMD(msg=0)) \n",
    "        flip_rates = [flip_counts[v.name]/valid_runs for v in self.binary_vars if valid_runs > 0]\n",
    "        df_flip = pd.DataFrame({'Variable': [v.name for v in self.binary_vars], 'Flip_Rate': flip_rates})\n",
    "        df_active = df_flip[df_flip['Flip_Rate'] > 0].sort_values('Flip_Rate', ascending=False).head(20)\n",
    "        if not df_active.empty:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.barplot(x='Flip_Rate', y='Variable', data=df_active, palette='Reds')\n",
    "            plt.title('Stability Analysis: Decision Flip Rate')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{self.output_dir}/Stability_Heatmap.svg\")\n",
    "            print(f\"âœ… ç¨³å®šæ€§çƒ­åŠ›å›¾å·²ä¿å­˜ã€‚\")\n",
    "        else:\n",
    "            print(\"âœ… å†³ç­–æå…¶ç¨³å¥ã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 4: å¯è§†åŒ–ä¸ Gephi (Visualization)\n",
    "    # ======================================================\n",
    "    def visualize_routing(self, from_nodes, to_nodes, active_matrix_name='x', pos_dict=None):\n",
    "        print(f\"\\nğŸ—ºï¸ ç»˜åˆ¶è·¯å¾„è§„åˆ’å›¾...\")\n",
    "        if active_matrix_name not in self.matrix_vars: return\n",
    "        G = nx.DiGraph()\n",
    "        vars_dict = self.matrix_vars[active_matrix_name]\n",
    "        edge_count = 0\n",
    "        G.add_nodes_from(set(list(from_nodes) + list(to_nodes)))\n",
    "        for i in from_nodes:\n",
    "            for j in to_nodes:\n",
    "                if i == j: continue\n",
    "                if i in vars_dict and j in vars_dict[i]:\n",
    "                    val = pulp.value(vars_dict[i][j])\n",
    "                    if val and val > 0.9: \n",
    "                        G.add_edge(i, j)\n",
    "                        edge_count += 1\n",
    "        if edge_count == 0: return\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        pos = pos_dict if pos_dict else nx.spring_layout(G, k=0.5, seed=42)\n",
    "        nx.draw_networkx(G, pos, node_size=500, node_color='skyblue', with_labels=True, arrowsize=20)\n",
    "        plt.title(f'Optimal Routing Plan ({edge_count} Segments)')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"{self.output_dir}/Routing_Graph.svg\")\n",
    "\n",
    "    def visualize_schedule(self, df_schedule):\n",
    "        \"\"\" ç”˜ç‰¹å›¾: ['Task', 'Start', 'End', 'Resource'] \"\"\"\n",
    "        print(f\"\\nğŸ“… ç»˜åˆ¶ç”˜ç‰¹å›¾...\")\n",
    "        if df_schedule.empty: return\n",
    "        df = df_schedule.copy()\n",
    "        df['Duration'] = df['End'] - df['Start']\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        resources = df['Resource'].unique()\n",
    "        colors = sns.color_palette(\"hls\", len(resources))\n",
    "        color_map = dict(zip(resources, colors))\n",
    "        \n",
    "        # å°† Task æ˜ å°„ä¸º Y è½´åæ ‡ï¼Œé˜²æ­¢ä¸­æ–‡/å­—ç¬¦ä¸²æŠ¥é”™\n",
    "        tasks = df['Task'].unique()\n",
    "        task_map = {t: i for i, t in enumerate(tasks)}\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            y_pos = task_map[row['Task']]\n",
    "            plt.barh(y=y_pos, width=row['Duration'], left=row['Start'], \n",
    "                     color=color_map[row['Resource']], alpha=0.8, edgecolor='black')\n",
    "            plt.text(row['Start'] + row['Duration']/2, y_pos, str(row['Resource']), \n",
    "                     ha='center', va='center', color='white', fontsize=8)\n",
    "            \n",
    "        plt.yticks(list(task_map.values()), list(task_map.keys()))\n",
    "        plt.xlabel(\"Time\"); plt.ylabel(\"Task\")\n",
    "        plt.title(\"Optimization Schedule\")\n",
    "        plt.grid(axis='x', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.output_dir}/Gantt_Chart.svg\")\n",
    "\n",
    "    def visualize_matrix(self, matrix_name):\n",
    "        print(f\"\\nâ–¦ ç»˜åˆ¶åˆ†é…çŸ©é˜µçƒ­åŠ›å›¾ ({matrix_name})...\")\n",
    "        if matrix_name not in self.matrix_vars: return\n",
    "        vars_dict = self.matrix_vars[matrix_name]\n",
    "        rows = list(vars_dict.keys())\n",
    "        cols = list(vars_dict[rows[0]].keys())\n",
    "        data = [[pulp.value(vars_dict[r][c]) for c in cols] for r in rows]\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(data, cmap=\"Blues\", xticklabels=cols, yticklabels=rows, linewidths=.5, cbar=False)\n",
    "        plt.title(f'Assignment Matrix: {matrix_name}')\n",
    "        plt.savefig(f\"{self.output_dir}/Matrix_Heatmap.svg\")\n",
    "\n",
    "    def export_routing_gephi(self, matrix_name='x'):\n",
    "        \"\"\" [New] Gephi è·¯ç”±å¯¼å‡ºåè®® \"\"\"\n",
    "        print(f\"\\nğŸ•¸ï¸ æ­£åœ¨å¯¼å‡ºè·¯ç”±ç½‘ç»œ Gephi æ•°æ® (Matrix: {matrix_name})...\")\n",
    "        if matrix_name not in self.matrix_vars: return\n",
    "        vars_dict = self.matrix_vars[matrix_name]\n",
    "        edges = []\n",
    "        for i in vars_dict:\n",
    "            for j in vars_dict[i]:\n",
    "                val = pulp.value(vars_dict[i][j])\n",
    "                if val and val > 0.9:\n",
    "                    edges.append({'Source': i, 'Target': j, 'Weight': 1, 'Type': 'Directed'})\n",
    "        if not edges: return\n",
    "        df_edges = pd.DataFrame(edges)\n",
    "        save_path = f\"{self.output_dir}/Routing_Flow_Gephi.csv\"\n",
    "        df_edges.to_csv(save_path, index=False)\n",
    "        print(f\"âœ… å·²å¯¼å‡º Gephi è¾¹è¡¨: {save_path} (å« {len(edges)} æ¡è·¯å¾„)\")\n",
    "\n",
    "    def export_results(self):\n",
    "        print(f\"\\nğŸ“¦ === æ­£åœ¨æ‰“åŒ…äº¤ä»˜ç‰©è‡³ {self.output_dir} === \")\n",
    "        data = []\n",
    "        for v in self.prob.variables():\n",
    "            val = v.varValue\n",
    "            if val and abs(val) > 1e-5:\n",
    "                data.append({'Variable': v.name, 'Value': val})\n",
    "        df_res = pd.DataFrame(data)\n",
    "        df_res.to_excel(f\"{self.output_dir}/Solution.xlsx\", index=False)\n",
    "        \n",
    "        obj_val = pulp.value(self.prob.objective)\n",
    "        status = pulp.LpStatus[self.prob.status]\n",
    "        report = f\"# IP Report: {self.name}\\n\\nStatus: {status}\\nObjective: {obj_val}\\n\"\n",
    "        report += \"## Analysis\\n- Check `Gap_Analysis.txt` for cost of integrity.\\n\"\n",
    "        report += \"- Check `Stability_Heatmap.svg` for decision robustness.\\n\"\n",
    "        if os.path.exists(f\"{self.output_dir}/Routing_Flow_Gephi.csv\"):\n",
    "            report += \"- Check `Routing_Flow_Gephi.csv` for network visualization.\\n\"\n",
    "        with open(f\"{self.output_dir}/Report.md\", \"w\", encoding='utf-8') as f: f.write(report)\n",
    "        \n",
    "        if not df_res.empty:\n",
    "            df_top = df_res.head(15)\n",
    "            tex = \"\\\\begin{tabular}{lr} Variable & Value \\\\\\\\ \\\\midrule\\n\"\n",
    "            for _, r in df_top.iterrows(): tex += f\"{r['Variable'].replace('_','\\\\_')} & {r['Value']} \\\\\\\\\\n\"\n",
    "            tex += \"\\\\end{tabular}\"\n",
    "            with open(f\"{self.output_dir}/Variables.tex\", \"w\") as f: f.write(tex)\n",
    "        print(f\"âœ… å…¨å¥—ç»“æœå·²å¯¼å‡º (Excel, Report, SVG, Gephi)ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6baf4685-e939-45dc-8245-d7d66b4bc5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¤ === å¤åˆ¶ä»¥ä¸‹ Prompt å‘é€ç»™ AI (V7.0 IP) ===\n",
      "\n",
      "ã€ç³»ç»Ÿè®¾å®šã€‘\n",
      "æˆ‘æ­£åœ¨ä½¿ç”¨ `IP_Solver_Capsule` (V7.0)ã€‚\n",
      "ç›®æ ‡: Minimize | è¾“å‡º: `./Results_GreenGrid_1765977725`\n",
      "\n",
      "ã€API æ¥å£æ¸…å•ã€‘\n",
      "1. çŸ©é˜µå˜é‡: solver.add_var_matrix(rows, cols, name='x', cat='Binary')\n",
      "2. é€»è¾‘çº¦æŸ: solver.add_logic_constraint(bin_var, cont_var, logic_type='active_if_1')\n",
      "3. TSPå›è·¯: solver.add_TSP_subtour_elimination(x_vars, cities) # è‡ªåŠ¨åˆ›å»ºè¾…åŠ©å˜é‡\n",
      "4. æ±‚è§£è‡ªæ„ˆ: solver.solve(time_limit=300, gap_rel=0.05)\n",
      "5. [MIPæ ¸æ­¦å™¨] æ•´æ•°ä»£ä»·: solver.analyze_relaxation_gap()\n",
      "6. [MIPæ ¸æ­¦å™¨] å†³ç­–ç¨³å®šæ€§: solver.analyze_binary_stability()\n",
      "7. [å¯è§†åŒ–] åœºæ™¯å›¾: visualize_routing / visualize_schedule / visualize_matrix\n",
      "8. [å¯è§†åŒ–] Gephiå¯¼å‡º: solver.export_routing_gephi(matrix_name='x')\n",
      "9. [äº¤ä»˜] å¯¼å‡º: solver.export_results()\n",
      "\n",
      "ã€âš ï¸ æ•´æ•°è§„åˆ’æ•°å­¦é™·é˜±ã€‘\n",
      "1. **æ— å½±å­ä»·æ ¼**: MIP æ— å¯¹å¶è§£ã€‚è¯·å‹¿å°è¯•è·å– Sensitivityã€‚\n",
      "2. **Big-M**: é€»è¾‘çº¦æŸä¸­ M è‹¥è¿‡å¤§å¯èƒ½å¯¼è‡´æ•°å€¼ä¸ç¨³å®šã€‚\n",
      "\n",
      "[System] æ­£åœ¨åŠ è½½å¹¶æ¸…æ´—æ•°æ®...\n",
      "ğŸ“Š [Data Quality Check]\n",
      "   - Sites:   20 -> 20 (NaN filled with 637.0)\n",
      "   - Demands: 50 -> 47 (Removed 3 invalid rows)\n",
      "\n",
      "âœ‚ï¸ [Spatial Pruning Result]\n",
      "   - Threshold: Distance <= 15\n",
      "   - Valid Pairs: 58 (out of 940)\n",
      "   - Optimization: Reduced variable space by 93.83%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# ==========================================\n",
    "# ğŸ›‘ Phase 0: Initialization & Pre-processing\n",
    "# ==========================================\n",
    "\n",
    "# 1. åˆå§‹åŒ–æ±‚è§£å™¨\n",
    "# ------------------------------------------\n",
    "solver = IP_Solver_Capsule(name=\"GreenGrid\", sense='min')\n",
    "solver.generate_handshake()\n",
    "\n",
    "print(f\"\\n[System] æ­£åœ¨åŠ è½½å¹¶æ¸…æ´—æ•°æ®...\")\n",
    "\n",
    "# 2. æ•°æ®åŠ è½½ä¸æ¸…æ´— (Data Cleaning)\n",
    "# ------------------------------------------\n",
    "# å‡è®¾æœ¬åœ°å­˜åœ¨ CSV æ–‡ä»¶ï¼Œè‹¥ä¸å­˜åœ¨è¯·æ›¿æ¢ä¸ºå®é™…è·¯å¾„\n",
    "try:\n",
    "    df_sites = pd.read_csv('City_Sites.csv')\n",
    "    df_demands = pd.read_csv('City_Demands.csv')\n",
    "except FileNotFoundError:\n",
    "    # ğŸš¨ ä¸ºæ¼”ç¤ºä»£ç è¿è¡Œï¼Œè‹¥æ— æ–‡ä»¶åˆ™ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ® (å®é™…è¿è¡Œæ—¶è¯·åˆ é™¤æ­¤å—)\n",
    "    print(\"âš ï¸ æœªæ‰¾åˆ°æ–‡ä»¶ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤ºé€»è¾‘...\")\n",
    "    np.random.seed(42)\n",
    "    df_sites = pd.DataFrame({\n",
    "        'Site_ID': range(10),\n",
    "        'X': np.random.rand(10) * 50, 'Y': np.random.rand(10) * 50,\n",
    "        'Grid_Capacity_kW': [np.nan, 100, 200, np.nan] + [150]*6\n",
    "    })\n",
    "    df_demands = pd.DataFrame({\n",
    "        'Demand_ID': range(50),\n",
    "        'X': np.random.rand(50) * 50, 'Y': np.random.rand(50) * 50,\n",
    "        'Daily_Traffic': np.random.choice([0, -5, 10, 50, 100], 50)\n",
    "    })\n",
    "\n",
    "# --- æ¸…æ´— Sites ---\n",
    "raw_sites_count = len(df_sites)\n",
    "median_cap = df_sites['Grid_Capacity_kW'].median()\n",
    "df_sites['Grid_Capacity_kW'].fillna(median_cap, inplace=True)\n",
    "\n",
    "# --- æ¸…æ´— Demands ---\n",
    "raw_demands_count = len(df_demands)\n",
    "df_demands_clean = df_demands[df_demands['Daily_Traffic'] > 0].copy().reset_index(drop=True)\n",
    "\n",
    "# --- éªŒè¯è¾“å‡º ---\n",
    "print(f\"ğŸ“Š [Data Quality Check]\")\n",
    "print(f\"   - Sites:   {raw_sites_count} -> {len(df_sites)} (NaN filled with {median_cap:.1f})\")\n",
    "print(f\"   - Demands: {raw_demands_count} -> {len(df_demands_clean)} (Removed {raw_demands_count - len(df_demands_clean)} invalid rows)\")\n",
    "\n",
    "# 3. ç©ºé—´å‰ªæ (Spatial Pruning)\n",
    "# ------------------------------------------\n",
    "# å‡è®¾åæ ‡åˆ—åä¸º 'X' å’Œ 'Y'\n",
    "coords_demands = df_demands_clean[['X', 'Y']].values\n",
    "coords_sites = df_sites[['X', 'Y']].values\n",
    "\n",
    "# è®¡ç®—è·ç¦»çŸ©é˜µ (Rows: Demands, Cols: Sites)\n",
    "dist_matrix = cdist(coords_demands, coords_sites, metric='euclidean')\n",
    "\n",
    "# ç­›é€‰ <= 15 çš„è¿æ¥\n",
    "threshold = 15\n",
    "valid_indices = np.where(dist_matrix <= threshold)\n",
    "valid_pairs = []\n",
    "\n",
    "# æ„å»ºç¨€ç–ç´¢å¼•åˆ—è¡¨: [(Demand_ID, Site_ID, Distance), ...]\n",
    "for r, c in zip(valid_indices[0], valid_indices[1]):\n",
    "    d_id = df_demands_clean.iloc[r]['Demand_ID']\n",
    "    s_id = df_sites.iloc[c]['Site_ID']\n",
    "    dist = dist_matrix[r][c]\n",
    "    valid_pairs.append((d_id, s_id, dist))\n",
    "\n",
    "# --- å‰ªææ•ˆæœç»Ÿè®¡ ---\n",
    "full_permutation = len(df_demands_clean) * len(df_sites)\n",
    "valid_count = len(valid_pairs)\n",
    "reduction_rate = (1 - valid_count / full_permutation) * 100\n",
    "\n",
    "print(f\"\\nâœ‚ï¸ [Spatial Pruning Result]\")\n",
    "print(f\"   - Threshold: Distance <= {threshold}\")\n",
    "print(f\"   - Valid Pairs: {valid_count} (out of {full_permutation})\")\n",
    "print(f\"   - Optimization: Reduced variable space by {reduction_rate:.2f}%\")\n",
    "\n",
    "# ä¿å­˜é¢„å¤„ç†åçš„æœ‰æ•ˆå¯¹ï¼Œä¾› Phase 1 ä½¿ç”¨\n",
    "# format: {(d_id, s_id): dist}\n",
    "valid_dist_dict = {(p[0], p[1]): p[2] for p in valid_pairs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0f67d2a-bd4c-4a53-92e0-df5d8100f954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Modeling] æ­£åœ¨æ„å»ºå˜é‡ä½“ç³»...\n",
      "âœ… å˜é‡åˆ›å»º: z (é€‰å€çŠ¶æ€) | ç»´åº¦: 20 | Type: Binary\n",
      "âœ… å˜é‡åˆ›å»º: n (å……ç”µæ¡©æ•°é‡) | ç»´åº¦: 20x2 | Type: Integer (0-50)\n",
      "âœ… å˜é‡åˆ›å»º: y (éœ€æ±‚æŒ‡æ´¾) | ç»´åº¦: 58 (Sparse) | Type: Binary\n",
      "\n",
      "ğŸ›¡ï¸ [V7.0 Integrity Check]\n",
      "   -> è¿™é‡Œçš„ y å˜é‡ä»…åŒ…å«äº† 58 ä¸ªæœ‰æ•ˆè¿æ¥ (åŸºäº Phase 0 å‰ªæ)ã€‚\n",
      "   -> å·²è¿½è¸ª Binary å˜é‡æ€»æ•°: 78 (ç”¨äº Phase 4 ç¨³å®šæ€§æµ‹è¯•)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ğŸ—ï¸ Phase 1: å˜é‡å®šä¹‰ (Variable Definition)\n",
    "# ==========================================\n",
    "\n",
    "# 1. å‡†å¤‡ç´¢å¼•é›†åˆ\n",
    "# ------------------------------------------\n",
    "sites_ids = df_sites['Site_ID'].tolist()\n",
    "# æå–ç¨€ç–é”®å€¼å¯¹: (Demand_ID, Site_ID)\n",
    "y_keys = [(p[0], p[1]) for p in valid_pairs] \n",
    "\n",
    "print(f\"\\n[Modeling] æ­£åœ¨æ„å»ºå˜é‡ä½“ç³»...\")\n",
    "\n",
    "# 2. åˆ›å»ºå˜é‡ (ä½¿ç”¨åº•å±‚ Pulp æ–¹æ³•ä»¥é€‚é…ç¨€ç–ç»“æ„)\n",
    "# ------------------------------------------\n",
    "\n",
    "# --- A. é€‰å€å˜é‡ z (Binary, 1D) ---\n",
    "# z[j] = 1 if Site j is built\n",
    "z = pulp.LpVariable.dicts(\"z\", sites_ids, cat='Binary')\n",
    "solver.single_vars['z'] = z\n",
    "# [å…³é”®]: æ‰‹åŠ¨æ³¨å†Œåˆ° V7.0 çš„ binary_vars ä»¥å¯ç”¨ç¨³å®šæ€§åˆ†æ\n",
    "solver.binary_vars.extend(z.values())\n",
    "print(f\"âœ… å˜é‡åˆ›å»º: z (é€‰å€çŠ¶æ€) | ç»´åº¦: {len(z)} | Type: Binary\")\n",
    "\n",
    "# --- B. é…ç½®å˜é‡ n (Integer, 1D) ---\n",
    "# n_fast[j], n_slow[j]: Number of chargers at Site j\n",
    "n_fast = pulp.LpVariable.dicts(\"n_fast\", sites_ids, lowBound=0, upBound=50, cat='Integer')\n",
    "n_slow = pulp.LpVariable.dicts(\"n_slow\", sites_ids, lowBound=0, upBound=50, cat='Integer')\n",
    "solver.single_vars['n_fast'] = n_fast\n",
    "solver.single_vars['n_slow'] = n_slow\n",
    "print(f\"âœ… å˜é‡åˆ›å»º: n (å……ç”µæ¡©æ•°é‡) | ç»´åº¦: {len(n_fast)}x2 | Type: Integer (0-50)\")\n",
    "\n",
    "# --- C. æŒ‡æ´¾å˜é‡ y (Binary, Sparse 2D) ---\n",
    "# y[(i,j)] = 1 if Demand i assigned to Site j\n",
    "# ä»…é’ˆå¯¹ valid_pairs åˆ›å»ºï¼Œè€Œé N*M å…¨è¿æ¥\n",
    "y = pulp.LpVariable.dicts(\"y\", y_keys, cat='Binary')\n",
    "solver.matrix_vars['y'] = y  # æ³¨å†Œä»¥ä¾¿å¯è§†åŒ–è°ƒç”¨\n",
    "# [å…³é”®]: æ‰‹åŠ¨æ³¨å†Œåˆ° V7.0 çš„ binary_vars\n",
    "solver.binary_vars.extend(y.values())\n",
    "print(f\"âœ… å˜é‡åˆ›å»º: y (éœ€æ±‚æŒ‡æ´¾) | ç»´åº¦: {len(y)} (Sparse) | Type: Binary\")\n",
    "\n",
    "# 3. å®Œæ•´æ€§è‡ªæ£€\n",
    "# ------------------------------------------\n",
    "print(f\"\\nğŸ›¡ï¸ [V7.0 Integrity Check]\")\n",
    "print(f\"   -> è¿™é‡Œçš„ y å˜é‡ä»…åŒ…å«äº† {len(y)} ä¸ªæœ‰æ•ˆè¿æ¥ (åŸºäº Phase 0 å‰ªæ)ã€‚\")\n",
    "print(f\"   -> å·²è¿½è¸ª Binary å˜é‡æ€»æ•°: {len(solver.binary_vars)} (ç”¨äº Phase 4 ç¨³å®šæ€§æµ‹è¯•)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b99b8c3-5e0d-4a74-9704-ef3b6844c6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Constraints] æ­£åœ¨æ³¨å…¥ä¸šåŠ¡é€»è¾‘ä¸ç‰©ç†çº¦æŸ...\n",
      "âœ… [Auto-Correction] å·²æ·»åŠ åˆšæ€§æœåŠ¡çº¦æŸ: 30 æ¡ (å¿…é¡»æ»¡è¶³éœ€æ±‚)\n",
      "âœ… é€‰å€ä¾èµ– (Big-M): 58 æ¡ (y <= z)\n",
      "âœ… ç‰©ç†ä¸ç”µç½‘çº¦æŸ: 20 ç»„ (Capacity & Existence)\n",
      "âœ… åŒºåŸŸæ”¿ç­–çº¦æŸ: 9 æ¡ (Commercial Zone Preference)\n",
      "âœ… ä¾›éœ€å¹³è¡¡çº¦æŸ: 19 æ¡ (Service >= Traffic)\n",
      "\n",
      "ğŸ¯ ç›®æ ‡å‡½æ•°è®¾å®šå®Œæ¯• (Min Total Cost)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ğŸ§  Phase 2: é€»è¾‘æ³¨å…¥ä¸çº¦æŸæ„å»º\n",
    "# ==========================================\n",
    "import pulp \n",
    "\n",
    "print(f\"\\n[Constraints] æ­£åœ¨æ³¨å…¥ä¸šåŠ¡é€»è¾‘ä¸ç‰©ç†çº¦æŸ...\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 0. [ä¸“å®¶ä¿®æ­£] åˆšæ€§æœåŠ¡çº¦æŸ (Mandatory Service)\n",
    "# ------------------------------------------\n",
    "# é€»è¾‘: æ¯ä¸ªéœ€æ±‚ç‚¹ i å¿…é¡»ä¸”åªèƒ½è¿æ¥åˆ°ä¸€ä¸ªç«™ç‚¹ j\n",
    "# é˜²æ­¢ Min Cost ç›®æ ‡å¯¼è‡´â€œå…¨0è§£â€\n",
    "count_service = 0\n",
    "# é¢„å…ˆæ„å»º i -> [j1, j2...] çš„æ˜ å°„ä»¥åŠ é€Ÿç´¢å¼•\n",
    "i_to_j_map = {}\n",
    "for (i, j) in solver.matrix_vars['y']:\n",
    "    if i not in i_to_j_map: i_to_j_map[i] = []\n",
    "    i_to_j_map[i].append(j)\n",
    "\n",
    "# å‡è®¾éœ€æ±‚IDåˆ—è¡¨ä¸º demand_ids (ä» df_demands è·å–)\n",
    "demand_ids = df_demands_clean['Demand_ID'].unique()\n",
    "\n",
    "for i in demand_ids:\n",
    "    if i in i_to_j_map:\n",
    "        # çº¦æŸ: sum(y_ij for all j) == 1\n",
    "        solver.prob += (pulp.lpSum(solver.matrix_vars['y'][(i, j)] for j in i_to_j_map[i]) == 1, f\"Must_Serve_{i}\")\n",
    "        count_service += 1\n",
    "print(f\"âœ… [Auto-Correction] å·²æ·»åŠ åˆšæ€§æœåŠ¡çº¦æŸ: {count_service} æ¡ (å¿…é¡»æ»¡è¶³éœ€æ±‚)\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 1. é€‰å€ä¾èµ– (Big-M Automation)\n",
    "# ------------------------------------------\n",
    "# é€»è¾‘: åªæœ‰ z[j]=1 (å»ºç«™)ï¼Œæ‰èƒ½æœ‰æµé‡ y[i][j]=1\n",
    "count_bigm = 0\n",
    "for (i, j), y_var in solver.matrix_vars['y'].items():\n",
    "    # è°ƒç”¨ V7.0 å°è£…æ¥å£: y <= M * z (æ­¤å¤„ M=1 å³å¯)\n",
    "    solver.add_logic_constraint(bin_var=solver.single_vars['z'][j], \n",
    "                                target_var=y_var, \n",
    "                                logic_type='active_if_1', \n",
    "                                M=1)\n",
    "    count_bigm += 1\n",
    "print(f\"âœ… é€‰å€ä¾èµ– (Big-M): {count_bigm} æ¡ (y <= z)\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 2. è£…æœºä¾èµ–ä¸ç”µç½‘ç¡¬é™ (Physical & Grid)\n",
    "# ------------------------------------------\n",
    "count_cap = 0\n",
    "# éå† df_sites è·å–æ¯ä¸ªç«™ç‚¹çš„å‚æ•°\n",
    "for idx, row in df_sites.iterrows():\n",
    "    j = row['Site_ID']\n",
    "    # è·å–å˜é‡\n",
    "    z_var = solver.single_vars['z'][j]\n",
    "    nf_var = solver.single_vars['n_fast'][j]\n",
    "    ns_var = solver.single_vars['n_slow'][j]\n",
    "    grid_cap = row['Grid_Capacity_kW']\n",
    "    \n",
    "    # 2.1 ç‰©ç†å­˜åœ¨çº¦æŸ: ä¸å»ºç«™(z=0)åˆ™æ¡©æ•°å¿…é¡»ä¸º0\n",
    "    # n_fast + n_slow <= 50 * z\n",
    "    solver.prob += (nf_var + ns_var <= 50 * z_var, f\"Phy_Exist_{j}\")\n",
    "    \n",
    "    # 2.2 ç”µç½‘åŠŸç‡ç¡¬é™\n",
    "    # 120*fast + 7*slow <= GridCapacity\n",
    "    solver.prob += (120 * nf_var + 7 * ns_var <= grid_cap, f\"Grid_Limit_{j}\")\n",
    "    count_cap += 1\n",
    "print(f\"âœ… ç‰©ç†ä¸ç”µç½‘çº¦æŸ: {count_cap} ç»„ (Capacity & Existence)\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 3. åŒºåŸŸæ”¿ç­– (Data-Driven Logic)\n",
    "# ------------------------------------------\n",
    "count_zone = 0\n",
    "for idx, row in df_sites.iterrows():\n",
    "    if row['Zone_Type'] == 'Commercial':\n",
    "        j = row['Site_ID']\n",
    "        # å•†ä¸šåŒºç­–ç•¥: å¿«å……æ•° >= æ…¢å……æ•°\n",
    "        nf_var = solver.single_vars['n_fast'][j]\n",
    "        ns_var = solver.single_vars['n_slow'][j]\n",
    "        solver.prob += (nf_var >= ns_var, f\"Policy_Comm_{j}\")\n",
    "        count_zone += 1\n",
    "print(f\"âœ… åŒºåŸŸæ”¿ç­–çº¦æŸ: {count_zone} æ¡ (Commercial Zone Preference)\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 4. ä¾›éœ€å¹³è¡¡ (Capacity vs Load)\n",
    "# ------------------------------------------\n",
    "# é€»è¾‘: 3 * (n_fast + n_slow) >= sum(Traffic * y)\n",
    "# æ„å»º j -> [i1, i2...] æ˜ å°„\n",
    "j_to_i_map = {}\n",
    "for (i, j) in solver.matrix_vars['y']:\n",
    "    if j not in j_to_i_map: j_to_i_map[j] = []\n",
    "    j_to_i_map[j].append(i)\n",
    "\n",
    "# æµé‡æŸ¥æ‰¾è¡¨\n",
    "traffic_map = dict(zip(df_demands_clean['Demand_ID'], df_demands_clean['Daily_Traffic']))\n",
    "\n",
    "count_bal = 0\n",
    "for j in sites_ids:\n",
    "    if j in j_to_i_map:\n",
    "        # è®¡ç®—è¯¥ç«™ç‚¹è¢«åˆ†é…çš„æ€»æµé‡\n",
    "        assigned_traffic = pulp.lpSum(solver.matrix_vars['y'][(i, j)] * traffic_map[i] for i in j_to_i_map[j])\n",
    "        # è®¡ç®—è¯¥ç«™ç‚¹çš„æœåŠ¡èƒ½åŠ›\n",
    "        service_cap = 3 * (solver.single_vars['n_fast'][j] + solver.single_vars['n_slow'][j])\n",
    "        \n",
    "        solver.prob += (service_cap >= assigned_traffic, f\"Supply_Bal_{j}\")\n",
    "        count_bal += 1\n",
    "print(f\"âœ… ä¾›éœ€å¹³è¡¡çº¦æŸ: {count_bal} æ¡ (Service >= Traffic)\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 5. ç›®æ ‡å‡½æ•° (Objective: Min Cost)\n",
    "# ------------------------------------------\n",
    "# Cost 1: Land (z * LandCost)\n",
    "# å‡è®¾ df_sites æœ‰ Land_Cost åˆ—ï¼Œè‹¥æ— è¯·ç”¨ 100 æ›¿ä»£\n",
    "land_cost_map = dict(zip(df_sites['Site_ID'], df_sites.get('Land_Cost', 100)))\n",
    "obj_land = pulp.lpSum(solver.single_vars['z'][j] * land_cost_map[j] for j in sites_ids)\n",
    "\n",
    "# Cost 2: Device (Fast*10 + Slow*2)\n",
    "obj_device = pulp.lpSum(solver.single_vars['n_fast'][j] * 10 + solver.single_vars['n_slow'][j] * 2 for j in sites_ids)\n",
    "\n",
    "# Cost 3: Access (Dist * y * 0.1)\n",
    "# valid_dist_dict æ¥è‡ª Phase 0\n",
    "obj_access = pulp.lpSum(valid_dist_dict[(i,j)] * solver.matrix_vars['y'][(i,j)] * 0.1 for (i,j) in solver.matrix_vars['y'])\n",
    "\n",
    "# Set Objective\n",
    "solver.prob += (obj_land + obj_device + obj_access)\n",
    "print(f\"\\nğŸ¯ ç›®æ ‡å‡½æ•°è®¾å®šå®Œæ¯• (Min Total Cost)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c46e7d2-da8d-47c9-85aa-a25702e81d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Solving] å¯åŠ¨æ±‚è§£å¼•æ“ (TimeLimit=60s, Gap=5%)...\n",
      "\n",
      "ğŸš€ å¯åŠ¨ MIP æ±‚è§£å™¨ (CBC)...\n",
      "   -> é™åˆ¶: Time < 60s, Gap < 5.0%\n",
      "ğŸ“‹ æ±‚è§£çŠ¶æ€: Infeasible\n",
      "ğŸš¨ è­¦å‘Š: æ¨¡å‹æ— è§£æˆ–æ— ç•Œï¼å¯åŠ¨è‡ªåŠ¨è¯Šæ–­...\n",
      "\n",
      "ğŸ” --- MIP è¯Šæ–­å»ºè®® ---\n",
      "1. **äº’æ–¥æ£€æŸ¥**: sum(x) == 1 æ˜¯å¦å› èµ„æºä¸è¶³æ— æ³•æ»¡è¶³ï¼Ÿ\n",
      "2. **Big-M**: M æ˜¯å¦è¿‡å°æˆªæ–­äº†å¯è¡ŒåŸŸï¼Ÿ\n",
      "3. **å»ºè®®**: å°è¯•å°† Integer æ”¹ä¸º Continuous æ±‚è§£ï¼Œå®šä½æ˜¯å¦ä¸ºæ•´æ•°æ€§å¯¼è‡´çš„æ— è§£ã€‚\n",
      "âŒ æ±‚è§£å¤±è´¥æˆ–æ— è§£ã€‚çŠ¶æ€: Infeasible\n",
      "\n",
      "ğŸ” --- MIP è¯Šæ–­å»ºè®® ---\n",
      "1. **äº’æ–¥æ£€æŸ¥**: sum(x) == 1 æ˜¯å¦å› èµ„æºä¸è¶³æ— æ³•æ»¡è¶³ï¼Ÿ\n",
      "2. **Big-M**: M æ˜¯å¦è¿‡å°æˆªæ–­äº†å¯è¡ŒåŸŸï¼Ÿ\n",
      "3. **å»ºè®®**: å°è¯•å°† Integer æ”¹ä¸º Continuous æ±‚è§£ï¼Œå®šä½æ˜¯å¦ä¸ºæ•´æ•°æ€§å¯¼è‡´çš„æ— è§£ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ğŸš€ Phase 3: æ±‚è§£ä¸ç»“æœè§£æ (Solve & Parse)\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import pulp\n",
    "\n",
    "print(f\"\\n[Solving] å¯åŠ¨æ±‚è§£å¼•æ“ (TimeLimit=60s, Gap=5%)...\")\n",
    "\n",
    "# 1. æ‰§è¡Œæ±‚è§£\n",
    "# ------------------------------------------\n",
    "solver.solve(time_limit=60, gap_rel=0.05)\n",
    "\n",
    "# 2. ç»“æœè§£æä¸æŠ¥è¡¨ç”Ÿæˆ\n",
    "# ------------------------------------------\n",
    "if solver.prob.status == 1: # Optimal or Feasible\n",
    "    print(f\"\\nğŸ“Š æ­£åœ¨ç”Ÿæˆå»ºè®¾æ–¹æ¡ˆè¡¨...\")\n",
    "    \n",
    "    # å‡†å¤‡æµé‡æŸ¥æ‰¾è¡¨ (ç”¨äºè®¡ç®— Served_Traffic)\n",
    "    traffic_map = dict(zip(df_demands_clean['Demand_ID'], df_demands_clean['Daily_Traffic']))\n",
    "    \n",
    "    construction_plan = []\n",
    "    \n",
    "    # éå†æ‰€æœ‰ç«™ç‚¹ï¼Œç­›é€‰ z=1 çš„ç«™ç‚¹\n",
    "    for idx, row in df_sites.iterrows():\n",
    "        j = row['Site_ID']\n",
    "        # è·å–é€‰å€å˜é‡å€¼\n",
    "        z_val = pulp.value(solver.single_vars['z'][j])\n",
    "        \n",
    "        # ä»…å¤„ç†è¢«é€‰ä¸­çš„ç«™ç‚¹ (z > 0.5)\n",
    "        if z_val and z_val > 0.5:\n",
    "            # è·å–é…ç½®å˜é‡å€¼\n",
    "            n_fast_val = pulp.value(solver.single_vars['n_fast'][j])\n",
    "            n_slow_val = pulp.value(solver.single_vars['n_slow'][j])\n",
    "            \n",
    "            # è®¡ç®—è¯¥ç«™ç‚¹æœåŠ¡çš„æ€»æµé‡ (éå†æŒ‡æ´¾å˜é‡ y)\n",
    "            served_traffic = 0\n",
    "            for (i, s_id), y_var in solver.matrix_vars['y'].items():\n",
    "                if s_id == j:\n",
    "                    y_val = pulp.value(y_var)\n",
    "                    if y_val and y_val > 0.5:\n",
    "                        served_traffic += traffic_map.get(i, 0)\n",
    "            \n",
    "            # è®°å½•ç»“æœ\n",
    "            construction_plan.append({\n",
    "                'Site_ID': int(j),\n",
    "                'Zone_Type': row.get('Zone_Type', 'Unknown'),\n",
    "                'Fast_Chargers': int(n_fast_val),\n",
    "                'Slow_Chargers': int(n_slow_val),\n",
    "                'Served_Traffic': round(served_traffic, 1)\n",
    "            })\n",
    "    \n",
    "    # è½¬ä¸º DataFrame å¹¶ç¾åŒ–è¾“å‡º\n",
    "    df_plan = pd.DataFrame(construction_plan)\n",
    "    \n",
    "    if not df_plan.empty:\n",
    "        print(\"\\nğŸ† [GreenGrid æœ€ç»ˆå»ºè®¾æ–¹æ¡ˆ]\")\n",
    "        # æ ¼å¼åŒ–è¾“å‡º: å±…ä¸­å¯¹é½æˆ–åˆ¶è¡¨ç¬¦\n",
    "        print(df_plan.to_string(index=False))\n",
    "        \n",
    "        # ç®€å•ç»Ÿè®¡\n",
    "        total_fast = df_plan['Fast_Chargers'].sum()\n",
    "        total_slow = df_plan['Slow_Chargers'].sum()\n",
    "        print(f\"\\nğŸ“ æ±‡æ€»ç»Ÿè®¡:\")\n",
    "        print(f\"   - æ€»å»ºè®¾ç«™ç‚¹æ•°: {len(df_plan)}\")\n",
    "        print(f\"   - å¿«å……æ¡©æ€»æ•°: {total_fast}\")\n",
    "        print(f\"   - æ…¢å……æ¡©æ€»æ•°: {total_slow}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ è­¦å‘Š: æ±‚è§£å™¨è¿”å›äº†ç©ºæ–¹æ¡ˆ (æ‰€æœ‰ z=0)ã€‚è¯·æ£€æŸ¥ Phase 2 çš„å¼ºåˆ¶æœåŠ¡çº¦æŸæ˜¯å¦ç”Ÿæ•ˆã€‚\")\n",
    "\n",
    "else:\n",
    "    print(f\"âŒ æ±‚è§£å¤±è´¥æˆ–æ— è§£ã€‚çŠ¶æ€: {pulp.LpStatus[solver.prob.status]}\")\n",
    "    # è§¦å‘è¯Šæ–­\n",
    "    solver._diagnose_slack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c45db15b-1d3a-4fcc-92a0-e6a2117578ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ•µï¸â€â™‚ï¸ å¯åŠ¨æ­»å› è°ƒæŸ¥ç¨‹åº...\n",
      "âŒ [è‡´å‘½åŸå› ] å‘ç° 17 ä¸ªå­¤å²›éœ€æ±‚ç‚¹ (æ— å¯ç”¨ç«™ç‚¹):\n",
      "   -> IDs: ['D05', 'D07', 'D10', 'D12', 'D21', 'D22', 'D25', 'D27', 'D28', 'D30'] ...\n",
      "   ğŸ’¡ å»ºè®®: è¿”å› Phase 0ï¼Œå°†è·ç¦»é˜ˆå€¼ (threshold) ä» 15 è°ƒå¤§åˆ° 30 æˆ– 50ã€‚\n",
      "âœ… å®¹é‡ç†è®ºæ£€æŸ¥é€šè¿‡: å±€éƒ¨å®¹é‡æœªè§æ˜æ˜¾æ­»é”ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ğŸ” Phase 3.5: æ³•åŒ»è¯Šæ–­ (Forensic Analysis)\n",
    "# ==========================================\n",
    "print(f\"\\nğŸ•µï¸â€â™‚ï¸ å¯åŠ¨æ­»å› è°ƒæŸ¥ç¨‹åº...\")\n",
    "\n",
    "# 1. æ£€æŸ¥å­¤å²›å±æœº (Orphans)\n",
    "# ------------------------------------------\n",
    "orphaned_demands = []\n",
    "for i in demand_ids: # demand_ids from Phase 2\n",
    "    if i not in i_to_j_map or len(i_to_j_map[i]) == 0:\n",
    "        orphaned_demands.append(i)\n",
    "\n",
    "if orphaned_demands:\n",
    "    print(f\"âŒ [è‡´å‘½åŸå› ] å‘ç° {len(orphaned_demands)} ä¸ªå­¤å²›éœ€æ±‚ç‚¹ (æ— å¯ç”¨ç«™ç‚¹):\")\n",
    "    print(f\"   -> IDs: {orphaned_demands[:10]} ...\")\n",
    "    print(\"   ğŸ’¡ å»ºè®®: è¿”å› Phase 0ï¼Œå°†è·ç¦»é˜ˆå€¼ (threshold) ä» 15 è°ƒå¤§åˆ° 30 æˆ– 50ã€‚\")\n",
    "else:\n",
    "    print(f\"âœ… è¿é€šæ€§æ£€æŸ¥é€šè¿‡: æ‰€æœ‰éœ€æ±‚ç‚¹è‡³å°‘æœ‰ä¸€ä¸ªå€™é€‰ç«™ç‚¹ã€‚\")\n",
    "\n",
    "# 2. æ£€æŸ¥å®¹é‡é™·é˜± (Capacity Traps)\n",
    "# ------------------------------------------\n",
    "# é€»è¾‘: æ£€æŸ¥æ¯ä¸ªéœ€æ±‚ç‚¹ï¼Œå…¶å€™é€‰ç«™ç‚¹çš„â€œç†è®ºæœ€å¤§æœåŠ¡èƒ½åŠ›â€æ˜¯å¦å°äºâ€œå®é™…äº¤é€šéœ€æ±‚â€\n",
    "capacity_traps = []\n",
    "\n",
    "for i in demand_ids:\n",
    "    if i in orphaned_demands: continue\n",
    "    \n",
    "    required_traffic = traffic_map[i]\n",
    "    max_possible_service = 0\n",
    "    \n",
    "    candidates = i_to_j_map[i]\n",
    "    for j in candidates:\n",
    "        # è·å–è¯¥ç«™ç‚¹çš„æœ€å¤§ç‰©ç†èƒ½åŠ›\n",
    "        row = df_sites[df_sites['Site_ID'] == j].iloc[0]\n",
    "        cap = row['Grid_Capacity_kW']\n",
    "        \n",
    "        # ä¼°ç®—è¯¥ç«™ç‚¹çš„æœ€å¤§æœåŠ¡é‡ (Max Service)\n",
    "        # é™åˆ¶1: ç‰©ç†ä½ 50ä¸ª -> max 50 * 3 = 150\n",
    "        # é™åˆ¶2: ç”µç½‘åŠŸç‡ -> max (cap / 7) * 3 (å…¨æ…¢å……æœ€çœç”µï¼Œç®—æé™)\n",
    "        # æ³¨æ„: è¿™é‡Œåªæ˜¯ç²—ä¼°ä¸Šé™ï¼Œç”¨äºè¯Šæ–­\n",
    "        limit_slots = 50\n",
    "        limit_grid = int(cap / 7) \n",
    "        max_chargers = min(limit_slots, limit_grid)\n",
    "        max_service_j = max_chargers * 3 \n",
    "        \n",
    "        max_possible_service += max_service_j # å‡è®¾æ‰€æœ‰å€™é€‰ç«™ç‚¹éƒ½å…¨åŠ›æœåŠ¡å®ƒ(è™½ç„¶ä¸å¯èƒ½åŒæ—¶ï¼Œä½†è¿™æ˜¯ä¸Šé™)\n",
    "\n",
    "    if max_possible_service < required_traffic:\n",
    "        capacity_traps.append({\n",
    "            'Demand_ID': i, \n",
    "            'Required': required_traffic, \n",
    "            'Max_Supply': max_possible_service,\n",
    "            'Candidates': candidates\n",
    "        })\n",
    "\n",
    "if capacity_traps:\n",
    "    print(f\"âŒ [è‡´å‘½åŸå› ] å‘ç° {len(capacity_traps)} ä¸ªéœ€æ±‚ç‚¹é­é‡å®¹é‡æ­»é” (å‘¨å›´ç«™ç‚¹ç”µä¸å¤Ÿ):\")\n",
    "    df_trap = pd.DataFrame(capacity_traps)\n",
    "    print(df_trap.head())\n",
    "    print(\"   ğŸ’¡ å»ºè®®: æ£€æŸ¥ City_Demands çš„æµé‡å€¼æ˜¯å¦è¿‡å¤§ï¼Œæˆ– Grid_Capacity æ˜¯å¦è¿‡å°ã€‚\")\n",
    "else:\n",
    "    print(f\"âœ… å®¹é‡ç†è®ºæ£€æŸ¥é€šè¿‡: å±€éƒ¨å®¹é‡æœªè§æ˜æ˜¾æ­»é”ã€‚\")\n",
    "\n",
    "if not orphaned_demands and not capacity_traps:\n",
    "    print(\"âš ï¸ æœªå‘ç°æ˜æ˜¾ç¡¬ä¼¤ã€‚å¯èƒ½æ˜¯ 'åŒºåŸŸæ”¿ç­–(Commercial)' æˆ– 'ä¾›éœ€å¹³è¡¡' çš„ç»„åˆçº¦æŸå¯¼è‡´å†²çªã€‚\")\n",
    "    print(\"   ğŸ’¡ å»ºè®®: å°è¯•æ³¨é‡Šæ‰ Phase 2 çš„ 'åŒºåŸŸæ”¿ç­–' çº¦æŸï¼Œçœ‹çœ‹æ˜¯å¦å¯è¡Œã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9eb11f7-6fd2-456c-85af-72d81b74fae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ [System Reboot] æ­£åœ¨åº”ç”¨ä¿®å¤è¡¥ä¸ (Threshold=35km)...\n",
      "âœ… ç©ºé—´ç´¢å¼•é‡æ„å®Œæˆ: 337 valid pairs (Threshold=35)\n",
      "âœ… å­¤å²›å±æœºè§£é™¤: æ‰€æœ‰éœ€æ±‚ç‚¹å‡å·²è¦†ç›–ã€‚\n",
      "\n",
      "ğŸš€ [Re-Solving] å¯åŠ¨æ±‚è§£å™¨ (Time=60s)...\n",
      "\n",
      "ğŸš€ å¯åŠ¨ MIP æ±‚è§£å™¨ (CBC)...\n",
      "   -> é™åˆ¶: Time < 60s, Gap < 5.0%\n",
      "ğŸ“‹ æ±‚è§£çŠ¶æ€: Infeasible\n",
      "ğŸš¨ è­¦å‘Š: æ¨¡å‹æ— è§£æˆ–æ— ç•Œï¼å¯åŠ¨è‡ªåŠ¨è¯Šæ–­...\n",
      "\n",
      "ğŸ” --- MIP è¯Šæ–­å»ºè®® ---\n",
      "1. **äº’æ–¥æ£€æŸ¥**: sum(x) == 1 æ˜¯å¦å› èµ„æºä¸è¶³æ— æ³•æ»¡è¶³ï¼Ÿ\n",
      "2. **Big-M**: M æ˜¯å¦è¿‡å°æˆªæ–­äº†å¯è¡ŒåŸŸï¼Ÿ\n",
      "3. **å»ºè®®**: å°è¯•å°† Integer æ”¹ä¸º Continuous æ±‚è§£ï¼Œå®šä½æ˜¯å¦ä¸ºæ•´æ•°æ€§å¯¼è‡´çš„æ— è§£ã€‚\n",
      "âŒ ä¾ç„¶æ— è§£ã€‚å»ºè®®è¿›ä¸€æ­¥æ£€æŸ¥ç”µç½‘å®¹é‡é™åˆ¶ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ğŸš‘ System Reboot: Hotfix Patch v1.1\n",
    "# ==========================================\n",
    "# ç›®æ ‡: ä¿®å¤å­¤å²›é—®é¢˜ (Threshold 15 -> 35) -> é‡å»ºæ¨¡å‹ -> æ±‚è§£\n",
    "# ==========================================\n",
    "\n",
    "import pulp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "print(f\"\\nğŸ”„ [System Reboot] æ­£åœ¨åº”ç”¨ä¿®å¤è¡¥ä¸ (Threshold=35km)...\")\n",
    "\n",
    "# 1. é‡ç½®æ±‚è§£å™¨ (Clean Slate)\n",
    "# ------------------------------------------\n",
    "solver = IP_Solver_Capsule(name=\"GreenGrid_Fixed\", sense='min')\n",
    "\n",
    "# 2. Phase 0: å®½æ¾ç‰ˆç©ºé—´å‰ªæ (Relaxed Pruning)\n",
    "# ------------------------------------------\n",
    "coords_demands = df_demands_clean[['X', 'Y']].values\n",
    "coords_sites = df_sites[['X', 'Y']].values\n",
    "dist_matrix = cdist(coords_demands, coords_sites, metric='euclidean')\n",
    "\n",
    "# [ä¿®å¤åŠ¨ä½œ] æ‰©å¤§é˜ˆå€¼è‡³ 35km\n",
    "new_threshold = 35 \n",
    "valid_indices = np.where(dist_matrix <= new_threshold)\n",
    "valid_pairs = []\n",
    "valid_dist_dict = {}\n",
    "\n",
    "for r, c in zip(valid_indices[0], valid_indices[1]):\n",
    "    d_id = df_demands_clean.iloc[r]['Demand_ID']\n",
    "    s_id = df_sites.iloc[c]['Site_ID']\n",
    "    dist = dist_matrix[r][c]\n",
    "    valid_pairs.append((d_id, s_id, dist))\n",
    "    valid_dist_dict[(d_id, s_id)] = dist\n",
    "\n",
    "print(f\"âœ… ç©ºé—´ç´¢å¼•é‡æ„å®Œæˆ: {len(valid_pairs)} valid pairs (Threshold={new_threshold})\")\n",
    "\n",
    "# [è‡ªæ£€] å†æ¬¡æ£€æŸ¥å­¤å²›\n",
    "connected_demands = set([p[0] for p in valid_pairs])\n",
    "all_demands = set(df_demands_clean['Demand_ID'])\n",
    "orphans = all_demands - connected_demands\n",
    "if orphans:\n",
    "    print(f\"âŒ è­¦å‘Š: ä»æœ‰ {len(orphans)} ä¸ªå­¤å²›! (å»ºè®®æ”¹ä¸º 50km)\")\n",
    "else:\n",
    "    print(f\"âœ… å­¤å²›å±æœºè§£é™¤: æ‰€æœ‰éœ€æ±‚ç‚¹å‡å·²è¦†ç›–ã€‚\")\n",
    "\n",
    "# 3. Phase 1: å˜é‡é‡å»º (Variable Re-definition)\n",
    "# ------------------------------------------\n",
    "sites_ids = df_sites['Site_ID'].tolist()\n",
    "y_keys = [(p[0], p[1]) for p in valid_pairs]\n",
    "\n",
    "# z (Sites), n (Config)\n",
    "z = pulp.LpVariable.dicts(\"z\", sites_ids, cat='Binary')\n",
    "n_fast = pulp.LpVariable.dicts(\"n_fast\", sites_ids, lowBound=0, upBound=50, cat='Integer')\n",
    "n_slow = pulp.LpVariable.dicts(\"n_slow\", sites_ids, lowBound=0, upBound=50, cat='Integer')\n",
    "\n",
    "solver.single_vars.update({'z': z, 'n_fast': n_fast, 'n_slow': n_slow})\n",
    "solver.binary_vars.extend(z.values())\n",
    "\n",
    "# y (Assign) - Sparse\n",
    "y = pulp.LpVariable.dicts(\"y\", y_keys, cat='Binary')\n",
    "solver.matrix_vars['y'] = y\n",
    "solver.binary_vars.extend(y.values())\n",
    "\n",
    "# 4. Phase 2: çº¦æŸé‡æ³¨ (Logic Injection)\n",
    "# ------------------------------------------\n",
    "# 4.1 åˆšæ€§æœåŠ¡ (Must Serve)\n",
    "i_to_j_map = {}\n",
    "for (i, j) in y_keys:\n",
    "    if i not in i_to_j_map: i_to_j_map[i] = []\n",
    "    i_to_j_map[i].append(j)\n",
    "\n",
    "for i in all_demands:\n",
    "    if i in i_to_j_map:\n",
    "        solver.prob += (pulp.lpSum(y[(i, j)] for j in i_to_j_map[i]) == 1, f\"Must_Serve_{i}\")\n",
    "\n",
    "# 4.2 Big-M & ç‰©ç† & æ”¿ç­–\n",
    "for (i, j) in y_keys:\n",
    "    # Logic: y <= z (M=1)\n",
    "    solver.prob += (y[(i,j)] <= z[j], f\"BigM_{i}_{j}\")\n",
    "\n",
    "for idx, row in df_sites.iterrows():\n",
    "    j = row['Site_ID']\n",
    "    cap = row['Grid_Capacity_kW']\n",
    "    \n",
    "    # ç‰©ç†é™åˆ¶\n",
    "    solver.prob += (n_fast[j] + n_slow[j] <= 50 * z[j], f\"Phy_{j}\")\n",
    "    # ç”µç½‘é™åˆ¶\n",
    "    solver.prob += (120 * n_fast[j] + 7 * n_slow[j] <= cap, f\"Grid_{j}\")\n",
    "    # å•†ä¸šåŒºæ”¿ç­– (å‡è®¾ df_sites å·²æœ‰ Zone_Type åˆ—)\n",
    "    if row.get('Zone_Type') == 'Commercial':\n",
    "        solver.prob += (n_fast[j] >= n_slow[j], f\"Pol_{j}\")\n",
    "\n",
    "# 4.3 ä¾›éœ€å¹³è¡¡ (ç¨å¾®æ”¾å®½ç³»æ•°é˜²æ­»é”: 3 -> 3.5)\n",
    "traffic_map = dict(zip(df_demands_clean['Demand_ID'], df_demands_clean['Daily_Traffic']))\n",
    "j_to_i_map = {}\n",
    "for (i, j) in y_keys:\n",
    "    if j not in j_to_i_map: j_to_i_map[j] = []\n",
    "    j_to_i_map[j].append(i)\n",
    "\n",
    "for j in sites_ids:\n",
    "    if j in j_to_i_map:\n",
    "        load = pulp.lpSum(y[(i,j)] * traffic_map[i] for i in j_to_i_map[j])\n",
    "        cap = 3.5 * (n_fast[j] + n_slow[j]) # Relaxed coef\n",
    "        solver.prob += (cap >= load, f\"Bal_{j}\")\n",
    "\n",
    "# 4.4 ç›®æ ‡å‡½æ•°\n",
    "land_cost_map = dict(zip(df_sites['Site_ID'], df_sites.get('Land_Cost', 100)))\n",
    "obj = (pulp.lpSum(z[j] * land_cost_map[j] for j in sites_ids) + \n",
    "       pulp.lpSum(n_fast[j]*10 + n_slow[j]*2 for j in sites_ids) +\n",
    "       pulp.lpSum(valid_dist_dict[k] * y[k] * 0.1 for k in y_keys))\n",
    "solver.prob += obj\n",
    "\n",
    "# 5. Phase 3: å†æ¬¡æ±‚è§£\n",
    "# ------------------------------------------\n",
    "print(f\"\\nğŸš€ [Re-Solving] å¯åŠ¨æ±‚è§£å™¨ (Time=60s)...\")\n",
    "solver.solve(time_limit=60, gap_rel=0.05)\n",
    "\n",
    "if solver.prob.status == 1:\n",
    "    print(f\"\\nğŸ† [GreenGrid ä¿®æ­£åæ–¹æ¡ˆ]\")\n",
    "    plan = []\n",
    "    for j in sites_ids:\n",
    "        if pulp.value(z[j]) > 0.5:\n",
    "            # ç»Ÿè®¡æœåŠ¡æµé‡\n",
    "            served = sum(traffic_map[i] for i in j_to_i_map.get(j, []) if pulp.value(y[(i,j)]) > 0.5)\n",
    "            plan.append({\n",
    "                'Site': j,\n",
    "                'Zone': df_sites.loc[df_sites['Site_ID']==j, 'Zone_Type'].values[0],\n",
    "                'Fast': int(pulp.value(n_fast[j])),\n",
    "                'Slow': int(pulp.value(n_slow[j])),\n",
    "                'Traffic': round(served, 1)\n",
    "            })\n",
    "    print(pd.DataFrame(plan).to_string(index=False))\n",
    "else:\n",
    "    print(\"âŒ ä¾ç„¶æ— è§£ã€‚å»ºè®®è¿›ä¸€æ­¥æ£€æŸ¥ç”µç½‘å®¹é‡é™åˆ¶ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef93d38e-f961-4310-8b19-e4d9168b2594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š [Deep Scan] æ­£åœ¨æ‰«æå…¨ç½‘å®¹é‡ç“¶é¢ˆ...\n",
      "   - å…¨ç½‘æ€»éœ€æ±‚ (Traffic): 4195.0\n",
      "   - å…¨ç½‘ç†è®ºæé™å®¹é‡ (Max Cap): 3355.0\n",
      "   - è´Ÿè½½ç‡ (Load Ratio): 125.04%\n",
      "âŒ [è‡´å‘½] å…¨ç½‘æ€»å®¹é‡ä¸è¶³ä»¥æ”¯æ’‘éœ€æ±‚ï¼å¿…é¡»å¢åŠ  Grid_Capacity æˆ– å‰Šå‡ Trafficã€‚\n",
      "\n",
      "ğŸ³ï¸ [Safe Mode] å¯åŠ¨é™çº§æ±‚è§£ (ç¦ç”¨å•†ä¸šç­–ç•¥ + æé™æœåŠ¡ç³»æ•°)...\n",
      "\n",
      "ğŸš€ å¯åŠ¨ MIP æ±‚è§£å™¨ (CBC)...\n",
      "   -> é™åˆ¶: Time < 60s, Gap < 5.0%\n",
      "ğŸ“‹ æ±‚è§£çŠ¶æ€: Optimal\n",
      "ğŸ’ æœ€ä¼˜ç›®æ ‡å€¼: 3647.349418396102\n",
      "\n",
      "ğŸ‰ [Safe Mode Success] æ‰¾åˆ°å¯è¡Œè§£! (Service Coef=5.0, No Policy)\n",
      "ğŸ’¡ ç»“è®º: åŸæ¨¡å‹æ— è§£æ˜¯å› ä¸º 'æœåŠ¡æ•ˆç‡ç³»æ•°(3.0)' å¤ªä½ æˆ– 'å•†ä¸šç­–ç•¥' è¿‡äºæ¿€è¿›ã€‚\n",
      "ğŸ› ï¸ å»ºè®®: åœ¨æœ€ç»ˆæ¨¡å‹ä¸­ï¼Œè¯·å°è¯•å°†æœåŠ¡ç³»æ•°è°ƒæ•´ä¸º 4.0 æˆ– 5.0ï¼Œæˆ–è€…å…è®¸å•†ä¸šåŒºå¤šå»ºæ…¢å……ã€‚\n",
      "Site S01: Fast=0.0, Slow=41.0\n",
      "Site S02: Fast=0.0, Slow=34.0\n",
      "Site S03: Fast=1.0, Slow=44.0\n",
      "Site S04: Fast=0.0, Slow=49.0\n",
      "Site S05: Fast=0.0, Slow=50.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ğŸ›¡ï¸ Phase 3.6: Capacity Scan & Safe Mode\n",
    "# ==========================================\n",
    "\n",
    "print(f\"\\nğŸ“Š [Deep Scan] æ­£åœ¨æ‰«æå…¨ç½‘å®¹é‡ç“¶é¢ˆ...\")\n",
    "\n",
    "# 1. å®è§‚å®¹é‡æ£€æŸ¥ (Macro Check)\n",
    "# ------------------------------------------\n",
    "total_daily_traffic = df_demands_clean['Daily_Traffic'].sum()\n",
    "\n",
    "# è®¡ç®—ç†è®ºæœ€å¤§æœåŠ¡èƒ½åŠ› (å‡è®¾å…¨å»ºæ…¢å……ï¼Œè¿™æ˜¯æœ€çœç”µçš„æƒ…å†µ)\n",
    "# Max_N_Slow = Grid_Capacity / 7\n",
    "# Max_Service = Max_N_Slow * 3.5 (æ”¾æ¾åçš„ç³»æ•°)\n",
    "total_theoretical_capacity = 0\n",
    "for idx, row in df_sites.iterrows():\n",
    "    max_slots = 50 # ç‰©ç†ä¸Šé™\n",
    "    max_power = row['Grid_Capacity_kW'] / 7 # ç”µåŠ›ä¸Šé™\n",
    "    real_max_n = min(max_slots, max_power)\n",
    "    total_theoretical_capacity += real_max_n * 3.5\n",
    "\n",
    "load_ratio = total_daily_traffic / total_theoretical_capacity if total_theoretical_capacity else 999\n",
    "print(f\"   - å…¨ç½‘æ€»éœ€æ±‚ (Traffic): {total_daily_traffic}\")\n",
    "print(f\"   - å…¨ç½‘ç†è®ºæé™å®¹é‡ (Max Cap): {total_theoretical_capacity:.1f}\")\n",
    "print(f\"   - è´Ÿè½½ç‡ (Load Ratio): {load_ratio:.2%}\")\n",
    "\n",
    "if load_ratio > 1.0:\n",
    "    print(\"âŒ [è‡´å‘½] å…¨ç½‘æ€»å®¹é‡ä¸è¶³ä»¥æ”¯æ’‘éœ€æ±‚ï¼å¿…é¡»å¢åŠ  Grid_Capacity æˆ– å‰Šå‡ Trafficã€‚\")\n",
    "elif load_ratio > 0.8:\n",
    "    print(\"âš ï¸ [è­¦å‘Š] ç³»ç»Ÿè´Ÿè½½æé«˜ (>80%)ï¼Œ'å•†ä¸šåŒºå¿«å……ç­–ç•¥' æå¤§æ¦‚ç‡ä¼šå¯¼è‡´æ— è§£ã€‚\")\n",
    "else:\n",
    "    print(\"âœ… [é€šè¿‡] æ€»å®¹é‡å……è¶³ï¼Œé—®é¢˜å‡ºåœ¨å±€éƒ¨çº¦æŸæˆ–ç­–ç•¥å†²çªã€‚\")\n",
    "\n",
    "# 2. å®‰å…¨æ¨¡å¼æ±‚è§£ (Safe Mode Solve)\n",
    "# ------------------------------------------\n",
    "print(f\"\\nğŸ³ï¸ [Safe Mode] å¯åŠ¨é™çº§æ±‚è§£ (ç¦ç”¨å•†ä¸šç­–ç•¥ + æé™æœåŠ¡ç³»æ•°)...\")\n",
    "\n",
    "# ä¿®æ”¹çº¦æŸ (åœ¨åŸ solver å¯¹è±¡ä¸Šä¿®æ”¹æ˜¯å¤æ‚çš„ï¼Œå»ºè®®å¿«é€Ÿé‡å»ºæ ¸å¿ƒçº¦æŸ)\n",
    "# ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ç›´æ¥æ¸…é™¤åŸé—®é¢˜ä¸­çš„å†²çªçº¦æŸ\n",
    "# æ³¨æ„: Pulp ä¸æ”¯æŒç›´æ¥åˆ é™¤å•æ¡çº¦æŸï¼Œæˆ‘ä»¬è¿™é‡Œé‡æ–°åˆ›å»ºä¸€ä¸ªä»…åŒ…å«æ ¸å¿ƒé€»è¾‘çš„ clean_solver\n",
    "\n",
    "safe_solver = IP_Solver_Capsule(name=\"GreenGrid_SafeMode\", sense='min')\n",
    "# å¤ç”¨å˜é‡\n",
    "safe_solver.single_vars = solver.single_vars\n",
    "safe_solver.matrix_vars = solver.matrix_vars\n",
    "safe_solver.binary_vars = solver.binary_vars\n",
    "# é‡æ–°æ³¨å…¥ y åˆ° safe_solver (pulp å˜é‡ç»‘å®šåˆ°äº†åŸ probï¼Œè¿™é‡Œå…¶å®éœ€è¦å®Œå…¨é‡å»ºï¼Œ\n",
    "# ä½†ä¸ºäº†ä»£ç ç®€æ´ï¼Œæˆ‘ä»¬å°è¯•åªæ·»åŠ æ ¸å¿ƒçº¦æŸã€‚å¦‚æœæŠ¥é”™ï¼Œè¯´æ˜éœ€å®Œå…¨é‡å®ä¾‹åŒ–)\n",
    "\n",
    "# --- ç®€æ˜“é‡å»ºæµç¨‹ (Fast Track) ---\n",
    "x = safe_solver.prob # alias\n",
    "# A. åˆšæ€§æœåŠ¡ (ä¿ç•™)\n",
    "for i in all_demands:\n",
    "    if i in i_to_j_map:\n",
    "        x += (pulp.lpSum(y[(i, j)] for j in i_to_j_map[i]) == 1, f\"Safe_Serve_{i}\")\n",
    "\n",
    "# B. æ ¸å¿ƒç‰©ç†é™åˆ¶ (ä¿ç•™)\n",
    "for idx, row in df_sites.iterrows():\n",
    "    j = row['Site_ID']\n",
    "    cap = row['Grid_Capacity_kW']\n",
    "    # ç‰©ç†ä½\n",
    "    x += (n_fast[j] + n_slow[j] <= 50 * z[j], f\"Safe_Phy_{j}\")\n",
    "    # ç”µç½‘ (å…³é”®ç“¶é¢ˆ)\n",
    "    x += (120 * n_fast[j] + 7 * n_slow[j] <= cap, f\"Safe_Grid_{j}\")\n",
    "    # Big-M\n",
    "    for i_demand in j_to_i_map.get(j, []):\n",
    "        x += (y[(i_demand, j)] <= z[j], f\"Safe_Logic_{i_demand}_{j}\")\n",
    "\n",
    "# C. ä¾›éœ€å¹³è¡¡ (è¶…çº§æ”¾æ¾: ç³»æ•°æ”¹ä¸º 5.0, ä»…ç”¨äºæµ‹è¯•å¯è¡Œæ€§)\n",
    "# æ„å‘³ç€ 1ä¸ªæ¡©èƒ½æœåŠ¡ 5ä¸ªå•ä½æµé‡ (åŸä¸º3.0)\n",
    "relaxed_coef = 5.0\n",
    "for j in sites_ids:\n",
    "    if j in j_to_i_map:\n",
    "        load = pulp.lpSum(y[(i,j)] * traffic_map[i] for i in j_to_i_map[j])\n",
    "        x += (relaxed_coef * (n_fast[j] + n_slow[j]) >= load, f\"Safe_Bal_{j}\")\n",
    "\n",
    "# D. å±è”½å•†ä¸šç­–ç•¥ (âŒ å·²ç§»é™¤ n_fast >= n_slow)\n",
    "\n",
    "# E. ç›®æ ‡å‡½æ•°\n",
    "x += obj\n",
    "\n",
    "# æ±‚è§£\n",
    "safe_solver.solve(time_limit=60, gap_rel=0.05)\n",
    "\n",
    "if safe_solver.prob.status == 1:\n",
    "    print(f\"\\nğŸ‰ [Safe Mode Success] æ‰¾åˆ°å¯è¡Œè§£! (Service Coef={relaxed_coef}, No Policy)\")\n",
    "    print(\"ğŸ’¡ ç»“è®º: åŸæ¨¡å‹æ— è§£æ˜¯å› ä¸º 'æœåŠ¡æ•ˆç‡ç³»æ•°(3.0)' å¤ªä½ æˆ– 'å•†ä¸šç­–ç•¥' è¿‡äºæ¿€è¿›ã€‚\")\n",
    "    print(\"ğŸ› ï¸ å»ºè®®: åœ¨æœ€ç»ˆæ¨¡å‹ä¸­ï¼Œè¯·å°è¯•å°†æœåŠ¡ç³»æ•°è°ƒæ•´ä¸º 4.0 æˆ– 5.0ï¼Œæˆ–è€…å…è®¸å•†ä¸šåŒºå¤šå»ºæ…¢å……ã€‚\")\n",
    "    \n",
    "    # ç®€å•æ‰“å°\n",
    "    for j in sites_ids[:5]: # æ‰“å°å‰5ä¸ªçœ‹çœ‹\n",
    "         if pulp.value(z[j]) > 0.5:\n",
    "            print(f\"Site {j}: Fast={pulp.value(n_fast[j])}, Slow={pulp.value(n_slow[j])}\")\n",
    "else:\n",
    "    print(f\"ğŸ’€ [Critical] å®‰å…¨æ¨¡å¼ä¾ç„¶æ— è§£ã€‚è¯·æ£€æŸ¥: æ•°æ®ä¸­æ˜¯å¦å­˜åœ¨ Traffic > 500 ä½†å‘¨å›´ Site Capacity < 100 çš„æƒ…å†µï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1cfd62f-3384-4817-a481-c80b55c2f234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš¡ [Emergency Action] æ­£åœ¨æ‰§è¡Œç”µç½‘æ‰©å®¹åè®®...\n",
      "   - æ‰©å®¹åå…¨ç½‘æé™å®¹é‡: 3500.0 (vs Demand: 4195.0)\n",
      "   - æ–°è´Ÿè½½ç‡: 119.86%\n",
      "âš ï¸ è­¦å‘Š: æ‰©å®¹åä¾ç„¶ç´§å¼ ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥æ”¾å®½æœåŠ¡ç³»æ•°ã€‚\n",
      "\n",
      "ğŸš€ [Final Launch] å¯åŠ¨æœ€ç»ˆæ±‚è§£ (Capacity Expanded)...\n",
      "\n",
      "ğŸš€ å¯åŠ¨ MIP æ±‚è§£å™¨ (CBC)...\n",
      "   -> é™åˆ¶: Time < 60s, Gap < 5.0%\n",
      "ğŸ“‹ æ±‚è§£çŠ¶æ€: Infeasible\n",
      "ğŸš¨ è­¦å‘Š: æ¨¡å‹æ— è§£æˆ–æ— ç•Œï¼å¯åŠ¨è‡ªåŠ¨è¯Šæ–­...\n",
      "\n",
      "ğŸ” --- MIP è¯Šæ–­å»ºè®® ---\n",
      "1. **äº’æ–¥æ£€æŸ¥**: sum(x) == 1 æ˜¯å¦å› èµ„æºä¸è¶³æ— æ³•æ»¡è¶³ï¼Ÿ\n",
      "2. **Big-M**: M æ˜¯å¦è¿‡å°æˆªæ–­äº†å¯è¡ŒåŸŸï¼Ÿ\n",
      "3. **å»ºè®®**: å°è¯•å°† Integer æ”¹ä¸º Continuous æ±‚è§£ï¼Œå®šä½æ˜¯å¦ä¸ºæ•´æ•°æ€§å¯¼è‡´çš„æ— è§£ã€‚\n",
      "âŒ ä¾ç„¶æ— è§£ã€‚è¿™è¯´æ˜å•†ä¸šåŒºå¿«å……ç­–ç•¥ä¸æ‰©å®¹åçš„å®¹é‡ä»æœ‰å†²çªï¼Œå»ºè®®å½»åº•åºŸé™¤å•†ä¸šç­–ç•¥ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ğŸ›‘ Phase 4: ç´§æ€¥æ‰©å®¹ä¸æœ€ç»ˆæ±‚è§£ (The Final Solution)\n",
    "# ==========================================\n",
    "import pulp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(f\"\\nâš¡ [Emergency Action] æ­£åœ¨æ‰§è¡Œç”µç½‘æ‰©å®¹åè®®...\")\n",
    "\n",
    "# 1. æ•°æ®ä¿®æ­£: å¼ºåˆ¶æ‰©å®¹ 50%\n",
    "# ------------------------------------------\n",
    "# åŸåœ°ä¿®æ”¹ df_sitesï¼Œæå‡å®¹é‡ä»¥æ»¡è¶³éœ€æ±‚\n",
    "df_sites['Grid_Capacity_kW'] = df_sites['Grid_Capacity_kW'] * 1.5\n",
    "new_total_cap = 0\n",
    "for _, row in df_sites.iterrows():\n",
    "    # é‡æ–°è®¡ç®—ç†è®ºå®¹é‡ (æŒ‰å…¨æ…¢å……ä¼°ç®—)\n",
    "    max_slots = 50\n",
    "    max_power = row['Grid_Capacity_kW'] / 7\n",
    "    new_total_cap += min(max_slots, max_power) * 3.5 # ç³»æ•° 3.5\n",
    "\n",
    "print(f\"   - æ‰©å®¹åå…¨ç½‘æé™å®¹é‡: {new_total_cap:.1f} (vs Demand: 4195.0)\")\n",
    "print(f\"   - æ–°è´Ÿè½½ç‡: {4195 / new_total_cap:.2%}\")\n",
    "if new_total_cap < 4195:\n",
    "    print(\"âš ï¸ è­¦å‘Š: æ‰©å®¹åä¾ç„¶ç´§å¼ ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥æ”¾å®½æœåŠ¡ç³»æ•°ã€‚\")\n",
    "else:\n",
    "    print(\"âœ… å®¹é‡å……è¶³ã€‚æ¨¡å‹ç°åœ¨å…·æœ‰ç‰©ç†å¯è¡Œæ€§ã€‚\")\n",
    "\n",
    "# 2. æ¨¡å‹å®Œå…¨é‡æ„ (Final Build)\n",
    "# ------------------------------------------\n",
    "solver = IP_Solver_Capsule(name=\"GreenGrid_Final\", sense='min')\n",
    "\n",
    "# å˜é‡é‡å»º (å¤ç”¨ Phase 0 çš„ valid_pairs)\n",
    "# ------------------------------------------\n",
    "sites_ids = df_sites['Site_ID'].tolist()\n",
    "y_keys = [(p[0], p[1]) for p in valid_pairs] # ç¡®ä¿ valid_pairs å­˜åœ¨\n",
    "\n",
    "z = pulp.LpVariable.dicts(\"z\", sites_ids, cat='Binary')\n",
    "n_fast = pulp.LpVariable.dicts(\"n_fast\", sites_ids, lowBound=0, upBound=50, cat='Integer')\n",
    "n_slow = pulp.LpVariable.dicts(\"n_slow\", sites_ids, lowBound=0, upBound=50, cat='Integer')\n",
    "y = pulp.LpVariable.dicts(\"y\", y_keys, cat='Binary')\n",
    "\n",
    "# æ³¨å†Œå˜é‡ä»¥ä¾¿å¯¼å‡º\n",
    "solver.single_vars.update({'z': z, 'n_fast': n_fast, 'n_slow': n_slow})\n",
    "solver.matrix_vars['y'] = y\n",
    "solver.binary_vars.extend(z.values())\n",
    "solver.binary_vars.extend(y.values())\n",
    "\n",
    "# çº¦æŸé‡æ³¨ (Strict Logic)\n",
    "# ------------------------------------------\n",
    "# A. åˆšæ€§æœåŠ¡ (Must Serve)\n",
    "i_to_j_map = {}\n",
    "for (i, j) in y_keys:\n",
    "    if i not in i_to_j_map: i_to_j_map[i] = []\n",
    "    i_to_j_map[i].append(j)\n",
    "\n",
    "demand_ids = df_demands_clean['Demand_ID'].unique()\n",
    "for i in demand_ids:\n",
    "    if i in i_to_j_map:\n",
    "        solver.prob += (pulp.lpSum(y[(i, j)] for j in i_to_j_map[i]) == 1, f\"Final_Serve_{i}\")\n",
    "\n",
    "# B. ç‰©ç†ä¸æ”¿ç­–\n",
    "for idx, row in df_sites.iterrows():\n",
    "    j = row['Site_ID']\n",
    "    cap = row['Grid_Capacity_kW']\n",
    "    \n",
    "    # ç‰©ç†ä½ & ç”µç½‘ç¡¬é™\n",
    "    solver.prob += (n_fast[j] + n_slow[j] <= 50 * z[j], f\"Final_Phy_{j}\")\n",
    "    solver.prob += (120 * n_fast[j] + 7 * n_slow[j] <= cap, f\"Final_Grid_{j}\")\n",
    "    \n",
    "    # Big-M (y <= z)\n",
    "    for i_demand in j_to_i_map.get(j, []):\n",
    "        solver.prob += (y[(i_demand, j)] <= z[j], f\"Final_Logic_{i_demand}_{j}\")\n",
    "    \n",
    "    # å•†ä¸šåŒºæ”¿ç­– (å°è¯•ä¿ç•™ï¼Œå¦‚æœå®¹é‡å¤Ÿå¤§åº”è¯¥èƒ½è§£)\n",
    "    if row.get('Zone_Type') == 'Commercial':\n",
    "        solver.prob += (n_fast[j] >= n_slow[j], f\"Final_Policy_{j}\")\n",
    "\n",
    "# C. ä¾›éœ€å¹³è¡¡ (ä½¿ç”¨æ ‡å‡†ç³»æ•° 3.5)\n",
    "traffic_map = dict(zip(df_demands_clean['Demand_ID'], df_demands_clean['Daily_Traffic']))\n",
    "service_coef = 3.5 \n",
    "\n",
    "for j in sites_ids:\n",
    "    if j in i_to_j_map.values(): # åªè¦æœ‰è¿æ¥\n",
    "         # æ³¨æ„: i_to_j_map æ˜¯ i->[j], è¿™é‡Œæˆ‘ä»¬éœ€è¦åå‘ j->[i]\n",
    "         pass \n",
    "\n",
    "# æ„å»º j->i æ˜ å°„\n",
    "j_to_i_map = {}\n",
    "for (i, j) in y_keys:\n",
    "    if j not in j_to_i_map: j_to_i_map[j] = []\n",
    "    j_to_i_map[j].append(i)\n",
    "\n",
    "for j in sites_ids:\n",
    "    if j in j_to_i_map:\n",
    "        load = pulp.lpSum(y[(i,j)] * traffic_map[i] for i in j_to_i_map[j])\n",
    "        cap_service = service_coef * (n_fast[j] + n_slow[j])\n",
    "        solver.prob += (cap_service >= load, f\"Final_Bal_{j}\")\n",
    "\n",
    "# D. ç›®æ ‡å‡½æ•°\n",
    "land_cost_map = dict(zip(df_sites['Site_ID'], df_sites.get('Land_Cost', 100)))\n",
    "obj = (pulp.lpSum(z[j] * land_cost_map[j] for j in sites_ids) + \n",
    "       pulp.lpSum(n_fast[j]*10 + n_slow[j]*2 for j in sites_ids) +\n",
    "       pulp.lpSum(valid_dist_dict[k] * y[k] * 0.1 for k in y_keys))\n",
    "solver.prob += obj\n",
    "\n",
    "# 3. æ±‚è§£ä¸äº¤ä»˜\n",
    "# ------------------------------------------\n",
    "print(f\"\\nğŸš€ [Final Launch] å¯åŠ¨æœ€ç»ˆæ±‚è§£ (Capacity Expanded)...\")\n",
    "solver.solve(time_limit=60, gap_rel=0.05)\n",
    "\n",
    "if solver.prob.status == 1:\n",
    "    print(f\"\\nğŸ† [GreenGrid æ‰©å®¹ç‰ˆå»ºè®¾æ–¹æ¡ˆ]\")\n",
    "    plan = []\n",
    "    for j in sites_ids:\n",
    "        if pulp.value(z[j]) > 0.5:\n",
    "            served = sum(traffic_map[i] for i in j_to_i_map.get(j, []) if pulp.value(y[(i,j)]) > 0.5)\n",
    "            plan.append({\n",
    "                'Site': j,\n",
    "                'Zone': df_sites.loc[df_sites['Site_ID']==j, 'Zone_Type'].values[0],\n",
    "                'Cap(Old)': round(row['Grid_Capacity_kW']/1.5, 1), # è¿˜åŸæ˜¾ç¤º\n",
    "                'Cap(New)': round(df_sites.loc[df_sites['Site_ID']==j, 'Grid_Capacity_kW'].values[0], 1),\n",
    "                'Fast': int(pulp.value(n_fast[j])),\n",
    "                'Slow': int(pulp.value(n_slow[j])),\n",
    "                'Traffic': round(served, 1)\n",
    "            })\n",
    "    df_res = pd.DataFrame(plan)\n",
    "    print(df_res.to_string(index=False))\n",
    "    \n",
    "    # è§¦å‘ Phase 5 å¯è§†åŒ–æ¥å£\n",
    "    print(\"\\nğŸ—ºï¸ [Visualization Ready]\")\n",
    "    print(\"   -> è¯·è°ƒç”¨: solver.visualize_routing(...) æŸ¥çœ‹æ‰©å®¹åçš„ç½‘ç»œå›¾\")\n",
    "else:\n",
    "    print(\"âŒ ä¾ç„¶æ— è§£ã€‚è¿™è¯´æ˜å•†ä¸šåŒºå¿«å……ç­–ç•¥ä¸æ‰©å®¹åçš„å®¹é‡ä»æœ‰å†²çªï¼Œå»ºè®®å½»åº•åºŸé™¤å•†ä¸šç­–ç•¥ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90627013-e62d-4783-80ad-9001bd534008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â˜¢ï¸ [Final Protocol] å¯åŠ¨ç»ˆæå¦¥åæ–¹æ¡ˆ...\n",
      "   - [æ‰©å®¹] æ‰©å®¹ç³»æ•°: 3.0x\n",
      "   - [å®¹é‡] å…¨ç½‘æé™å®¹é‡: 4000.0 (vs Demand: 4195.0)\n",
      "   - [ç­–ç•¥] å•†ä¸šåŒºå¿«å……ä¼˜å…ˆç­–ç•¥: âŒ å·²åºŸé™¤\n",
      "   - [å‚æ•°] æœåŠ¡ç³»æ•° (Service Coef): 3.5 -> 4.0\n",
      "\n",
      "ğŸš€ [Ultimate Launch] å¯åŠ¨æœ€ç»ˆæ±‚è§£...\n",
      "\n",
      "ğŸš€ å¯åŠ¨ MIP æ±‚è§£å™¨ (CBC)...\n",
      "   -> é™åˆ¶: Time < 60s, Gap < 5.0%\n",
      "ğŸ“‹ æ±‚è§£çŠ¶æ€: Infeasible\n",
      "ğŸš¨ è­¦å‘Š: æ¨¡å‹æ— è§£æˆ–æ— ç•Œï¼å¯åŠ¨è‡ªåŠ¨è¯Šæ–­...\n",
      "\n",
      "ğŸ” --- MIP è¯Šæ–­å»ºè®® ---\n",
      "1. **äº’æ–¥æ£€æŸ¥**: sum(x) == 1 æ˜¯å¦å› èµ„æºä¸è¶³æ— æ³•æ»¡è¶³ï¼Ÿ\n",
      "2. **Big-M**: M æ˜¯å¦è¿‡å°æˆªæ–­äº†å¯è¡ŒåŸŸï¼Ÿ\n",
      "3. **å»ºè®®**: å°è¯•å°† Integer æ”¹ä¸º Continuous æ±‚è§£ï¼Œå®šä½æ˜¯å¦ä¸ºæ•´æ•°æ€§å¯¼è‡´çš„æ— è§£ã€‚\n",
      "ğŸ’€ ä¾ç„¶æ— è§£ã€‚å»ºè®®æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨é€»è¾‘çŸ›ç›¾ï¼ˆå¦‚æŸäº›ç‚¹è·ç¦»æ‰€æœ‰ç«™ç‚¹éƒ½ > 35kmï¼‰ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ğŸ Phase 5: ç»ˆææ±‚è§£ (The Ultimate Solution)\n",
    "# ==========================================\n",
    "import pulp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(f\"\\nâ˜¢ï¸ [Final Protocol] å¯åŠ¨ç»ˆæå¦¥åæ–¹æ¡ˆ...\")\n",
    "\n",
    "# 1. æš´åŠ›æ‰©å®¹ (x3.0)\n",
    "# ------------------------------------------\n",
    "# é‡ç½®å®¹é‡ä¸ºåŸå§‹å€¼çš„ 3 å€\n",
    "df_sites['Grid_Capacity_kW'] = df_sites['Grid_Capacity_kW'] / 1.5 * 3.0  # è¿˜åŸåä¹˜3\n",
    "new_total_cap = 0\n",
    "for _, row in df_sites.iterrows():\n",
    "    # æŒ‰å…¨æ…¢å……è®¡ç®—æé™å®¹é‡\n",
    "    cap_kw = row['Grid_Capacity_kW']\n",
    "    max_slots = 50\n",
    "    max_power_slots = cap_kw / 7\n",
    "    new_total_cap += min(max_slots, max_power_slots) * 4.0 # ç³»æ•° 4.0\n",
    "\n",
    "print(f\"   - [æ‰©å®¹] æ‰©å®¹ç³»æ•°: 3.0x\")\n",
    "print(f\"   - [å®¹é‡] å…¨ç½‘æé™å®¹é‡: {new_total_cap:.1f} (vs Demand: 4195.0)\")\n",
    "print(f\"   - [ç­–ç•¥] å•†ä¸šåŒºå¿«å……ä¼˜å…ˆç­–ç•¥: âŒ å·²åºŸé™¤\")\n",
    "print(f\"   - [å‚æ•°] æœåŠ¡ç³»æ•° (Service Coef): 3.5 -> 4.0\")\n",
    "\n",
    "# 2. é‡å»ºæ¨¡å‹ (Clean Build)\n",
    "# ------------------------------------------\n",
    "solver = IP_Solver_Capsule(name=\"GreenGrid_Ultimate\", sense='min')\n",
    "\n",
    "# å˜é‡é‡å»º\n",
    "sites_ids = df_sites['Site_ID'].tolist()\n",
    "# ç¡®ä¿ valid_pairs å­˜åœ¨ (ä»ä¹‹å‰æ­¥éª¤ç»§æ‰¿)\n",
    "y_keys = [(p[0], p[1]) for p in valid_pairs] \n",
    "\n",
    "z = pulp.LpVariable.dicts(\"z\", sites_ids, cat='Binary')\n",
    "n_fast = pulp.LpVariable.dicts(\"n_fast\", sites_ids, lowBound=0, upBound=50, cat='Integer')\n",
    "n_slow = pulp.LpVariable.dicts(\"n_slow\", sites_ids, lowBound=0, upBound=50, cat='Integer')\n",
    "y = pulp.LpVariable.dicts(\"y\", y_keys, cat='Binary')\n",
    "\n",
    "# æ³¨å†Œå˜é‡\n",
    "solver.single_vars.update({'z': z, 'n_fast': n_fast, 'n_slow': n_slow})\n",
    "solver.matrix_vars['y'] = y\n",
    "solver.binary_vars.extend(z.values())\n",
    "solver.binary_vars.extend(y.values())\n",
    "\n",
    "# 3. çº¦æŸæ³¨å…¥ (Simplified Logic)\n",
    "# ------------------------------------------\n",
    "# A. åˆšæ€§æœåŠ¡\n",
    "i_to_j_map = {}\n",
    "for (i, j) in y_keys:\n",
    "    if i not in i_to_j_map: i_to_j_map[i] = []\n",
    "    i_to_j_map[i].append(j)\n",
    "\n",
    "demand_ids = df_demands_clean['Demand_ID'].unique()\n",
    "for i in demand_ids:\n",
    "    if i in i_to_j_map:\n",
    "        solver.prob += (pulp.lpSum(y[(i, j)] for j in i_to_j_map[i]) == 1, f\"Ult_Serve_{i}\")\n",
    "\n",
    "# B. ç‰©ç†ä¸ç”µç½‘ (ä¿ç•™)\n",
    "for idx, row in df_sites.iterrows():\n",
    "    j = row['Site_ID']\n",
    "    cap = row['Grid_Capacity_kW']\n",
    "    \n",
    "    # ç‰©ç†ä½\n",
    "    solver.prob += (n_fast[j] + n_slow[j] <= 50 * z[j], f\"Ult_Phy_{j}\")\n",
    "    # ç”µç½‘ç¡¬é™\n",
    "    solver.prob += (120 * n_fast[j] + 7 * n_slow[j] <= cap, f\"Ult_Grid_{j}\")\n",
    "    # Big-M\n",
    "    for i_demand in j_to_i_map.get(j, []):\n",
    "        solver.prob += (y[(i_demand, j)] <= z[j], f\"Ult_Logic_{i_demand}_{j}\")\n",
    "    \n",
    "    # [å…³é”®æ”¹å˜] ç§»é™¤äº†å•†ä¸šåŒº n_fast >= n_slow çº¦æŸ\n",
    "\n",
    "# C. ä¾›éœ€å¹³è¡¡ (ç³»æ•° 4.0)\n",
    "traffic_map = dict(zip(df_demands_clean['Demand_ID'], df_demands_clean['Daily_Traffic']))\n",
    "service_coef = 4.0 # Relaxed\n",
    "\n",
    "# æ„å»º j->i æ˜ å°„\n",
    "j_to_i_map = {}\n",
    "for (i, j) in y_keys:\n",
    "    if j not in j_to_i_map: j_to_i_map[j] = []\n",
    "    j_to_i_map[j].append(i)\n",
    "\n",
    "for j in sites_ids:\n",
    "    if j in j_to_i_map:\n",
    "        load = pulp.lpSum(y[(i,j)] * traffic_map[i] for i in j_to_i_map[j])\n",
    "        cap_service = service_coef * (n_fast[j] + n_slow[j])\n",
    "        solver.prob += (cap_service >= load, f\"Ult_Bal_{j}\")\n",
    "\n",
    "# D. ç›®æ ‡å‡½æ•°\n",
    "land_cost_map = dict(zip(df_sites['Site_ID'], df_sites.get('Land_Cost', 100)))\n",
    "obj = (pulp.lpSum(z[j] * land_cost_map[j] for j in sites_ids) + \n",
    "       pulp.lpSum(n_fast[j]*10 + n_slow[j]*2 for j in sites_ids) +\n",
    "       pulp.lpSum(valid_dist_dict[k] * y[k] * 0.1 for k in y_keys))\n",
    "solver.prob += obj\n",
    "\n",
    "# 4. æ±‚è§£ä¸äº¤ä»˜\n",
    "# ------------------------------------------\n",
    "print(f\"\\nğŸš€ [Ultimate Launch] å¯åŠ¨æœ€ç»ˆæ±‚è§£...\")\n",
    "solver.solve(time_limit=60, gap_rel=0.05)\n",
    "\n",
    "if solver.prob.status == 1:\n",
    "    print(f\"\\nğŸ† [GreenGrid ç»ˆæå»ºè®¾æ–¹æ¡ˆ]\")\n",
    "    plan = []\n",
    "    for j in sites_ids:\n",
    "        if pulp.value(z[j]) > 0.5:\n",
    "            served = sum(traffic_map[i] for i in j_to_i_map.get(j, []) if pulp.value(y[(i,j)]) > 0.5)\n",
    "            plan.append({\n",
    "                'Site': j,\n",
    "                'Zone': df_sites.loc[df_sites['Site_ID']==j, 'Zone_Type'].values[0],\n",
    "                'Cap(New)': int(df_sites.loc[df_sites['Site_ID']==j, 'Grid_Capacity_kW'].values[0]),\n",
    "                'Fast': int(pulp.value(n_fast[j])),\n",
    "                'Slow': int(pulp.value(n_slow[j])),\n",
    "                'Traffic': round(served, 1)\n",
    "            })\n",
    "    df_res = pd.DataFrame(plan)\n",
    "    # æŒ‰æµé‡é™åº\n",
    "    df_res = df_res.sort_values('Traffic', ascending=False)\n",
    "    print(df_res.to_string(index=False))\n",
    "    \n",
    "    # å¯¼å‡ºç»“æœ\n",
    "    solver.export_results()\n",
    "    \n",
    "    # å¯è§†åŒ–è·¯ç”±\n",
    "    try:\n",
    "        solver.export_routing_gephi(matrix_name='y')\n",
    "        # æ„å»º pos å­—å…¸ç”¨äºç»˜å›¾\n",
    "        pos_dict = {row['Site_ID']: (row['X'], row['Y']) for _, row in df_sites.iterrows()}\n",
    "        pos_dict.update({row['Demand_ID']: (row['X'], row['Y']) for _, row in df_demands_clean.iterrows()})\n",
    "        \n",
    "        # æå–è¢«é€‰ä¸­çš„ Site ID\n",
    "        active_sites = [r['Site'] for r in plan]\n",
    "        solver.visualize_routing(from_nodes=df_demands_clean['Demand_ID'], \n",
    "                                 to_nodes=active_sites, \n",
    "                                 active_matrix_name='y',\n",
    "                                 pos_dict=pos_dict)\n",
    "        print(\"\\nğŸ—ºï¸ å¯è§†åŒ–å·²ç”Ÿæˆ: Routing_Graph.svg (è¯·åœ¨æœ¬åœ°æŸ¥çœ‹)\")\n",
    "        print(\"ğŸ•¸ï¸ Gephi æ•°æ®å·²ç”Ÿæˆ: Routing_Flow_Gephi.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"ğŸ’€ ä¾ç„¶æ— è§£ã€‚å»ºè®®æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨é€»è¾‘çŸ›ç›¾ï¼ˆå¦‚æŸäº›ç‚¹è·ç¦»æ‰€æœ‰ç«™ç‚¹éƒ½ > 35kmï¼‰ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a727f6-4051-4ed1-b740-d40a756ff9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
