{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9c1cde-a2fb-4219-92b6-c7f24540d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "# --- V7.0 ç»˜å›¾ç¾å­¦é…ç½® (Aesthetic Setup) ---\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'SimHei'] # é€‚é…ä¸­è‹±æ–‡\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "try:\n",
    "    import scienceplots\n",
    "    plt.style.use(['science', 'no-latex']) # å­¦æœ¯é£æ ¼\n",
    "except ImportError:\n",
    "    # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ Seaborn ä¼˜åŒ–\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"deep\", context=\"paper\")\n",
    "\n",
    "class Graph_Solver_Capsule:\n",
    "    def __init__(self, name=\"Graph_Model\", is_directed=False):\n",
    "        \"\"\"\n",
    "        [MCM Graph Solver V7.0 - Final Version]\n",
    "        æ¶æ„: 1.Audit -> 2.Metrics -> 3.Deep Analysis -> 4.Auto-Delivery\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.is_directed = is_directed\n",
    "        self.timestamp = int(time.time())\n",
    "        self.G = None\n",
    "        \n",
    "        # ç»“æœå­˜å‚¨å®¹å™¨\n",
    "        self.node_metrics = pd.DataFrame()\n",
    "        self.robustness_log = {} # è®°å½•æ”»å‡»æµ‹è¯•çš„å…³é”®ç»“è®º\n",
    "        \n",
    "        # è‡ªåŠ¨åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "        self.output_dir = f\"./Results_{name}_{self.timestamp}\"\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 0: æ¡æ‰‹ä¸åè®® (Setup & Handshake)\n",
    "    # ======================================================\n",
    "    def generate_handshake(self, df_dict=None):\n",
    "        print(f\"\\nğŸ¤ === å¤åˆ¶ä»¥ä¸‹ Prompt å‘é€ç»™ AI (V7.0 Graph) ===\\n\")\n",
    "        print(f\"ã€ç³»ç»Ÿè®¾å®šã€‘\\næˆ‘æ­£åœ¨ä½¿ç”¨ `Graph_Solver_Capsule` (V7.0)ã€‚\")\n",
    "        print(f\"å›¾ç±»å‹: {'æœ‰å‘å›¾ (DiGraph)' if self.is_directed else 'æ— å‘å›¾ (Graph)'}ã€‚\")\n",
    "        print(f\"è¾“å‡ºç›®å½•: `{self.output_dir}`\")\n",
    "        \n",
    "        print(\"\\nã€API æ¥å£æ¸…å•ã€‘\")\n",
    "        print(\"1. æ„å»º: solver.build_from_edgelist(df, source='S', target='T', weight='W')\")\n",
    "        print(\"2. è‡ªæ£€: solver.audit() # å¿…é¡»æ‰§è¡Œï¼Œé€»è¾‘è‡ªæ£€\")\n",
    "        print(\"3. æŒ‡æ ‡: solver.compute_centrality()\")\n",
    "        print(\"4. [æ ¸æ­¦å™¨] ç¤¾å›¢: solver.detect_communities(method='louvain')\")\n",
    "        print(\"5. [æ ¸æ­¦å™¨] é²æ£’æ€§: solver.analyze_robustness(attack_type='targeted', fraction=0.3)\")\n",
    "        print(\"6. [å¯è§†åŒ–] ç»˜å›¾: solver.plot_network(layout='kamada_kawai')\")\n",
    "        print(\"7. [äº¤ä»˜] å¯¼å‡º: solver.export_results() # ç”Ÿæˆå…¨å¥—äº¤ä»˜ç‰©\")\n",
    "        \n",
    "        print(\"\\nã€âš ï¸ å¿…é¡»æ³¨æ„çš„å›¾è®ºé™·é˜±ã€‘\")\n",
    "        print(\"1. **è´Ÿæƒè¾¹ (Negative Weights)**: å¦‚å­˜åœ¨ï¼ŒDijkstra å¤±æ•ˆï¼Œè¯·æç¤ºä½¿ç”¨ Bellman-Fordã€‚\")\n",
    "        print(\"2. **è¿é€šæ€§ (Connectivity)**: è‹¥å›¾ä¸è¿é€šï¼ŒGlobal Efficiency æ— ç‰©ç†æ„ä¹‰ã€‚å»ºè®®æå– LCC (Largest Connected Component)ã€‚\")\n",
    "        print(\"3. **å¼º/å¼±è¿é€š**: æœ‰å‘å›¾ä¸­è¯·åŒºåˆ† Strong (åŒå‘å¯è¾¾) vs Weak (å¿½ç•¥æ–¹å‘)ã€‚\")\n",
    "        \n",
    "        if df_dict:\n",
    "            print(\"\\nã€æ•°æ®æ‘˜è¦ã€‘\")\n",
    "            for name, df in df_dict.items():\n",
    "                print(f\"Dataset '{name}': {list(df.columns)} | Rows: {len(df)}\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 1: æ„å»ºä¸è‡ªæ£€ (Build & Audit)\n",
    "    # ======================================================\n",
    "    def build_from_edgelist(self, df, source, target, weight=None):\n",
    "        print(f\"\\nğŸ—ï¸ æ­£åœ¨æ„å»ºç½‘ç»œ...\")\n",
    "        create_using = nx.DiGraph() if self.is_directed else nx.Graph()\n",
    "        \n",
    "        try:\n",
    "            # è‡ªåŠ¨å¤„ç†åˆ—åç©ºæ ¼é—®é¢˜\n",
    "            self.G = nx.from_pandas_edgelist(df, source=source, target=target, edge_attr=weight, create_using=create_using)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æ„å»ºå¤±è´¥: {e}\")\n",
    "            return\n",
    "\n",
    "        print(f\"âœ… ç½‘ç»œæ„å»ºå®Œæˆã€‚Nodes: {self.G.number_of_nodes()}, Edges: {self.G.number_of_edges()}\")\n",
    "        # åˆå§‹åŒ–æŒ‡æ ‡è¡¨\n",
    "        self.node_metrics = pd.DataFrame(index=list(self.G.nodes()))\n",
    "        self.node_metrics.index.name = 'Node_ID'\n",
    "\n",
    "    def audit(self):\n",
    "        print(\"\\nğŸ›¡ï¸ === é€»è¾‘å®¡è®¡ (Network Audit) =====\")\n",
    "        if self.G is None: raise ValueError(\"âŒ å›¾æœªæ„å»ºã€‚\")\n",
    "        \n",
    "        # 1. è¿é€šæ€§æ£€æŸ¥\n",
    "        if self.is_directed:\n",
    "            n_comp = nx.number_strongly_connected_components(self.G)\n",
    "            n_weak = nx.number_weakly_connected_components(self.G)\n",
    "            print(f\"info: å¼ºè¿é€šåˆ†é‡: {n_comp}, å¼±è¿é€šåˆ†é‡: {n_weak}\")\n",
    "            if n_weak > 1: print(\"âš ï¸ è­¦å‘Š: ç½‘ç»œä¸æ˜¯(å¼±)è¿é€šçš„ï¼\")\n",
    "        else:\n",
    "            n_comp = nx.number_connected_components(self.G)\n",
    "            print(f\"info: è¿é€šåˆ†é‡: {n_comp}\")\n",
    "            if n_comp > 1:\n",
    "                largest = len(max(nx.connected_components(self.G), key=len))\n",
    "                ratio = largest / len(self.G)\n",
    "                print(f\"âš ï¸ è­¦å‘Š: ç½‘ç»œä¸è¿é€šï¼æœ€å¤§è¿é€šå­å›¾(LCC)å æ¯”: {ratio:.1%}\")\n",
    "                print(\"ğŸ’¡ å»ºè®®: åœ¨è®ºæ–‡ä¸­å£°æ˜â€œåç»­åˆ†æåŸºäºæœ€å¤§è¿é€šå­å›¾(LCC)â€ã€‚\")\n",
    "\n",
    "        # 2. å­¤ç«‹ç‚¹\n",
    "        isolates = list(nx.isolates(self.G))\n",
    "        if isolates:\n",
    "            print(f\"âš ï¸ è­¦å‘Š: å‘ç° {len(isolates)} ä¸ªå­¤ç«‹ç‚¹ (Isolates)ã€‚å»ºè®®é¢„å¤„ç†ç§»é™¤ã€‚\")\n",
    "            \n",
    "        # 3. è‡ªç¯\n",
    "        loops = list(nx.selfloop_edges(self.G))\n",
    "        if loops:\n",
    "            print(f\"âš ï¸ è­¦å‘Š: å‘ç° {len(loops)} æ¡è‡ªç¯ã€‚\")\n",
    "        \n",
    "        print(\"âœ… å®¡è®¡ç»“æŸã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 2: åŸºç¡€æŒ‡æ ‡ (Metrics)\n",
    "    # ======================================================\n",
    "    def compute_centrality(self):\n",
    "        print(f\"\\nğŸ“ è®¡ç®—ä¸­å¿ƒåº¦æŒ‡æ ‡...\")\n",
    "        \n",
    "        # Degree\n",
    "        if self.is_directed:\n",
    "            self.node_metrics['In_Degree'] = pd.Series(nx.in_degree_centrality(self.G))\n",
    "            self.node_metrics['Out_Degree'] = pd.Series(nx.out_degree_centrality(self.G))\n",
    "        else:\n",
    "            self.node_metrics['Degree'] = pd.Series(nx.degree_centrality(self.G))\n",
    "            \n",
    "        # Betweenness (å¤§å›¾ä¼˜åŒ–ï¼šé‡‡æ ·)\n",
    "        if len(self.G) > 2000:\n",
    "            print(\"âš ï¸ è­¦å‘Š: èŠ‚ç‚¹æ•°>2000ï¼Œå¯ç”¨ k=100 é‡‡æ ·åŠ é€Ÿè®¡ç®— Betweennessã€‚\")\n",
    "            bet = nx.betweenness_centrality(self.G, k=100)\n",
    "        else:\n",
    "            bet = nx.betweenness_centrality(self.G)\n",
    "        self.node_metrics['Betweenness'] = pd.Series(bet)\n",
    "        \n",
    "        # Closeness\n",
    "        self.node_metrics['Closeness'] = pd.Series(nx.closeness_centrality(self.G))\n",
    "        \n",
    "        # Eigenvector (å¤„ç†ä¸æ”¶æ•›)\n",
    "        try:\n",
    "            eig = nx.eigenvector_centrality(self.G, max_iter=600)\n",
    "            self.node_metrics['Eigenvector'] = pd.Series(eig)\n",
    "        except:\n",
    "            print(\"âš ï¸ Eigenvector æœªæ”¶æ•›ï¼Œå¡«å…… 0ã€‚\")\n",
    "            self.node_metrics['Eigenvector'] = 0.0\n",
    "\n",
    "        print(\"âœ… åŸºç¡€æŒ‡æ ‡å·²å­˜å…¥ self.node_metricsã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 3: æ·±åº¦åˆ†æ (Deep Analysis - Oå¥–æ ¸æ­¦å™¨)\n",
    "    # ======================================================\n",
    "    def detect_communities(self, method='louvain'):\n",
    "        print(f\"\\nğŸ§© å¯åŠ¨ç¤¾å›¢æ£€æµ‹ (Method: {method})...\")\n",
    "        if method == 'louvain':\n",
    "            try:\n",
    "                import community.community_louvain as community_louvain\n",
    "                # Louvain éœ€è½¬æ— å‘\n",
    "                g_temp = self.G.to_undirected() if self.is_directed else self.G\n",
    "                partition = community_louvain.best_partition(g_temp)\n",
    "                modularity = community_louvain.modularity(partition, g_temp)\n",
    "                \n",
    "                self.node_metrics['Community_ID'] = self.node_metrics.index.map(partition)\n",
    "                print(f\"âœ… ç¤¾å›¢åˆ’åˆ†å®Œæˆ (Louvain)ã€‚Modularity Q={modularity:.4f}\")\n",
    "                print(f\"   å…±å‘ç° {len(set(partition.values()))} ä¸ªç¤¾å›¢ã€‚\")\n",
    "                return modularity\n",
    "            except ImportError:\n",
    "                print(\"âŒ æœªå®‰è£… `python-louvain`ã€‚è¯· pip install python-louvainã€‚\")\n",
    "        else:\n",
    "            print(\"âš ï¸ ç›®å‰ä»…å°è£…äº† Louvain ç®—æ³•ã€‚\")\n",
    "\n",
    "    def analyze_robustness(self, attack_type='targeted', fraction=0.3):\n",
    "        \"\"\"\n",
    "        [æ ¸æ­¦å™¨] é²æ£’æ€§åˆ†æ\n",
    "        è¾“å‡ºï¼šRobustness_Curve.svg\n",
    "        \"\"\"\n",
    "        print(f\"\\nğŸ’£ å¯åŠ¨é²æ£’æ€§åˆ†æ (Type: {attack_type}, Remove: {fraction*100:.0f}%)...\")\n",
    "        \n",
    "        # 1. å‡†å¤‡å‰¯æœ¬ (è½¬æ— å‘ä»¥åˆ†æè¿é€šæ€§)\n",
    "        G_sim = self.G.copy()\n",
    "        if self.is_directed: G_sim = G_sim.to_undirected()\n",
    "        \n",
    "        N = G_sim.number_of_nodes()\n",
    "        remove_count = int(N * fraction)\n",
    "        \n",
    "        # 2. ç¡®å®šç§»é™¤åˆ—è¡¨\n",
    "        if attack_type == 'targeted':\n",
    "            # æŒ‰åº¦é™åº (è“„æ„æ”»å‡»)\n",
    "            nodes_sorted = sorted(G_sim.degree, key=lambda x: x[1], reverse=True)\n",
    "            targets = [n[0] for n in nodes_sorted]\n",
    "        else:\n",
    "            # éšæœºä¹±åº (éšæœºæ•…éšœ)\n",
    "            targets = list(G_sim.nodes())\n",
    "            random.shuffle(targets)\n",
    "            \n",
    "        targets = targets[:remove_count]\n",
    "        \n",
    "        # 3. æ¨¡æ‹Ÿæ”»å‡» (ä½¿ç”¨ np.linspace å‡å°‘ç»˜å›¾ç‚¹æ•°ï¼Œæé«˜æ•ˆç‡)\n",
    "        steps = np.unique(np.linspace(0, remove_count, 25, dtype=int))\n",
    "        \n",
    "        history = {'Removed_Pct': [], 'Giant_Component': [], 'Efficiency': []}\n",
    "        \n",
    "        # è®¡ç®—åŸºå‡†æ•ˆç‡ (å¤§å›¾è·³è¿‡)\n",
    "        calc_eff = N < 1500\n",
    "        base_eff = nx.global_efficiency(G_sim) if calc_eff else 1.0\n",
    "        \n",
    "        current_removed = 0\n",
    "        for target_count in steps:\n",
    "            # ç§»é™¤å¢é‡\n",
    "            to_remove = target_count - current_removed\n",
    "            if to_remove > 0:\n",
    "                nodes_to_drop = targets[current_removed : target_count]\n",
    "                G_sim.remove_nodes_from(nodes_to_drop)\n",
    "                current_removed = target_count\n",
    "            \n",
    "            # è®°å½• X è½´\n",
    "            history['Removed_Pct'].append(current_removed / N)\n",
    "            \n",
    "            # è®°å½• Y1: æœ€å¤§è¿é€šå­å›¾å æ¯”\n",
    "            if len(G_sim) > 0:\n",
    "                lc = len(max(nx.connected_components(G_sim), key=len))\n",
    "                history['Giant_Component'].append(lc / N)\n",
    "            else:\n",
    "                history['Giant_Component'].append(0)\n",
    "                \n",
    "            # è®°å½• Y2: å…¨å±€æ•ˆç‡ (ç›¸å¯¹å€¼)\n",
    "            if calc_eff:\n",
    "                eff = nx.global_efficiency(G_sim)\n",
    "                history['Efficiency'].append(eff / base_eff)\n",
    "            else:\n",
    "                history['Efficiency'].append(0)\n",
    "                \n",
    "        # 4. ç»˜å›¾\n",
    "        df_res = pd.DataFrame(history)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(df_res['Removed_Pct'], df_res['Giant_Component'], 'o-', label='Giant Component Size', color='#d62728', lw=2)\n",
    "        if calc_eff:\n",
    "            plt.plot(df_res['Removed_Pct'], df_res['Efficiency'], 's--', label='Global Efficiency', color='#1f77b4', lw=2)\n",
    "            \n",
    "        plt.title(f\"Network Robustness: {attack_type.title()} Attack\")\n",
    "        plt.xlabel(\"Fraction of Nodes Removed\")\n",
    "        plt.ylabel(\"Relative Metric Score\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(f\"{self.output_dir}/Robustness_Curve_{attack_type}.svg\", dpi=300)\n",
    "        plt.show()\n",
    "        \n",
    "        # è®°å½•ç»“è®º\n",
    "        collapse_val = df_res[df_res['Giant_Component'] < 0.5].iloc[0]['Removed_Pct'] if (df_res['Giant_Component'] < 0.5).any() else 1.0\n",
    "        self.robustness_log[attack_type] = collapse_val\n",
    "        print(f\"âœ… é²æ£’æ€§åˆ†æå®Œæˆã€‚å´©æºƒç‚¹ (GC<0.5) çº¦åœ¨ç§»é™¤ {collapse_val:.1%} èŠ‚ç‚¹æ—¶ã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 4: é¡¶çº§å¯è§†åŒ– (Visualization)\n",
    "    # ======================================================\n",
    "    def plot_network(self, layout='kamada_kawai'):\n",
    "        print(f\"\\nğŸ¨ ç»˜åˆ¶ç½‘ç»œå›¾ (Layout: {layout})...\")\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        \n",
    "        # 1. å¸ƒå±€å®‰å…¨é™çº§é€»è¾‘ (é˜²æ­¢ Kamada-Kawai å¡æ­»)\n",
    "        pos = None\n",
    "        if layout == 'kamada_kawai':\n",
    "            if len(self.G) > 1000:\n",
    "                print(\"âš ï¸ èŠ‚ç‚¹æ•° > 1000ï¼Œå¼ºåˆ¶é™çº§ä¸º spring_layout ä»¥é˜²å¡æ­»ã€‚\")\n",
    "                pos = nx.spring_layout(self.G, seed=42)\n",
    "            else:\n",
    "                try:\n",
    "                    pos = nx.kamada_kawai_layout(self.G)\n",
    "                except:\n",
    "                    pos = nx.spring_layout(self.G, seed=42)\n",
    "        else:\n",
    "            pos = nx.spring_layout(self.G, seed=42)\n",
    "            \n",
    "        # 2. æ ·å¼æ˜ å°„\n",
    "        deg = dict(self.G.degree())\n",
    "        # å¤§å°å½’ä¸€åŒ–\n",
    "        sizes = [v * 5 + 30 for v in deg.values()] \n",
    "        \n",
    "        # é¢œè‰²æ˜ å°„ (ç¤¾å›¢ or é»˜è®¤)\n",
    "        if 'Community_ID' in self.node_metrics.columns:\n",
    "            colors = self.node_metrics.loc[list(self.G.nodes()), 'Community_ID']\n",
    "            cmap = 'tab20'\n",
    "        else:\n",
    "            colors = '#69b3a2'\n",
    "            cmap = None\n",
    "            \n",
    "        # 3. ç»˜åˆ¶\n",
    "        nx.draw_networkx_nodes(self.G, pos, node_size=sizes, node_color=colors, cmap=cmap, alpha=0.9, edgecolors='white')\n",
    "        nx.draw_networkx_edges(self.G, pos, alpha=0.2, edge_color='gray')\n",
    "        \n",
    "        # 4. æ™ºèƒ½æ ‡ç­¾ (ä»… Top 10)\n",
    "        top_nodes = sorted(deg.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        for node, val in top_nodes:\n",
    "            x, y = pos[node]\n",
    "            plt.text(x, y+0.03, str(node), fontsize=11, fontweight='bold', ha='center', \n",
    "                     bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=1))\n",
    "\n",
    "        plt.title(f\"Network Visualization ({self.name})\", fontsize=16)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"{self.output_dir}/Network_Viz.svg\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    def export_to_gephi(self):\n",
    "        try:\n",
    "            # å±æ€§æ³¨å…¥ (ç±»å‹è½¬æ¢é˜²æ­¢æŠ¥é”™)\n",
    "            for col in self.node_metrics.columns:\n",
    "                attrs = {k: float(v) if isinstance(v, float) else int(v) \n",
    "                         for k, v in self.node_metrics[col].to_dict().items()}\n",
    "                nx.set_node_attributes(self.G, attrs, col)\n",
    "            nx.write_gexf(self.G, f\"{self.output_dir}/{self.name}.gexf\")\n",
    "            print(\"âœ… Gephi æ–‡ä»¶å·²ç”Ÿæˆ (.gexf)ã€‚\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Gephi å¯¼å‡ºè·³è¿‡: {e}\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 5: äº¤ä»˜ (Delivery)\n",
    "    # ======================================================\n",
    "    def export_results(self):\n",
    "        print(f\"\\nğŸ“¦ === ç”Ÿæˆäº¤ä»˜ç‰©è‡³ {self.output_dir} === \")\n",
    "        \n",
    "        # 1. Excel\n",
    "        self.node_metrics.to_excel(f\"{self.output_dir}/Node_Metrics.xlsx\")\n",
    "        \n",
    "        # 2. Gephi\n",
    "        self.export_to_gephi()\n",
    "        \n",
    "        # 3. æ™ºèƒ½æˆ˜æŠ¥ (Auto-Report.md)\n",
    "        report = f\"# V7.0 Graph Analysis Report: {self.name}\\n\\n\"\n",
    "        \n",
    "        report += \"## 1. Network Summary\\n\"\n",
    "        report += f\"- **Type**: {'Directed' if self.is_directed else 'Undirected'}\\n\"\n",
    "        report += f\"- **Nodes**: {self.G.number_of_nodes()}, **Edges**: {self.G.number_of_edges()}\\n\"\n",
    "        report += f\"- **Density**: {nx.density(self.G):.4f}\\n\\n\"\n",
    "        \n",
    "        report += \"## 2. Key Insights\\n\"\n",
    "        if not self.node_metrics.empty:\n",
    "            # æ‰¾å‡ºæŒ‡æ ‡æœ€é«˜çš„èŠ‚ç‚¹\n",
    "            col = 'Degree' if 'Degree' in self.node_metrics else 'In_Degree'\n",
    "            top_deg = self.node_metrics[col].idxmax()\n",
    "            report += f\"* **Hub Node**: Node `{top_deg}` has the highest degree centrality.\\n\"\n",
    "            \n",
    "            if 'Betweenness' in self.node_metrics:\n",
    "                top_bet = self.node_metrics['Betweenness'].idxmax()\n",
    "                report += f\"* **Bridge Node**: Node `{top_bet}` has the highest betweenness, controlling flow.\\n\"\n",
    "                \n",
    "            if 'Community_ID' in self.node_metrics.columns:\n",
    "                n_comm = self.node_metrics['Community_ID'].nunique()\n",
    "                report += f\"* **Community Structure**: The network divides into **{n_comm}** communities (Louvain).\\n\"\n",
    "        \n",
    "        if self.robustness_log:\n",
    "            report += \"\\n## 3. Resilience Analysis (Robustness)\\n\"\n",
    "            for atk, val in self.robustness_log.items():\n",
    "                status = \"Fragile\" if val < 0.1 else (\"Robust\" if val > 0.4 else \"Moderate\")\n",
    "                report += f\"* Under **{atk} attack**, the network collapses (Giant Component < 50%) after removing **{val:.1%}** of nodes. Rating: **{status}**.\\n\"\n",
    "        \n",
    "        with open(f\"{self.output_dir}/Report.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(report)\n",
    "            \n",
    "        print(f\"âœ… [1] æ•°æ®è¡¨: Node_Metrics.xlsx\")\n",
    "        print(f\"âœ… [2] çŸ¢é‡å›¾: Network_Viz.svg, Robustness_*.svg\")\n",
    "        print(f\"âœ… [3] äº¤äº’æ–‡ä»¶: {self.name}.gexf\")\n",
    "        print(f\"âœ… [4] æ™ºèƒ½æˆ˜æŠ¥: Report.md (å«è‡ªåŠ¨ç»“è®º)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
