{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0143d9c8-a7b9-4b26-937a-3312edd03cf3",
   "metadata": {},
   "source": [
    "## âœ… V7.0 éœ€æ±‚éªŒæ”¶æ¸…å• (Checklist)\n",
    "\n",
    "| æ¨¡å— | æ ¸å¿ƒéœ€æ±‚ | éªŒæ”¶ç»“æœ | V7.0 å¢å¼ºç‰¹æ€§ |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **1. æ¡æ‰‹ä¸é˜²å¾¡** | `generate_handshake` | âœ… Pass | æ˜ç¡®è­¦å‘Š **MIP å½±å­ä»·æ ¼å¤±æ•ˆ**ï¼›éçº¿æ€§é™·é˜±é¢„è­¦ï¼›è‡ªåŠ¨æ£€æµ‹ Solver å®‰è£…ã€‚ |\n",
    "| **2. å»ºæ¨¡å·¥å‚** | `add_var_batch` | âœ… Pass | **æ™ºèƒ½è¿½è¸ªå˜é‡ç±»å‹** (`is_mip` æ ‡å¿—ä½)ï¼›æ”¯æŒé«˜æ•ˆçš„å­—å…¸å˜é‡ç”Ÿæˆã€‚ |\n",
    "| **3. æ±‚è§£ä¸è‡ªæ„ˆ** | `solve` | âœ… Pass | **Infeasible è¯Šæ–­å›è·¯**ï¼šæ±‚è§£å¤±è´¥æ—¶è‡ªåŠ¨å»ºè®®æ£€æŸ¥ RHSï¼›é›†æˆæ–­ç‚¹ç»­ä¼ ã€‚ |\n",
    "| **4. æ ¸æ­¦å™¨ I** | **èµ„æºç“¶é¢ˆ (Shadow Price)** | âœ… Pass | **LP ä¸“å±**ï¼šè‡ªåŠ¨ç»˜åˆ¶ç“¶é¢ˆçƒ­åŠ›å›¾ï¼Œè¯†åˆ«ç´§ç¼ºèµ„æºã€‚ |\n",
    "| **5. æ ¸æ­¦å™¨ II** | **çœŸÂ·é²æ£’æ€§ (Robustness)** | âœ… Pass | **çœŸå® Monte Carlo**ï¼šä¿®å¤äº†ä¼ªéšæœºé€»è¾‘ï¼Œå®æ–½â€œæ‰°åŠ¨ç³»æ•°$\\to$é‡ç®—$\\to$åˆ†å¸ƒç»Ÿè®¡â€çš„çœŸå®å‹åŠ›æµ‹è¯•ã€‚ |\n",
    "| **6. æ ¸æ­¦å™¨ III** | **å¸•ç´¯æ‰˜å‰æ²¿ (Pareto)** | âœ… Pass | **å¤šç›®æ ‡æƒè¡¡**ï¼šè‡ªåŠ¨æ‰«æåŒç›®æ ‡ Trade-off æ›²çº¿ï¼Œå¯»æ‰¾æœ€ä½³æŠ˜è¡·ç‚¹ã€‚ |\n",
    "| **7. äº¤ä»˜** | `export_results` | âœ… Pass | ä¿®å¤ Pandas LaTeX å…¼å®¹æ€§ï¼›è‡ªåŠ¨ç”Ÿæˆæ™ºèƒ½æˆ˜æŠ¥ (`Report.md`)ã€‚ |\n",
    "| **8. é™„å½•åè®®** | **ç½‘ç»œæµå¯è§†åŒ– (Gephi)** | ğŸ†• Added | æ–°å¢ `export_flow_gephi`ï¼šé’ˆå¯¹ç‰©æµ/ç½‘ç»œé¢˜ï¼Œå°†æœ€ä¼˜è·¯å¾„å¯¼å‡ºä¸ºè¾¹è¡¨ï¼Œä¾› Gephi ç»˜åˆ¶æµå‘å›¾ã€‚ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c2a187e-4bb2-43fd-991c-2e65690c2790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pulp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "# --- V7.0 ç»˜å›¾ç¾å­¦é…ç½® ---\n",
    "# ç»˜å›¾å¿…é¡»ç¾è§‚\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'SimHei'] \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "try:\n",
    "    import scienceplots\n",
    "    plt.style.use(['science', 'no-latex'])\n",
    "except ImportError:\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"deep\", context=\"paper\")\n",
    "\n",
    "class Opt_Solver_Capsule:\n",
    "    def __init__(self, name=\"Optimization_Model\", sense='min'):\n",
    "        \"\"\"\n",
    "        [MCM Opt Solver V7.0 - Final Verified]\n",
    "        Core: LP & MIP (Linear/Integer)\n",
    "        Features: Auto-Diagnosis, Shadow Price, Robustness, Pareto, Network Flow Export\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.timestamp = int(time.time())\n",
    "        self.sense = pulp.LpMinimize if sense.lower() == 'min' else pulp.LpMaximize\n",
    "        \n",
    "        # åˆå§‹åŒ–æ¨¡å‹\n",
    "        self.prob = pulp.LpProblem(self.name, self.sense)\n",
    "        \n",
    "        # å®¹å™¨\n",
    "        self.var_dict = {}       # å­˜å‚¨å˜é‡å­—å…¸ (ç”¨äºGephiå¯¼å‡º)\n",
    "        self.constraints = {}    # å­˜å‚¨æ˜¾å¼å‘½åçš„çº¦æŸ\n",
    "        self.history = []        # æ±‚è§£å†å²\n",
    "        self.is_mip = False      # æ˜¯å¦åŒ…å«æ•´æ•°å˜é‡\n",
    "        \n",
    "        # è‡ªåŠ¨åˆ›å»ºè¾“å‡ºç›®å½• \n",
    "        self.output_dir = f\"./Results_{name}_{self.timestamp}\"\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 0: æ„é€ ä¸åå‘æ¡æ‰‹ (Handshake)\n",
    "    # ======================================================\n",
    "    def generate_handshake(self):\n",
    "        \"\"\" Self-Describing Handshake \"\"\"\n",
    "        print(f\"\\nğŸ¤ === å¤åˆ¶ä»¥ä¸‹ Prompt å‘é€ç»™ AI (V7.0 Opt) ===\\n\")\n",
    "        print(f\"ã€ç³»ç»Ÿè®¾å®šã€‘\\næˆ‘æ­£åœ¨ä½¿ç”¨ `Opt_Solver_Capsule` (V7.0)ã€‚\")\n",
    "        print(f\"ç›®æ ‡æ–¹å‘: {'Minimize' if self.sense == 1 else 'Maximize'}\")\n",
    "        print(f\"è¾“å‡ºç›®å½•: `{self.output_dir}`\")\n",
    "        \n",
    "        print(\"\\nã€API æ¥å£æ¸…å•ã€‘\")\n",
    "        print(\"1. å˜é‡å·¥å‚: solver.add_var_batch(keys, low=0, up=None, cat='Continuous', name_prefix='x')\")\n",
    "        print(\"2. å¢åŠ çº¦æŸ: solver.add_constraint(expr, sense='<=', rhs=100, name='Res_Limit')\")\n",
    "        print(\"3. è®¾ç›®æ ‡å‡½: solver.set_objective(expr)\")\n",
    "        print(\"4. æ±‚è§£è‡ªæ„ˆ: solver.solve(solver_name='CBC')\")\n",
    "        print(\"5. [LPæ ¸æ­¦å™¨] å½±å­ä»·æ ¼: solver.analyze_shadow_prices(top_k=5)\")\n",
    "        print(\"6. [é²æ£’æ€§] è’™ç‰¹å¡æ´›: solver.analyze_robustness(perturb_range=0.1)\")\n",
    "        print(\"7. [å¤šç›®æ ‡] å¸•ç´¯æ‰˜: solver.scan_pareto_frontier(obj1, obj2)\")\n",
    "        print(\"8. [å¯è§†åŒ–] ç½‘ç»œæµå¯¼å‡º: solver.export_flow_gephi(var_name_prefix='Trans')\")\n",
    "        print(\"9. [äº¤ä»˜] å¯¼å‡º: solver.export_results()\")\n",
    "        \n",
    "        print(\"\\nã€âš ï¸ ä¼˜åŒ–æ¨¡å‹æ•°å­¦é™·é˜±ã€‘\")\n",
    "        print(\"1. **å½±å­ä»·æ ¼**: ä»…é™ LP æ¨¡å‹ã€‚è‹¥åŒ…å«æ•´æ•°å˜é‡ï¼Œæ­¤åŠŸèƒ½å°†è‡ªåŠ¨å±è”½ã€‚\")\n",
    "        print(\"2. **æ— è§£**: è‹¥ solve() è¿”å› Infeasibleï¼Œè¯·æ ¹æ®ç³»ç»Ÿæç¤ºæ£€æŸ¥çº¦æŸ RHSã€‚\")\n",
    "        print(\"3. **éçº¿æ€§**: ä¸¥ç¦ä½¿ç”¨ sin/cos/exp ç­‰éçº¿æ€§å‡½æ•°ã€‚\")\n",
    "\n",
    "    def audit(self):\n",
    "        \"\"\" Logic Audit \"\"\"\n",
    "        print(\"\\nğŸ›¡ï¸ === æ¨¡å‹å®¡è®¡ (Model Audit) =====\")\n",
    "        var_count = len(self.prob.variables())\n",
    "        const_count = len(self.prob.constraints)\n",
    "        print(f\"å˜é‡æ•°é‡: {var_count}\")\n",
    "        print(f\"çº¦æŸæ•°é‡: {const_count}\")\n",
    "        \n",
    "        if var_count == 0: raise ValueError(\"âŒ æ¨¡å‹ä¸ºç©ºï¼šæœªæ·»åŠ ä»»ä½•å˜é‡ã€‚\")\n",
    "        if const_count == 0: print(\"âš ï¸ è­¦å‘Š: æ¨¡å‹æ²¡æœ‰çº¦æŸæ¡ä»¶ã€‚\")\n",
    "        print(\"âœ… å®¡è®¡é€šè¿‡ã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 1: å»ºæ¨¡å·¥å‚ (Modeling Factory)\n",
    "    # ======================================================\n",
    "    def add_var_batch(self, keys, low=0, up=None, cat='Continuous', name_prefix=\"x\"):\n",
    "        \"\"\"\n",
    "        æ‰¹é‡åˆ›å»ºå˜é‡ã€‚\n",
    "        keys: é€šå¸¸ä¸º tuple åˆ—è¡¨ (source, target) ç”¨äºç½‘ç»œæµï¼Œæˆ–ç®€å•åˆ—è¡¨ã€‚\n",
    "        \"\"\"\n",
    "        if cat in ['Integer', 'Binary']:\n",
    "            self.is_mip = True\n",
    "            \n",
    "        vars_dict = pulp.LpVariable.dicts(name_prefix, keys, lowBound=low, upBound=up, cat=cat)\n",
    "        # å­˜å‚¨å¼•ç”¨ä»¥ä¾¿åç»­ Gephi å¯¼å‡º\n",
    "        self.var_dict[name_prefix] = vars_dict\n",
    "        print(f\"âœ… å·²æ³¨å†Œå˜é‡æ‰¹æ¬¡: {name_prefix} (æ•°é‡: {len(keys)}, ç±»å‹: {cat})\")\n",
    "        return vars_dict\n",
    "\n",
    "    def add_constraint(self, expr, sense, rhs, name):\n",
    "        \"\"\" å°è£…çº¦æŸï¼Œå¼ºåˆ¶å‘½å \"\"\"\n",
    "        if sense == '<=': c = (expr <= rhs)\n",
    "        elif sense == '>=': c = (expr >= rhs)\n",
    "        elif sense == '==': c = (expr == rhs)\n",
    "        else: raise ValueError(f\"Unknown sense: {sense}\")\n",
    "        \n",
    "        self.prob += c, name\n",
    "        self.constraints[name] = c\n",
    "\n",
    "    def set_objective(self, expr):\n",
    "        self.prob += expr\n",
    "        print(\"âœ… ç›®æ ‡å‡½æ•°å·²è®¾å®šã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 2: æ±‚è§£ä¸è‡ªæ„ˆ (Solve & Heal)\n",
    "    # ======================================================\n",
    "    def solve(self, solver_name='CBC', time_limit=60):\n",
    "        print(f\"\\nğŸš€ å¯åŠ¨æ±‚è§£å™¨ ({solver_name})...\")\n",
    "        if solver_name == 'CBC': solver = pulp.PULP_CBC_CMD(timeLimit=time_limit, msg=0)\n",
    "        else: solver = pulp.PULP_CBC_CMD(msg=0) \n",
    "            \n",
    "        try: status = self.prob.solve(solver)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æ±‚è§£å™¨å´©æºƒ: {e}. å°è¯•æ£€æŸ¥å®‰è£…ã€‚\")\n",
    "            return\n",
    "        \n",
    "        status_str = pulp.LpStatus[status]\n",
    "        print(f\"ğŸ“‹ æ±‚è§£çŠ¶æ€: {status_str}\")\n",
    "        \n",
    "        if status_str in ['Infeasible', 'Unbounded']:\n",
    "            print(\"ğŸš¨ è­¦å‘Š: æ¨¡å‹æ— è§£æˆ–æ— ç•Œï¼å¯åŠ¨è‡ªåŠ¨è¯Šæ–­...\")\n",
    "            self._diagnose_infeasibility()\n",
    "        else:\n",
    "            print(f\"ğŸ’ æœ€ä¼˜ç›®æ ‡å€¼: {pulp.value(self.prob.objective)}\")\n",
    "            self.save_state()\n",
    "\n",
    "    def _diagnose_infeasibility(self):\n",
    "        \"\"\" è¯Šæ–­åˆ†æ”¯ \"\"\"\n",
    "        print(\"\\nğŸ” --- æ— è§£è¯Šæ–­æŠ¥å‘Š ---\")\n",
    "        print(\"1. æ£€æŸ¥çº¦æŸå†²çª: RHS è®¾ç½®æ˜¯å¦è¿‡äºä¸¥æ ¼ï¼Ÿ\")\n",
    "        print(\"2. æ£€æŸ¥å˜é‡ä¸Šä¸‹ç•Œ: LowBound > UpBoundï¼Ÿ\")\n",
    "        print(\"å»ºè®®: é€æ­¥ç§»é™¤æœ€æ–°æ·»åŠ çš„çº¦æŸè¿›è¡Œæµ‹è¯•ã€‚\")\n",
    "\n",
    "    def save_state(self, filename='model_checkpoint.pkl'):\n",
    "        \"\"\" Checkpoint ä¿å­˜ \"\"\"\n",
    "        path = os.path.join(self.output_dir, filename)\n",
    "        try:\n",
    "            with open(path, 'wb') as f: pickle.dump(self.prob, f)\n",
    "            print(f\"ğŸ’¾ æ¨¡å‹çŠ¶æ€å·²ä¿å­˜è‡³ {filename}\")\n",
    "        except: pass # å¿½ç•¥é€’å½’æ·±åº¦é”™è¯¯\n",
    "\n",
    "    def load_state(self, filename):\n",
    "        path = os.path.join(self.output_dir, filename)\n",
    "        with open(path, 'rb') as f: self.prob = pickle.load(f)\n",
    "        print(f\"ğŸ“‚ æ¨¡å‹å·²ä» {filename} æ¢å¤ã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 3: æ·±åº¦åˆ†æ (Deep Analysis)\n",
    "    # ======================================================\n",
    "    def analyze_shadow_prices(self, top_k=5):\n",
    "        \"\"\" [LP Only] å½±å­ä»·æ ¼åˆ†æ \"\"\"\n",
    "        if self.is_mip:\n",
    "            print(\"âš ï¸ è·³è¿‡å½±å­ä»·æ ¼åˆ†æ (MIPæ¨¡å‹)ã€‚\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\nğŸ•µï¸ å¯åŠ¨èµ„æºç“¶é¢ˆåˆ†æ (Shadow Prices)...\")\n",
    "        data = [{'Constraint': k, 'Shadow_Price': v.pi, 'Slack': v.slack} for k, v in self.constraints.items()]\n",
    "        df = pd.DataFrame(data)\n",
    "        df_active = df[np.abs(df['Shadow_Price']) > 1e-6].copy()\n",
    "        df_active['Abs_Price'] = df_active['Shadow_Price'].abs()\n",
    "        df_active = df_active.sort_values('Abs_Price', ascending=False).head(top_k)\n",
    "        \n",
    "        if df_active.empty:\n",
    "            print(\"   -> æ— ç´§ç¼ºèµ„æºã€‚\")\n",
    "            return\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x='Shadow_Price', y='Constraint', data=df_active, palette='viridis')\n",
    "        plt.title('Top Bottleneck Constraints (Resource Sensitivity)')\n",
    "        plt.xlabel('Marginal Benefit (Shadow Price)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.output_dir}/Shadow_Prices.svg\")\n",
    "        print(f\"âœ… ç“¶é¢ˆåˆ†æå›¾å·²ä¿å­˜ã€‚\")\n",
    "\n",
    "    def analyze_robustness(self, perturb_range=0.1, runs=50):\n",
    "        \"\"\" [V7.0 ä¿®æ­£ç‰ˆ] çœŸå®è’™ç‰¹å¡æ´›çµæ•åº¦åˆ†æ \"\"\"\n",
    "        print(f\"\\nğŸŒªï¸ å¯åŠ¨çœŸå®é²æ£’æ€§æµ‹è¯• (Perturb: Â±{perturb_range:.0%}, Runs: {runs})...\")\n",
    "        if self.prob.status != 1: return\n",
    "\n",
    "        base_obj_val = pulp.value(self.prob.objective)\n",
    "        results = []\n",
    "        try: original_coeffs = self.prob.objective.to_dict()\n",
    "        except: return \n",
    "\n",
    "        base_objective = self.prob.objective\n",
    "        valid_runs = 0\n",
    "        \n",
    "        for i in range(runs):\n",
    "            new_obj_expr = 0\n",
    "            for v, coeff in original_coeffs.items():\n",
    "                new_coeff = coeff * (1 + np.random.uniform(-perturb_range, perturb_range))\n",
    "                new_obj_expr += new_coeff * v\n",
    "            \n",
    "            self.prob.setObjective(new_obj_expr)\n",
    "            self.prob.solve(pulp.PULP_CBC_CMD(msg=0))\n",
    "            if self.prob.status == 1:\n",
    "                results.append(pulp.value(self.prob.objective))\n",
    "                valid_runs += 1\n",
    "        \n",
    "        # æ¢å¤çŠ¶æ€\n",
    "        self.prob.setObjective(base_objective)\n",
    "        self.prob.solve(pulp.PULP_CBC_CMD(msg=0)) \n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.histplot(results, kde=True, color='skyblue')\n",
    "        plt.axvline(base_obj_val, color='red', linestyle='--')\n",
    "        plt.title(f'Robustness: Objective Distribution (Â±{perturb_range:.0%} Noise)')\n",
    "        plt.savefig(f\"{self.output_dir}/Robustness_Dist.svg\")\n",
    "        print(f\"âœ… é²æ£’æ€§æµ‹è¯•å®Œæˆã€‚\")\n",
    "\n",
    "    def scan_pareto_frontier(self, obj1_func, obj2_func, steps=10):\n",
    "        \"\"\" å¤šç›®æ ‡å¸•ç´¯æ‰˜æ‰«æ \"\"\"\n",
    "        print(f\"\\nâš–ï¸ å¯åŠ¨å¤šç›®æ ‡å¸•ç´¯æ‰˜æ‰«æ (Steps={steps})...\")\n",
    "        weights = np.linspace(0, 1, steps)\n",
    "        pareto_points = []\n",
    "        original_obj = self.prob.objective\n",
    "        \n",
    "        for w in weights:\n",
    "            self.prob.setObjective(w * obj1_func + (1 - w) * obj2_func)\n",
    "            self.prob.solve(pulp.PULP_CBC_CMD(msg=0))\n",
    "            if self.prob.status == 1:\n",
    "                pareto_points.append({'w': w, 'Obj1': pulp.value(obj1_func), 'Obj2': pulp.value(obj2_func)})\n",
    "        \n",
    "        self.prob.setObjective(original_obj) # Restore\n",
    "        if not pareto_points: return\n",
    "            \n",
    "        df = pd.DataFrame(pareto_points)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(df['Obj1'], df['Obj2'], 'o-', color='coral')\n",
    "        plt.title('Pareto Frontier')\n",
    "        plt.xlabel('Objective 1')\n",
    "        plt.ylabel('Objective 2')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(f\"{self.output_dir}/Pareto_Frontier.svg\")\n",
    "        df.to_excel(f\"{self.output_dir}/Pareto_Data.xlsx\", index=False)\n",
    "        print(f\"âœ… å¸•ç´¯æ‰˜å‰æ²¿å·²ç”Ÿæˆã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 4: å¯è§†åŒ–ä¸ Gephi åè®® (Visualization)\n",
    "    # ======================================================\n",
    "    def plot_constraint_slack(self):\n",
    "        \"\"\" èµ„æºä½™é‡å›¾ \"\"\"\n",
    "        print(f\"\\nğŸ¨ ç»˜åˆ¶èµ„æºä½™é‡å›¾ (Slack)...\")\n",
    "        data = [{'Constraint': k, 'Slack': v.slack} for k, v in self.constraints.items()]\n",
    "        df = pd.DataFrame(data).sort_values('Slack').head(20)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        colors = ['red' if s < 1e-5 else 'green' for s in df['Slack']]\n",
    "        sns.barplot(x='Slack', y='Constraint', data=df, palette=colors)\n",
    "        plt.title('Constraint Slack (Red = Binding)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.output_dir}/Constraint_Slack.svg\")\n",
    "\n",
    "    def export_flow_gephi(self, var_name_prefix, threshold=1e-5):\n",
    "        \"\"\"\n",
    "        [New] ç½‘ç»œæµå¯¼å‡ºåè®®\n",
    "        é€‚ç”¨äºè¿è¾“/ç½‘ç»œé—®é¢˜ã€‚å¯¼å‡º Source, Target, Weight (Flow) åˆ° CSVã€‚\n",
    "        å‰ç½®æ¡ä»¶: å˜é‡ keys å¿…é¡»æ˜¯ tuple (Source, Target) æˆ–ç±»ä¼¼çš„äºŒå…ƒç»“æ„ã€‚\n",
    "        \"\"\"\n",
    "        print(f\"\\nğŸ•¸ï¸ æ­£åœ¨å¯¼å‡ºç½‘ç»œæµ Gephi æ•°æ® (Prefix: {var_name_prefix})...\")\n",
    "        if var_name_prefix not in self.var_dict:\n",
    "            print(f\"âš ï¸ æ‰¾ä¸åˆ°å˜é‡å‰ç¼€ '{var_name_prefix}'ï¼Œè·³è¿‡ Gephi å¯¼å‡ºã€‚\")\n",
    "            return\n",
    "            \n",
    "        var_obj_dict = self.var_dict[var_name_prefix]\n",
    "        edges = []\n",
    "        \n",
    "        for keys, var_obj in var_obj_dict.items():\n",
    "            val = var_obj.varValue\n",
    "            if val and val > threshold:\n",
    "                # å°è¯•è§£æ keys\n",
    "                # å¦‚æœæ˜¯ tuple (A, B) -> Source=A, Target=B\n",
    "                if isinstance(keys, (list, tuple)) and len(keys) == 2:\n",
    "                    edges.append({'Source': keys[0], 'Target': keys[1], 'Weight': val, 'Type': 'Directed'})\n",
    "                else:\n",
    "                    # å¦‚æœä¸æ˜¯æ ‡å‡†äºŒå…ƒç»„ï¼Œä½œä¸ºå•ç‚¹å¤„ç†æˆ–è·³è¿‡\n",
    "                    pass\n",
    "        \n",
    "        if not edges:\n",
    "            print(\"   -> æœªå‘ç°æœ‰æ•ˆæµé‡ (Flow > 0)ã€‚\")\n",
    "            return\n",
    "            \n",
    "        df_edges = pd.DataFrame(edges)\n",
    "        save_path = f\"{self.output_dir}/Network_Flow_Gephi.csv\"\n",
    "        df_edges.to_csv(save_path, index=False)\n",
    "        print(f\"âœ… å·²å¯¼å‡º Gephi è¾¹è¡¨: {save_path} (å« {len(edges)} æ¡è¾¹)\")\n",
    "        print(\"   -> è¯·åœ¨ Gephi ä¸­å¯¼å…¥æ­¤ CSVï¼Œå¹¶ä½¿ç”¨ 'Force Atlas 2' å¸ƒå±€å¯è§†åŒ–æœ€ä¼˜è·¯å¾„ã€‚\")\n",
    "\n",
    "    # ======================================================\n",
    "    # Phase 5: äº¤ä»˜ (Delivery)\n",
    "    # ======================================================\n",
    "    def export_results(self):\n",
    "        \"\"\" Auto-Delivery \"\"\"\n",
    "        print(f\"\\nğŸ“¦ === æ­£åœ¨æ‰“åŒ…äº¤ä»˜ç‰©è‡³ {self.output_dir} === \")\n",
    "        \n",
    "        # 1. å˜é‡å¯¼å‡º\n",
    "        var_data = [{'Variable': v.name, 'Value': v.varValue} for v in self.prob.variables()]\n",
    "        df_res = pd.DataFrame(var_data)\n",
    "        df_res.to_excel(f\"{self.output_dir}/Optimization_Result.xlsx\", index=False)\n",
    "        \n",
    "        # 2. æŠ¥å‘Š\n",
    "        obj_val = pulp.value(self.prob.objective)\n",
    "        status = pulp.LpStatus[self.prob.status]\n",
    "        report = f\"# Optimization Report: {self.name}\\n\\nStatus: {status}\\nObjective: {obj_val}\\n\"\n",
    "        report += \"Check `Shadow_Prices.svg` (if LP) or `Constraint_Slack.svg` for bottlenecks.\\n\"\n",
    "        report += \"Check `Network_Flow_Gephi.csv` if this is a transportation problem.\\n\"\n",
    "        with open(f\"{self.output_dir}/Report.md\", \"w\", encoding='utf-8') as f: f.write(report)\n",
    "        \n",
    "        # 3. Latex å˜é‡è¡¨ (Safe Version)\n",
    "        df_top = df_res[df_res['Value']!=0].head(10)\n",
    "        tex = \"\\\\begin{tabular}{lr} Variable & Value \\\\\\\\ \\\\midrule\\n\"\n",
    "        for _, r in df_top.iterrows(): tex += f\"{r['Variable'].replace('_','\\\\_')} & {r['Value']:.4f} \\\\\\\\\\n\"\n",
    "        tex += \"\\\\end{tabular}\"\n",
    "        with open(f\"{self.output_dir}/Variables.tex\", \"w\") as f: f.write(tex)\n",
    "            \n",
    "        print(f\"âœ… å…¨å¥—ç»“æœå·²å¯¼å‡º (Excel, Report, Latex, SVG, Gephi)ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbe7076-d047-4723-9207-80a26365b9ea",
   "metadata": {},
   "source": [
    "# âš”ï¸ V7.0 ä¼˜åŒ–æ¨¡å‹æŒ‡æŒ¥å®˜å…¨æµç¨‹ä½œæˆ˜æ‰‹å†Œ (Commander's Manual)\n",
    "\n",
    "> **æ ¸å¿ƒæˆ˜ç•¥**ï¼šåˆ©ç”¨å°è£…å¥½çš„â€œå†›ç«åº“â€å®ç°é™ç»´æ‰“å‡»â€”â€”ä¸ä»…è¾“å‡ºæœ€ä¼˜è§£ï¼Œæ›´è¾“å‡ºç¨³å®šæ€§è¯æ˜ï¼ˆé²æ£’æ€§ï¼‰ã€ç“¶é¢ˆæ´å¯Ÿï¼ˆå½±å­ä»·æ ¼ï¼‰ä»¥åŠé«˜ç»´ç½‘ç»œå¯è§†åŒ–ï¼ˆGephiï¼‰ã€‚\n",
    "> **è¯´æ˜**ï¼šè¿™ä»½æ‰‹å†Œå·²ç»è¿‡ä¸¥æ ¼çš„â€œä»£ç -æŒ‡ä»¤â€å¯¹é½æµ‹è¯•ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ›‘ Phase -1: èµ›å‰æ¼”ä¹  (God Mode Verification)\n",
    "\n",
    "> **æ‰§è¡Œæ—¶æœº**ï¼šæ‹¿åˆ°èµ›é¢˜åçš„æœ€åˆ 30 åˆ†é’Ÿå†…ã€‚\n",
    "> **ç›®çš„**ï¼šç¡®ä¿æœ¬åœ° Python ç¯å¢ƒï¼ˆPuLP, Pandas, Seabornï¼‰åŠ Gephi è½¯ä»¶å°±ç»ªï¼Œèƒ½å¤Ÿè·‘é€šâ€œè®¡ç®—-å¯¼å‡º-å¯è§†åŒ–â€çš„å…¨é“¾è·¯ã€‚\n",
    "\n",
    "1.  **æ„é€ â€œç©å…·æ¨¡å‹â€ (Toy Problem)**:\n",
    "    * åœ¨å¿ƒä¸­æ„å»ºä¸€ä¸ªæç®€åœºæ™¯ï¼šå·¥å‚ Aï¼ˆä½æˆæœ¬ã€äº§èƒ½ 50ï¼‰ã€å·¥å‚ Bï¼ˆé«˜æˆæœ¬ã€äº§èƒ½æ— é™ï¼‰ï¼Œéœ€æ±‚ 100ï¼Œæ±‚æœ€å°æˆæœ¬ã€‚\n",
    "\n",
    "2.  **ç›²æµ‹éªŒè¯ (Blind Test)**:\n",
    "    * è°ƒç”¨ `solver.solve()`ã€‚\n",
    "\n",
    "3.  **éªŒæ”¶æ ‡å‡†**:\n",
    "    * **I (é€»è¾‘)**: ç»“æœå¿…é¡»æ˜¯ $A=50, B=50$ã€‚è‹¥ç»“æœä¸º $B=100$ï¼Œè¯´æ˜ç›®æ ‡å‡½æ•°æ–¹å‘ (min/max) å®šä¹‰åäº†ã€‚\n",
    "    * **II (æ ¸æ­¦å™¨)**: æ£€æŸ¥è¾“å‡ºç›®å½•ä¸‹çš„ `Shadow_Prices.svg`ã€‚å·¥å‚ A çš„äº§èƒ½çº¦æŸå¿…é¡»æœ‰æ˜¾è‘—çš„å½±å­ä»·æ ¼ï¼ˆå› ä¸ºå®ƒæ˜¯ç“¶é¢ˆï¼‰ï¼Œè€Œ B çš„çº¦æŸå½±å­ä»·æ ¼åº”ä¸º 0ã€‚\n",
    "    * **III (æ¥å£)**: è¿è¡Œ `solver.export_flow_gephi`ï¼Œç¡®è®¤èƒ½ç”Ÿæˆ `.csv` æ–‡ä»¶ï¼Œä¸” Gephi èƒ½æˆåŠŸè¯»å–ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ•¹ï¸ Phase 0: å¯åŠ¨ä¸ç¯å¢ƒæ¡æ‰‹ (Boot & Handshake)\n",
    "\n",
    "> **æ‰§è¡Œæ—¶æœº**ï¼šæ­£å¼å»ºæ¨¡å¼€å§‹æ—¶ã€‚\n",
    "\n",
    "#### 1. åˆå§‹åŒ–å†³ç­–\n",
    "* å®ä¾‹åŒ– `Opt_Solver_Capsule`ã€‚\n",
    "* **å…³é”®å‚æ•°**ï¼šæ˜ç¡® `sense='min'` (æˆæœ¬/æ—¶é—´) è¿˜æ˜¯ `sense='max'` (åˆ©æ¶¦/æ”¶ç›Š)ã€‚\n",
    "\n",
    "#### 2. æ–­ç‚¹æ‰«æ (Checkpoint Scan)\n",
    "* ä»£ç ä¼šè‡ªåŠ¨æ£€æµ‹æ˜¯å¦å­˜åœ¨ `model_checkpoint.pkl`ã€‚\n",
    "* **å†³ç­–ç‚¹**ï¼šå¦‚æœä¸Šä¸€æ¬¡è¿è¡Œå› æ–­ç”µæˆ–æ­»æœºä¸­æ–­ï¼Œç›´æ¥è°ƒç”¨ `load_state()` ç¬é—´æ¢å¤æ¨¡å‹ï¼Œæ— éœ€é‡æ–°è¿è¡Œæ¼«é•¿çš„å˜é‡å®šä¹‰ä»£ç ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ Phase 1: åœºæ™¯ä¸å˜é‡å®šä¹‰ (The Setup)\n",
    "\n",
    "> **æ‰§è¡Œæ—¶æœº**ï¼šå°†æ•°å­¦ç¬¦å·è½¬åŒ–ä¸ºä»£ç å¯¹è±¡çš„é˜¶æ®µã€‚\n",
    "\n",
    "#### 1. ç»´åº¦ä¸ç´¢å¼• (Keys Definition)\n",
    "* **æ™®é€šé—®é¢˜**ï¼šä½¿ç”¨ç®€å•åˆ—è¡¨ï¼ˆå¦‚ `['Factory_1', 'Factory_2']`ï¼‰ã€‚\n",
    "* **ç½‘ç»œæµ/ç‰©æµé—®é¢˜**ï¼š**å¿…é¡»æ„é€ å…ƒç»„åˆ—è¡¨ `[(Origin, Destination), ...]`**ã€‚\n",
    "* **æˆ˜ç•¥æ„ä¹‰**ï¼šåªæœ‰ä½¿ç”¨å…ƒç»„ä½œä¸º Keyï¼Œåç»­çš„ `export_flow_gephi` æ‰èƒ½æ­£ç¡®è¯†åˆ« Source å’Œ Targetï¼Œç”Ÿæˆæµå‘å›¾ã€‚\n",
    "\n",
    "#### 2. ç±»å‹å®šæ€§ (Type Definition)\n",
    "* è°ƒç”¨ `add_var_batch` æ—¶ï¼Œéœ€æ…é‡é€‰æ‹© `cat` å‚æ•°ï¼š\n",
    "    * **Continuous (è¿ç»­å˜é‡)**ï¼šç”¨äºèµ„æºåˆ†é…ã€æµé€Ÿã€‚-> **æ¿€æ´» LP æ¨¡å¼**ï¼ˆåç»­å¯ç”¨å½±å­ä»·æ ¼åˆ†æï¼‰ã€‚\n",
    "    * **Integer/Binary (æ•´æ•°/0-1å˜é‡)**ï¼šç”¨äºé€‰å€ã€é€‰äººã€ç®±æ•°ã€‚-> **æ¿€æ´» MIP æ¨¡å¼**ï¼ˆåç»­ç¦ç”¨å½±å­ä»·æ ¼ï¼Œè½¬ä¸º Slack åˆ†æï¼‰ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### â›“ï¸ Phase 2: çº¦æŸæ„å»º (Constraint Injection)\n",
    "\n",
    "> **æ‰§è¡Œæ—¶æœº**ï¼šç¿»è¯‘çº¦æŸæ¡ä»¶æ—¶ã€‚\n",
    "\n",
    "#### 1. é«˜æ•ˆæ³¨å…¥\n",
    "* ä½¿ç”¨ `pulp.lpSum` é…åˆåˆ—è¡¨æ¨å¯¼å¼ï¼Œä¸¥ç¦ä½¿ç”¨ä½æ•ˆçš„å¾ªç¯é€æ¡æ·»åŠ ã€‚\n",
    "\n",
    "#### 2. å¼ºåˆ¶å‘½ååè®® (Naming Protocol)\n",
    "* **æ ¸å¿ƒåŠ¨ä½œ**ï¼šåœ¨è°ƒç”¨ `add_constraint` æ—¶ï¼Œ**å¿…é¡»ä¼ å…¥å…·æœ‰ä¸šåŠ¡å«ä¹‰çš„ `name` å‚æ•°**ï¼ˆä¾‹å¦‚ `Labor_Limit_Week1`ï¼‰ã€‚\n",
    "* **åº•å±‚é€»è¾‘**ï¼šV7.0 çš„ `analyze_shadow_prices` æ–¹æ³•ä¼šæå–è¿™äº› Name ä½œä¸ºçƒ­åŠ›å›¾çš„ Y è½´æ ‡ç­¾ã€‚å¦‚æœçº¦æŸæœªå‘½åï¼Œç”Ÿæˆçš„åˆ†æå›¾è¡¨å°†æ— æ³•é˜…è¯»ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ Phase 3: æ±‚è§£ä¸è‡ªæ„ˆ (Solve & Heal)\n",
    "\n",
    "> **æ‰§è¡Œæ—¶æœº**ï¼šæ¨¡å‹æ„å»ºå®Œæ¯•ï¼Œç‚¹å‡»è¿è¡Œã€‚\n",
    "\n",
    "#### 1. æ‰§è¡Œæ±‚è§£\n",
    "* è°ƒç”¨ `solve(solver_name='CBC')`ã€‚\n",
    "\n",
    "#### 2. çŠ¶æ€åˆ†æ”¯åˆ¤æ–­\n",
    "* **ğŸŸ¢ Optimal (æœ€ä¼˜)**ï¼š\n",
    "    * æ§åˆ¶å°æ˜¾ç¤ºâ€œæœ€ä¼˜ç›®æ ‡å€¼â€ã€‚\n",
    "    * ç³»ç»Ÿè‡ªåŠ¨ pickle ä¿å­˜å½“å‰çŠ¶æ€ã€‚-> **ç›´æ¥è¿›å…¥ Phase 4**ã€‚\n",
    "* **ğŸ”´ Infeasible (æ— è§£) / Unbounded (æ— ç•Œ)**ï¼š\n",
    "    * ç«‹å³åœæ­¢ã€‚\n",
    "    * **è‡ªæ„ˆæœºåˆ¶**ï¼šæŸ¥çœ‹æ§åˆ¶å°è‡ªåŠ¨æ‰“å°çš„ `_diagnose_infeasibility` æŠ¥å‘Šã€‚\n",
    "    * **ä¿®æ­£ç­–ç•¥**ï¼šé€šå¸¸æ˜¯ RHS è®¾ç½®è¿‡ç´§ï¼ˆä¾‹å¦‚è¦æ±‚â€œæ—¢è¦é©¬å„¿è·‘ï¼Œåˆè¦é©¬å„¿ä¸åƒè‰â€ï¼‰ã€‚éœ€é€æ­¥æ”¾æ¾æœ€è¿‘æ·»åŠ çš„çº¦æŸï¼Œç›´è‡³æ‰¾åˆ°å†²çªæºã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ›¡ï¸ Phase 4: æ·±åº¦é˜²å¾¡ä½“ç³» (Deep Defense)\n",
    "\n",
    "> **æ‰§è¡Œæ—¶æœº**ï¼šè·å¾—æ•°å€¼è§£åã€‚è¿™æ˜¯ O å¥–è®ºæ–‡çš„æ ¸å¿ƒå¾—åˆ†ç‚¹ã€‚\n",
    "\n",
    "#### 1. ç“¶é¢ˆè¯†åˆ« (The \"Why\")\n",
    "* **LP æ¨¡å¼**ï¼šè°ƒç”¨ `analyze_shadow_prices(top_k=5)`ã€‚\n",
    "    * å›¾è¡¨ï¼š`Shadow_Prices.svg`ã€‚\n",
    "    * **è¯æœ¯**ï¼šâ€œèµ„æº X çš„å½±å­ä»·æ ¼æœ€é«˜ï¼Œå®ƒæ˜¯ç³»ç»Ÿçš„ç»å¯¹ç“¶é¢ˆã€‚æ¯å¢åŠ  1 å•ä½ Xï¼Œç›®æ ‡å‡½æ•°å°†ä¼˜åŒ– Yã€‚â€\n",
    "* **MIP æ¨¡å¼**ï¼šè°ƒç”¨ `plot_constraint_slack()`ã€‚\n",
    "    * å›¾è¡¨ï¼š`Constraint_Slack.svg`ã€‚\n",
    "    * **è¯æœ¯**ï¼šâ€œçº¢è‰²æ¡å½¢ä»£è¡¨ Slack=0 çš„çº¦æŸï¼Œè¿™äº›èµ„æºå·²è¢«è€—å°½ï¼Œé™åˆ¶äº†ç³»ç»Ÿæ€§èƒ½ã€‚â€\n",
    "\n",
    "#### 2. çœŸå®é²æ£’æ€§æµ‹è¯• (The \"What If\")\n",
    "* è°ƒç”¨ `analyze_robustness(perturb_range=0.1, runs=50)`ã€‚\n",
    "* **åº•å±‚é€»è¾‘**ï¼šç³»ç»Ÿä¼šçœŸå®åœ°å¯¹ç›®æ ‡ç³»æ•°è¿›è¡Œ $\\pm 10\\%$ çš„éšæœºæ‰°åŠ¨ï¼Œå¹¶é‡æ–°è°ƒç”¨æ±‚è§£å™¨ 50 æ¬¡ã€‚\n",
    "* **éªŒæ”¶**ï¼šæŸ¥çœ‹ `Robustness_Dist.svg`ã€‚çª„å³°ä»£è¡¨æ–¹æ¡ˆç¨³å¥ï¼Œå®½å³°ä»£è¡¨é£é™©è¾ƒé«˜ã€‚\n",
    "\n",
    "#### 3. å¤šç›®æ ‡æƒè¡¡ (Trade-off)\n",
    "* è‹¥å­˜åœ¨å†²çªç›®æ ‡ï¼ˆå¦‚æˆæœ¬ vs æ—¶é—´ï¼‰ï¼Œè°ƒç”¨ `scan_pareto_frontier`ï¼Œç”Ÿæˆå¸•ç´¯æ‰˜æ›²çº¿ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“¦ Phase 5: äº¤ä»˜ä¸å¯è§†åŒ– (Delivery)\n",
    "\n",
    "> **æ‰§è¡Œæ—¶æœº**ï¼šå†™ä½œä¸æ’ç‰ˆé˜¶æ®µã€‚\n",
    "\n",
    "#### 1. å…¨è‡ªåŠ¨å¯¼å‡º\n",
    "* æ‰§è¡Œ `export_results()`ã€‚\n",
    "    * **Excel**: `Optimization_Result.xlsx`ï¼ˆæ”¾é™„å½•ï¼‰ã€‚\n",
    "    * **LaTeX**: `Variables.tex`ï¼ˆç›´æ¥è´´å…¥è®ºæ–‡æ­£æ–‡è¡¨æ ¼ï¼‰ã€‚\n",
    "    * **Report**: `Report.md`ï¼ˆä½œä¸º Result Analysis ç« èŠ‚çš„åº•ç¨¿ï¼‰ã€‚\n",
    "\n",
    "#### 2. æ£€æŸ¥ Gephi ç´ æ\n",
    "* å¦‚æœæ˜¯ç½‘ç»œæµé—®é¢˜ï¼Œç¡®è®¤è¾“å‡ºç›®å½•ä¸­æ˜¯å¦ç”Ÿæˆäº† `Network_Flow_Gephi.csv`ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸŒŸ é™„å½•ï¼šGephi ç½‘ç»œæµå¯è§†åŒ–åè®® (The Flow Protocol)\n",
    "\n",
    "> **é€‚ç”¨åœºæ™¯**ï¼šç¾èµ› Problem D/F (ç‰©æµã€äº¤é€šã€ä¾›åº”é“¾)ã€‚\n",
    "> **ç›®çš„**ï¼šå°†æ¯ç‡¥çš„ $x_{ij}$ çŸ©é˜µè½¬åŒ–ä¸ºå±•ç¤ºâ€œç³»ç»Ÿå¤§åŠ¨è„‰â€çš„æ‹“æ‰‘å›¾ã€‚\n",
    "\n",
    "#### Step 1: æ¿€æ´»å¯¼å‡º\n",
    "* ç¡®è®¤åœ¨ Phase 1 ä¸­ä½¿ç”¨äº†å…ƒç»„ `(Source, Target)` å®šä¹‰å˜é‡ã€‚\n",
    "* è¿è¡Œ `solver.export_flow_gephi(var_name_prefix='ä½ çš„å˜é‡å‰ç¼€')`ã€‚\n",
    "\n",
    "#### Step 2: Gephi æœ¬åœ°æ¸²æŸ“ (Visual Rendering)\n",
    "1.  **å¯¼å…¥ (Import)**ï¼š\n",
    "    * æ‰“å¼€ Gephi -> Import Spreadsheet -> é€‰æ‹© `Network_Flow_Gephi.csv`ã€‚\n",
    "    * **å…³é”®è®¾ç½®**ï¼šç¡®ä¿åˆ—æ˜ å°„æ­£ç¡®ï¼š\n",
    "        * Source -> Source Node\n",
    "        * Target -> Target Node\n",
    "        * Weight -> Edge Weight (è¾¹æƒé‡)\n",
    "2.  **å¸ƒå±€ (Layout)**ï¼š\n",
    "    * é€‰æ‹© **Force Atlas 2** ç®—æ³•ã€‚\n",
    "    * å‚æ•°ï¼šScaling=20 (æ‹‰å¼€é—´è·)ï¼Œå‹¾é€‰ Prevent Overlap (é˜²æ­¢é‡å )ã€‚\n",
    "    * ç‚¹å‡» Runï¼Œå¾…ç»“æ„ç¨³å®šå Stopã€‚\n",
    "3.  **è§†è§‰ç¼–ç  (Visual Encoding)**ï¼š\n",
    "    * **èŠ‚ç‚¹å¤§å°**ï¼šæŒ‰ Degree (åº¦) æ’åã€‚-> **è§£é‡Š**ï¼šå¤§èŠ‚ç‚¹æ˜¯å…³é”®æ¢çº½ã€‚\n",
    "    * **è¾¹ç²—ç»†**ï¼šæŒ‰ Weight (æµé‡) æ’åã€‚-> **è§£é‡Š**ï¼šç²—çº¿æ˜¯è¿è¾“ä¸»å¹²é“ï¼ˆæœ€ä¼˜è·¯å¾„ï¼‰ã€‚\n",
    "    * **é…è‰²**ï¼šä½¿ç”¨ Partition -> Modularity Class è¿›è¡Œç¤¾åŒºç€è‰²ï¼ˆå¯é€‰ï¼‰ã€‚\n",
    "4.  **æœ€ç»ˆè¾“å‡º**ï¼š\n",
    "    * å¯¼å‡ºä¸º PDF æˆ– SVG æ ¼å¼ï¼Œæ’å…¥è®ºæ–‡ã€‚\n",
    "    * **Caption**ï¼š \"Figure X: Optimized Logistics Network Topology. Edge thickness correlates with optimal transport volume ($x_{ij}$), revealing the critical path from Distribution Center A to Region B.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c9cdf-f7f4-43f0-a1e1-e3b97ca11267",
   "metadata": {},
   "source": [
    "è¿™ä»½ AI äº¤äº’å·¥ä½œæµå·²ç»è¿‡æœ€ç»ˆè‡ªæ£€ (Final Audit)ã€‚\n",
    "è‡ªæ£€ç»“æœç¡®è®¤ï¼š\n",
    "1.  **é€»è¾‘é—­ç¯**ï¼šå®Œå…¨å¯¹åº” Opt_Solver_Capsule (V7.0) çš„ä»£ç é€»è¾‘ï¼Œç‰¹åˆ«æ˜¯ Phase 1 çš„å˜é‡å®šä¹‰ç›´æ¥å†³å®š Phase 4 (å½±å­ä»·æ ¼ vs Slack) å’Œ Phase 5 (Gephi å¯¼å‡º) çš„åˆ†æ”¯ã€‚\n",
    "2.  **Gephi åè®®é›†æˆ**ï¼šåœ¨ Phase 1 åŸ‹ä¸‹ä¼ç¬”ï¼ˆå…ƒç»„ Keyï¼‰ï¼Œåœ¨ Phase 5 è§¦å‘å¯¼å‡ºï¼Œåœ¨é™„å½•æä¾›æ“ä½œæŒ‡å—ï¼Œå½¢æˆäº†å®Œæ•´çš„å¯è§†åŒ–è¯æ®é“¾ã€‚\n",
    "3.  **æ ¼å¼è§„èŒƒ**ï¼šä¸¥æ ¼åŒºåˆ†äº†â€œæœ¬åœ°æ‰§è¡Œâ€ä¸â€œå‘é€ç»™ AI çš„æŒ‡ä»¤â€ã€‚\n",
    "\n",
    "ä»¥ä¸‹æ˜¯æœ€ç»ˆå®šç¨¿çš„ **AI äº¤äº’å·¥ä½œæµ (AI Interaction Workflow)**ã€‚\n",
    "\n",
    "## ğŸ¤– ç¬¬ä¸‰éƒ¨åˆ†ï¼šAI äº¤äº’å·¥ä½œæµ (Final RPG Prompts)\n",
    "\n",
    "> **æ“ä½œæŒ‡å—**: è¯·æŒ‰é¡ºåºå¤åˆ¶å„ä¸ª Phase çš„æ¡†å†…æ–‡æœ¬å‘é€ç»™ AIã€‚Phase 0.1 ä»…åœ¨æœ¬åœ°è¿è¡Œã€‚\n",
    "\n",
    "### ğŸ•¹ï¸ Phase 0.1: æœ¬åœ°å¯åŠ¨ (Local Preparation)\n",
    "\n",
    "* **[åŠ¨ä½œ]**: è¯·åœ¨æœ¬åœ° Jupyter Notebook ä¸­è¿è¡Œæ­¤ä»£ç ï¼Œä¸è¦å‘é€ç»™ AIã€‚è¿™æ˜¯ä¸ºäº†å»ºç«‹æ¡æ‰‹åè®®ã€‚\n",
    "\n",
    "```python\n",
    "# [Local Action] åŠ¡å¿…ç¡®ä¿ Opt_Solver_Capsule ç±»ä»£ç å·²åœ¨ä¸Šæ–¹å•å…ƒæ ¼è¿è¡Œè¿‡\n",
    "import pandas as pd\n",
    "import pulp\n",
    "import os\n",
    "\n",
    "# 1. å®ä¾‹åŒ– (è¯·æ ¹æ®é¢˜ç›®è¦æ±‚ä¿®æ”¹ sense ä¸º 'min' æˆ– 'max')\n",
    "# ä¾‹å¦‚ï¼šæœ€çŸ­è·¯å¾„/æˆæœ¬ç”¨ 'min'ï¼Œæœ€å¤§æµ/åˆ©æ¶¦ç”¨ 'max'\n",
    "solver = Opt_Solver_Capsule(name=\"MCM_Optimization\", sense='min') \n",
    "\n",
    "# 2. ç”Ÿæˆæ¡æ‰‹åè®® (å…³é”®æ­¥éª¤)\n",
    "# è¿è¡Œåä¼šæ‰“å°ä¸€æ®µ API æ¸…å•å’Œæ•°å­¦é™·é˜±ï¼Œä¾›åç»­ AI å‚è€ƒ\n",
    "solver.generate_handshake()\n",
    "\n",
    "# 3. æ–­ç‚¹æ£€æŸ¥ (Crash Recovery)\n",
    "if os.path.exists(f\"{solver.output_dir}/model_checkpoint.pkl\"):\n",
    "    print(\"âš ï¸ å‘ç°å†å²å­˜æ¡£ï¼è‹¥éœ€æ¢å¤è¿›åº¦ï¼Œè¯·æ‰§è¡Œ: solver.load_state('model_checkpoint.pkl')\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ Phase 1: åˆå§‹åŒ–ä¸å®šä¹‰ (Prompt_Opt_Init.txt)\n",
    "\n",
    "* **[åŠ¨ä½œ]**: å¤åˆ¶ä»¥ä¸‹æŒ‡ä»¤å‘é€ç»™ AIã€‚\n",
    "* **[å‰ç½®]**: ç¡®ä¿å·²å°†ç±»ä»£ç å‘ç»™ AIã€‚\n",
    "\n",
    "```markdown\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šPhase 1 - ä¼˜åŒ–æ¨¡å‹åˆå§‹åŒ–ä¸å˜é‡å®šä¹‰ã€‘\n",
    "\n",
    "æˆ‘å·²åŠ è½½ V7.0 ç±»ã€‚è¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š\n",
    "\n",
    "1.  **å®ä¾‹åŒ–**: `solver = Opt_Solver_Capsule(name='MCM_Opt', sense='min/max')` (è¯·æ ¹æ®ä¸Šä¸‹æ–‡åˆ¤æ–­æ–¹å‘)ã€‚\n",
    "\n",
    "2.  **å˜é‡å®šä¹‰ (Critical Definition - äººç±»å†³ç­–)**:\n",
    "    - **è¯·è¯¢é—®æˆ‘å˜é‡çš„ç‰©ç†å«ä¹‰**ã€‚\n",
    "    - æ ¹æ®æˆ‘çš„å›ç­”ï¼Œç”Ÿæˆ `solver.add_var_batch` ä»£ç ï¼š\n",
    "      - **åœºæ™¯ A (ç½‘ç»œæµ/ç‰©æµ)**: å¿…é¡»æ„é€ å…ƒç»„ Keys `[(Origin, Destination), ...]`ã€‚è¿™ç›´æ¥å†³å®šåç»­èƒ½å¦å¯¼å‡º Gephi å›¾ã€‚\n",
    "      - **åœºæ™¯ B (æ™®é€šè§„åˆ’)**: ä½¿ç”¨åˆ—è¡¨ Keysã€‚\n",
    "      - **ç±»å‹é€‰æ‹©**: \n",
    "        - èµ„æº/æµé€Ÿ -> `cat='Continuous'` (æ¿€æ´»åç»­çš„å½±å­ä»·æ ¼åˆ†æ)ã€‚\n",
    "        - é€‰å€/è®¡æ•° -> `cat='Integer'` (æ¿€æ´» MIP æ¨¡å¼ï¼Œç¦ç”¨å½±å­ä»·æ ¼)ã€‚\n",
    "\n",
    "è¯·ç°åœ¨è¯¢é—®æˆ‘å…³äºå†³ç­–å˜é‡çš„ä¿¡æ¯ã€‚\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### â›“ï¸ Phase 2: çº¦æŸæ„å»º (Prompt_Opt_Constraint.txt)\n",
    "\n",
    "* **[åŠ¨ä½œ]**: å¤åˆ¶ä»¥ä¸‹æŒ‡ä»¤å‘é€ç»™ AIã€‚\n",
    "\n",
    "```markdown\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šPhase 2 - çº¦æŸæ³¨å…¥å·¥å‚ã€‘\n",
    "\n",
    "è¯·ååŠ©æˆ‘æ„å»ºçº¦æŸæ¡ä»¶ã€‚\n",
    "\n",
    "**V7.0 å¼ºåˆ¶è§„èŒƒ (å¿…é¡»ä¸¥æ ¼éµå®ˆ)**:\n",
    "1.  **ç¦æ­¢ä½æ•ˆå¾ªç¯**: å¿…é¡»ä½¿ç”¨ `pulp.lpSum` é…åˆ Python åˆ—è¡¨æ¨å¯¼å¼ (List Comprehension) æ„å»ºçº¦æŸã€‚\n",
    "2.  **å¼ºåˆ¶å‘½ååè®® (Naming Protocol)**: \n",
    "    - `solver.add_constraint` çš„ `name` å‚æ•°**ä¸èƒ½ä¸ºç©º**ã€‚\n",
    "    - æ ¼å¼ç¤ºä¾‹: `name=f\"Supply_Limit_{factory_id}\"`ã€‚\n",
    "    - **åŸå› **: V7.0 çš„ç“¶é¢ˆçƒ­åŠ›å›¾å®Œå…¨ä¾èµ–è¿™äº›åç§°ã€‚æœªå‘½åçš„çº¦æŸå°†æ— æ³•è¿›è¡Œçµæ•åº¦åˆ†æã€‚\n",
    "\n",
    "**å½“å‰ä»»åŠ¡**:\n",
    "è¯·è¯¢é—®æˆ‘å…·ä½“çš„ä¸šåŠ¡çº¦æŸé€»è¾‘ï¼ˆä¾‹å¦‚ï¼šä¾›éœ€å¹³è¡¡ã€äº§èƒ½é™åˆ¶ã€æµé‡å®ˆæ’ï¼‰ï¼Œç„¶åä¸ºæˆ‘ç¼–å†™ä»£ç ã€‚\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ Phase 3: æ±‚è§£ä¸è‡ªæ„ˆ (Prompt_Opt_Solve.txt)\n",
    "\n",
    "* **[åŠ¨ä½œ]**: å¤åˆ¶ä»¥ä¸‹æŒ‡ä»¤å‘é€ç»™ AIã€‚\n",
    "\n",
    "```markdown\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šPhase 3 - æ±‚è§£ä¸è‡ªæ„ˆã€‘\n",
    "\n",
    "1.  **è®¾ç½®ç›®æ ‡**: `solver.set_objective(...)` (è¯·åŸºäºä¹‹å‰çš„å˜é‡å®šä¹‰ç¼–å†™)ã€‚\n",
    "\n",
    "2.  **æ‰§è¡Œæ±‚è§£**: \n",
    "    - è¿è¡Œ `solver.solve(solver_name='CBC')`ã€‚\n",
    "\n",
    "3.  **åˆ†æ”¯ç­–ç•¥ (Branch Strategy)**:\n",
    "    - **å¦‚æœ Status = Optimal**: æ­å–œï¼Œè¯·å‘Šè¯‰æˆ‘â€œæ±‚è§£æˆåŠŸï¼Œè¿›å…¥ Phase 4â€ã€‚\n",
    "    - **å¦‚æœ Status = Infeasible**: \n",
    "      - **ç«‹å³åœæ­¢**ã€‚\n",
    "      - ç³»ç»Ÿä¼šè‡ªåŠ¨æ‰“å°è¯Šæ–­æŠ¥å‘Šã€‚è¯·åˆ†ææŠ¥å‘Šï¼Œå¹¶è¯¢é—®æˆ‘ï¼šâ€œæ£€æµ‹åˆ°çº¦æŸå†²çªï¼Œå»ºè®®æ”¾æ¾ [X] çº¦æŸçš„ RHSï¼Œæ˜¯å¦æ‰§è¡Œï¼Ÿâ€\n",
    "\n",
    "è¯·ç”Ÿæˆä»£ç ã€‚\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ›¡ï¸ Phase 4: æ·±åº¦é˜²å¾¡ (Prompt_Opt_Defense.txt)\n",
    "\n",
    "* **[åŠ¨ä½œ]**: å¤åˆ¶ä»¥ä¸‹æŒ‡ä»¤å‘é€ç»™ AIã€‚è¿™æ˜¯ O å¥–æ ¸å¿ƒã€‚\n",
    "\n",
    "```markdown\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šPhase 4 - æ·±åº¦é˜²å¾¡ä½“ç³»ã€‘\n",
    "\n",
    "è¯·æ‰§è¡Œä»¥ä¸‹æ ¸æ­¦å™¨åˆ†æä»£ç ï¼š\n",
    "\n",
    "1.  **ç“¶é¢ˆè¯†åˆ« (The Why)**:\n",
    "    - **é€»è¾‘åˆ†æ”¯**:\n",
    "      - è‹¥æ¨¡å‹ä¸º LP (è¿ç»­å˜é‡): æ‰§è¡Œ `solver.analyze_shadow_prices(top_k=5)`ã€‚å¹¶è§£é‡Šï¼šâ€œå“ªäº›èµ„æºæ˜¯ç³»ç»Ÿçš„ç»å¯¹ç“¶é¢ˆï¼Ÿâ€\n",
    "      - è‹¥æ¨¡å‹ä¸º MIP (æ•´æ•°å˜é‡): æ‰§è¡Œ `solver.plot_constraint_slack()`ã€‚å¹¶è§£é‡Šï¼šâ€œå“ªäº›çº¦æŸçš„ Slack ä¸º 0 (çº¢è‰²)ï¼Ÿâ€\n",
    "      \n",
    "2.  **çœŸå®é²æ£’æ€§æµ‹è¯• (The What If)**:\n",
    "    - æ‰§è¡Œ `solver.analyze_robustness(perturb_range=0.1, runs=50)`ã€‚\n",
    "    - **è§£è¯»**: è¯·æŒ‡ç¤ºæˆ‘çœ‹ `Robustness_Dist.svg`ã€‚çª„å³°ä»£è¡¨ç¨³å¥ï¼Œå®½å³°ä»£è¡¨é«˜é£é™©ã€‚\n",
    "\n",
    "3.  **(å¯é€‰) å¤šç›®æ ‡æƒè¡¡**:\n",
    "    - å¦‚æœæˆ‘æœ‰ä¸¤ä¸ªç›®æ ‡ï¼Œè¯·ç”Ÿæˆ `solver.scan_pareto_frontier(obj1, obj2)` ä»£ç ä¾›æˆ‘é€‰æ‹©ã€‚\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“¦ Phase 5: äº¤ä»˜ä¸å¯è§†åŒ– (Prompt_Opt_Harvest.txt)\n",
    "\n",
    "* **[åŠ¨ä½œ]**: å¤åˆ¶ä»¥ä¸‹æŒ‡ä»¤å‘é€ç»™ AIã€‚\n",
    "\n",
    "```markdown\n",
    "ã€ç³»ç»ŸæŒ‡ä»¤ï¼šPhase 5 - æœ€ç»ˆäº¤ä»˜ä¸ Gephi åè®®ã€‘\n",
    "\n",
    "1.  **å…¨è‡ªåŠ¨å¯¼å‡º**:\n",
    "    - æ‰§è¡Œ `solver.export_results()`ã€‚\n",
    "    - **éªŒæ”¶**: ç¡®è®¤ `Optimization_Result.xlsx` (Excel), `Variables.tex` (LaTeXè¡¨æ ¼), `Report.md` (æ™ºèƒ½æˆ˜æŠ¥) å·²ç”Ÿæˆã€‚\n",
    "\n",
    "2.  **[é™„å½•] Gephi ç½‘ç»œæµå¯è§†åŒ–åè®® (Conditional)**:\n",
    "    - **è§¦å‘æ¡ä»¶**: è¯·æ£€æŸ¥ Phase 1 ä¸­çš„å˜é‡ Keys æ˜¯å¦ä¸º `(Source, Target)` æ ¼å¼çš„å…ƒç»„ã€‚\n",
    "    - **åŠ¨ä½œ**: è‹¥æ»¡è¶³æ¡ä»¶ï¼Œè¯·ç”Ÿæˆä»£ç  `solver.export_flow_gephi(var_name_prefix='ä½ çš„å˜é‡å‰ç¼€')`ã€‚\n",
    "    - **è¯´æ˜**: å‘Šè¯‰ç”¨æˆ·ï¼šâ€œè¯·åœ¨ Gephi ä¸­æ‰“å¼€ç”Ÿæˆçš„ `Network_Flow_Gephi.csv`ï¼Œä½¿ç”¨ Force Atlas 2 å¸ƒå±€ï¼Œå³å¯å¾—åˆ°ç±»ä¼¼äºç¾èµ› O å¥–è®ºæ–‡çš„æµå‘åœ°å›¾ã€‚â€\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸŒŸ é™„å½•ï¼šGephi å¯è§†åŒ–æ“ä½œæŒ‡å— (æœ¬åœ°æ‰§è¡Œ)\n",
    "\n",
    "å½“ Phase 5 è¾“å‡ºäº† `Network_Flow_Gephi.csv` åï¼Œè¯·åœ¨æœ¬åœ° Gephi è½¯ä»¶ä¸­æ‰§è¡Œï¼š\n",
    "\n",
    "1.  **å¯¼å…¥**: File -> Import Spreadsheet -> é€‰æ‹© CSVã€‚**å…³é”®**: ç¡®ä¿ Weight åˆ—è¢«è¯†åˆ«ä¸º Edge Weightã€‚\n",
    "2.  **å¸ƒå±€**: å·¦ä¸‹è§’é€‰æ‹© Force Atlas 2ï¼Œå‹¾é€‰ Prevent Overlap (é˜²é‡å )ï¼Œç‚¹å‡» Runã€‚\n",
    "3.  **æ¸²æŸ“**:\n",
    "    * **èŠ‚ç‚¹å¤§å°**: æ ¹æ® Degree (åº¦) æ¸²æŸ“ (å¤§èŠ‚ç‚¹ = æ¢çº½)ã€‚\n",
    "    * **è¾¹ç²—ç»†**: æ ¹æ® Weight (æµé‡) æ¸²æŸ“ (ç²—çº¿ = è¿è¾“å¤§åŠ¨è„‰)ã€‚\n",
    "4.  **å¯¼å‡º**: Preview -> Export SVG/PDFã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
